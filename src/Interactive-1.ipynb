{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Restarted base (Python 3.11.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate_database import Client\n",
    "\n",
    "c = Client()\n",
    "c.client.collections.delete_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.init_schemas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/anaconda3/lib/python3.11/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdfa\n",
      "[{'name': 'TITLE', 'text': 'Changing travel patterns in China during the early stages of the COVID-19 pandemic'}, {'name': None, 'text': 'T he COVID-19 pandemic was first identified in Wuhan, China, in late 2019, and came to prominence in January 2020, and quickly spread within the country.'}, {'name': None, 'text': 'January is also a major holiday period in China, and the 40-day period around Lunar New Year (LNY), or Chunyun, marks the largest annual human movement in the world, with major travel flows out of large cities 1 .'}, {'name': None, 'text': 'The purpose of this holiday travel is often to visit family members.'}, {'name': None, 'text': 'The temporary displacement from residential addresses as a result of this holiday travel could last one to two weeks, up to a month.'}, {'name': None, 'text': 'In 2019, nearly 3 billion individual journeys were made during Chunyun 2 .'}, {'name': None, 'text': 'In 2020, Chunyun lasted from 10th January to 18th February 3 , with the first day of the LNY holidays on 24th January, followed by the first day of LNY on 25th January.'}, {'name': None, 'text': 'This period coincided with the initial phase of the COVID-19 pandemic, and there has been speculation that holiday travel may have accelerated the propagation of COVID-19 both within China and internationally 4 .'}, {'name': None, 'text': 'As part of initial efforts to contain the outbreak, the Chinese government announced a cordon sanitaire for the city of Wuhan, Hubei Province, starting on 23rd January 2020, one day before LNY holidays.'}, {'name': None, 'text': 'This intervention restricted all non-essential movement into and out of the city.'}, {'name': None, 'text': 'Services at airports, train stations, long-distance bus stations, and commercial ports were all suspended 5 .'}, {'name': None, 'text': 'Several studies have focused on assessing the effectiveness of the cordon sanitaire in Wuhan and other domestic travel restrictions in China in the context of COVID-19 control As other affected regions worldwide begin implementing similar travel restrictions 9 , it is critical to understand human mobility patterns during the initial phase of the COVID-19 pandemic and their potential implications for other countries.'}, {'name': None, 'text': 'Out-going traffic from Wuhan was reduced by 89% within two days of the cordon sanitaire, according to data from Baidu Huiyan, an internet service company in China which uses location targeting to provide services to users.'}, {'name': None, 'text': \"Baidu's Location Based Service (LBS) 10 provides travel fluxes between prefectures in China during the annual Chunyun period to allow monitoring of movement of people using their services.\"}, {'name': None, 'text': 'Previous analyses of Baidu movement data have used mobility data in transmission models 6,11 , and others have examined the changes in patterns around Wuhan 7 .'}, {'name': None, 'text': 'A key unknown is to what extent the observed travel patterns in Wuhan and the rest of China were part of regular seasonal movements or were responses to the emerging epidemic or interventions against it, including the cordon sanitaire.'}, {'name': None, 'text': 'Relying on a range of data scientific techniques, we examine human movement between Chinese prefectures on multiple geographic scales to provide a detailed examination of travel patterns during the early stages of the COVID-19 pandemic in China.'}, {'name': None, 'text': 'We combine analyses of travel patterns from Wuhan, where the first COVID-19 epidemic was identified, and the first Chinese city to introduce large scale movement restrictions, with an analysis of the effects on the overall Chinese travel network.'}, {'name': None, 'text': 'We further explore the relationship between travel patterns during the LNY holidays and regional healthcare capacity, to understand the impact of the human movements on the healthcare pressure caused by the spreading epidemic.'}, {'name': None, 'text': 'This research is intended to provide a complete picture of the overall movement dynamics in China, and the public health implications of those movements, and has relevance to other countries implementing travel restrictions in an effort to limit the spread of COVID-19.'}, {'name': 'RESULTS', 'text': 'Human movement surrounding Wuhan, Hubei.'}, {'name': 'RESULTS', 'text': 'We used daily prefecture-level movement data across China provided by Baidu Huiyan 10 to understand the spatial and temporal characteristics of movement patterns before, during and after the COVID-19 epidemic in Wuhan.'}, {'name': 'RESULTS', 'text': 'Before the cordon sanitaire and during the initial phase of the COVID-19 epidemic, outbound travel volume from Wuhan was marked by an early-January peak, followed by a sharper second peak in the days before the LNY holidays ( Fig.'}, {'name': 'RESULTS', 'text': '1a).'}, {'name': 'RESULTS', 'text': 'The first peak was not observed in 2019, while the second peak was higher in 2020 than 2019.'}, {'name': 'RESULTS', 'text': \"Because the start of Wuhan's cordon sanitaire and the beginning of LNY holidays were only one day apart, we refer only to LNY while describing our results.\"}, {'name': 'RESULTS', 'text': 'Using k-means clustering of the timeseries of daily outbound travel from Wuhan to other prefectures, we identified four general temporal patterns that captured the travel patterns from Wuhan ( Fig.'}, {'name': 'RESULTS', 'text': '1e, Supplementary Table 1).'}, {'name': 'RESULTS', 'text': 'Two of these clusters exhibited an increase in flow immediately before LNY (clusters A and B).'}, {'name': 'RESULTS', 'text': 'Members of clusters A and B are geographically closer to Wuhan (Fig.'}, {'name': 'RESULTS', 'text': '1d), with fewer residents and overall lower population density ( Fig.'}, {'name': 'RESULTS', 'text': '1e, Supplementary Tables 2-3).'}, {'name': 'RESULTS', 'text': 'Cluster C exhibited two peaks around 7 and 22 January 2020, respectively.'}, {'name': 'RESULTS', 'text': 'Cluster D showed one peak in early-January 2020, with no peak immediately preceding the LNY holidays.'}, {'name': 'RESULTS', 'text': 'The findings are not sensitive to the number of clusters, (Supplementary Figs.'}, {'name': 'RESULTS', 'text': 'The earliest detection of COVID-19 outside of Wuhan was 17th January 2020 ( Fig.'}, {'name': 'RESULTS', 'text': '1b).'}, {'name': 'RESULTS', 'text': 'By late March, over 90% of prefectures and province-level cities (further detail on administrative levels included in \"Methods\" section) in mainland China had at least one confirmed case of COVID-19.'}, {'name': 'RESULTS', 'text': 'Most prefectures confirmed their first COVID-19 cases between 23rd and 26th January 2020.'}, {'name': 'RESULTS', 'text': 'Among the four clusters identified, cluster membership was associated with COVID-19 detection timing (p-value = 0.0004).'}, {'name': 'RESULTS', 'text': 'Members of cluster D tended to have earlier COVID-19 detection.'}, {'name': 'RESULTS', 'text': 'Such association persisted after adjusting for surveillance bias (p-value = 0.00002, see also Supplementary Fig.'}, {'name': 'RESULTS', 'text': '6).'}, {'name': 'RESULTS', 'text': 'Cluster membership was also associated with differences in prefecture-level population sizes ( Fig.'}, {'name': 'RESULTS', 'text': '1c).'}, {'name': 'RESULTS', 'text': 'Cluster D includes large population centres (e.g., Beijing, Shanghai, Guangzhou and Shenzhen) ( Fig.'}, {'name': 'RESULTS', 'text': '1d).'}, {'name': 'RESULTS', 'text': 'After the possible arrival of infected individuals from Wuhan, these highly connected cities could have contributed to the further spread of COVID-19 to places less directly connected to Wuhan.'}, {'name': 'RESULTS', 'text': 'There were also a small number of prefectures that did not have any confirmed cases until 3 weeks after the cordon sanitaire in Wuhan.'}, {'name': 'RESULTS', 'text': 'We repeated the same analyses for other large cities in China, finding that despite the different numbers of clusters identified, the general patterns in movement flows observed in Wuhan were seen elsewhere in mainland China, with an early January peak in travel, and another increase in travel volume preceding LNY .'}, {'name': 'RESULTS', 'text': 'The association between the population size of destinations and geographic distance, however, was less apparent.'}, {'name': 'RESULTS', 'text': 'The early-January peak in Wuhan coincided with the beginning of winter break for university students in China 12 , approximately one million of whom study in Wuhan 13 .'}, {'name': 'RESULTS', 'text': 'Without information about the age composition of travellers at this time, we cannot provide a definite explanation of this observation.'}, {'name': 'RESULTS', 'text': 'There is anecdotal evidence implying an association between the announcement of a cordon sanitaire on 23rd January and temporarily increased outbound travel from Wuhan 14 .'}, {'name': 'RESULTS', 'text': 'This relationship, if true, could have hindered the effectiveness of the cordon sanitaire.'}, {'name': 'RESULTS', 'text': 'Focusing on the six-day period preceding LNY, we compared the outbound travel patterns from Wuhan with the rest of mainland China using 2019 as the baseline.'}, {'name': 'RESULTS', 'text': 'We used two variability metrics to investigate potential outbound travel surges: (1) a proportion-based matric, Eq.'}, {'name': 'RESULTS', 'text': '(3), that captures the relative between-year difference; and (2) an anomaly-based metric Eq.'}, {'name': 'RESULTS', 'text': '(4) that captures the deviation observed in 2020 compared to 2019.'}, {'name': 'RESULTS', 'text': 'We found that although there is evidence of an increase in outbound travel from Wuhan during this period, a similar increase was also observed in many other prefectures.'}, {'name': 'RESULTS', 'text': 'Wuhan was ranked 46 (top 13%) and 88 (top 24%) of 305, by the two metrics for the change in flow ( Supplementary Fig.'}, {'name': 'RESULTS', 'text': '12).'}, {'name': 'RESULTS', 'text': 'Movement patterns across China.'}, {'name': 'RESULTS', 'text': 'We explored the existence of hierarchical patterns of movement between differently-sized prefectures in mainland China, in an effort to understand differences in the connectivity between more and less populated prefectures during heightened travel during the LNY holidays.'}, {'name': 'RESULTS', 'text': 'We divided prefectures and province-level cities into four population quartiles (i.e., Low (2000 to 1.44 million residents), Medium-low (1.45 to 2.96 million residents), Medium-high (2.98 to 4.90 million residents) and High (4.92 to 24.20 million residents).'}, {'name': 'RESULTS', 'text': 'We found that the trends of inbound and outbound travel volume over time were relatively consistent across population quartiles ( Supplementary Fig.'}, {'name': 'RESULTS', 'text': '13).'}, {'name': 'RESULTS', 'text': \"The flow between all pairs of quartiles, measured in Baidu's migration index, increased prior to LNY and dropped sharply after Wuhan's cordon sanitaire, with an increase in within-quartile flow following 23rd January for all quartiles.\"}, {'name': 'RESULTS', 'text': 'However, the underlying composition of these in-and outbound travel flows differed substantially by population quartile ( Fig.'}, {'name': 'RESULTS', 'text': '2).'}, {'name': 'RESULTS', 'text': 'Before LNY, all regions saw increased inbound travel from highly populated prefectures ( Fig.'}, {'name': 'RESULTS', 'text': '2a-d).'}, {'name': 'RESULTS', 'text': 'These changes were more marked in prefectures of lower population sizes.'}, {'name': 'RESULTS', 'text': 'After LNY, the contribution to inbound travel by prefectures in the middle quartiles stabilised at higher levels compared to pre-LNY.'}, {'name': 'RESULTS', 'text': 'As the volume of inbound travel recovered through February (Supplementary Fig.'}, {'name': 'RESULTS', 'text': '15), the relative proportion of travellers from the most populated quartiles remained low.'}, {'name': 'RESULTS', 'text': 'For outbound travel, a higher proportion of travellers from the most populated prefectures travelled to the middle quartiles before LNY, and a higher proportion from medium-sized prefectures travelled to low-population prefectures ( Fig.'}, {'name': 'RESULTS', 'text': '2e-h).'}, {'name': 'RESULTS', 'text': 'Travel volumes and distance patterns in Beijing, Shanghai, and Guangzhou began to return to normal more quickly than in Wuhan, and outbound travel generally recovered more after LNY ( Supplementary Fig.'}, {'name': 'RESULTS', 'text': '14).'}, {'name': 'RESULTS', 'text': 'This analysis of origin or destination locations revealed diverging hierarchical effects, rather than a simple cascading flow of travellers from larger to smaller population prefectures.'}, {'name': 'RESULTS', 'text': 'Travellers from large prefectures more often travelled to other large or medium size prefectures; travellers from medium and small prefectures more often travelled between medium and small prefectures.'}, {'name': 'RESULTS', 'text': 'Holiday travel immediately preceding LNY can be considered an indicator of long-term migration in China, as people travel back along their long-term migration route temporarily to visit family.'}, {'name': 'RESULTS', 'text': 'The patterns we observed are consistent with the migration step effect along the urban hierarchy, in which geographic regions of similar population size exchange members more often 15,16 .'}, {'name': 'RESULTS', 'text': 'The divergence in hierarchical flow between high and low population prefectures means that middle population prefectures could play a key role in limiting the spread of COVID-19 to prefectures with fewer residents.'}, {'name': 'RESULTS', 'text': 'Non-pharmaceutical interventions could target these mediumsized prefectures to prevent epidemics from reaching the relatively rural parts of China.'}, {'name': 'RESULTS', 'text': 'NATURE COMMUNICATIONS | ARTICLE Healthcare capacity and COVID-19-related healthcare pressure.'}, {'name': 'RESULTS', 'text': 'Before the LNY, the move away from larger population centres was also a move away from high healthcare capacity, measured by the number of Grade II and III hospitals per 100,000 residents ( Fig.'}, {'name': 'RESULTS', 'text': '3).'}, {'name': 'RESULTS', 'text': 'Prefectures with higher healthcare capacity had more outgoing than incoming travellers, and after LNY, travellers gradually returned to high healthcare capacity settings, but the overall geographic distribution of residents had not recovered to its pre-LNY conditions by 1st March 2020 ( Fig.'}, {'name': 'RESULTS', 'text': '3a).'}, {'name': 'RESULTS', 'text': 'This pattern persisted when we used an alternative healthcare capacity measure of the number of Grade II and III hospitals without adjusting for background population size ( Supplementary Fig.'}, {'name': 'RESULTS', 'text': '16).'}, {'name': 'RESULTS', 'text': 'The movement observed was associated with COVID-19related healthcare pressure (see \"Methods\" section), a measure of confirmed cases compared with healthcare capacity (Fig.'}, {'name': 'RESULTS', 'text': '3b).'}, {'name': 'RESULTS', 'text': 'From the week before LNY to two weeks after, locations with low healthcare capacity experienced significantly higher pressure compared to locations with high healthcare capacity.'}, {'name': 'RESULTS', 'text': 'Therefore Chunyun not only increased the chance of infection along mobility networks, but also shifted healthcare pressure caused by COVID-19 to regions with low healthcare capacity, an effect seen in other countries and during natural disasters Using the alternative healthcare capacity measure that considers number of hospitals only, we found similar relative associations (Supplementary Fig.'}, {'name': 'RESULTS', 'text': '16).'}, {'name': 'RESULTS', 'text': 'Changes in overall travel network structure.'}, {'name': 'RESULTS', 'text': 'In order to understand broad changes in the Chinese transportation network, we identified communities of highly connected prefectures and assessed the change in these communities during LNY and the introduction of local interventions in Chinese prefectures.'}, {'name': 'RESULTS', 'text': 'We determined the community structure of the local travel network by calculating the daily modularity, Q, of the directed network 20 from 1st January to 1st March 2020.'}, {'name': 'RESULTS', 'text': 'Each community (or module) has more connections within vs. between communities, and modularity is one method for measuring community structure in networks.'}, {'name': 'RESULTS', 'text': 'The changing modularity provides a holistic view of transport throughout the country, highlighting macroscopic changes in the network, e.g., rerouting behaviour or increased linkages between new prefectures, as the movement network adjusted to travel restrictions in Wuhan.'}, {'name': 'RESULTS', 'text': 'Preceding the implementation of travel restrictions, there was a stable pattern of communities connected to large cities, with significant flows between communities (Fig.'}, {'name': 'RESULTS', 'text': '4).'}, {'name': 'RESULTS', 'text': 'A lower Modularity value (Q) indicates weaker connections between prefectures within a community, or higher volumes of travel between different communities, rather than within the same communities.'}, {'name': 'RESULTS', 'text': 'The low values of Q preceding LNY indicate a high volume of travel between communities, with increased interconnection of the movement network.'}, {'name': 'RESULTS', 'text': 'Early January before LNY represents typical travel in China with flow between major population centres.'}, {'name': 'RESULTS', 'text': 'During this period, travel within China was generally structured into well-defined communities, with high modularity, Q (Fig.'}, {'name': 'RESULTS', 'text': '4, time point 1).'}, {'name': 'RESULTS', 'text': 'Major cities had consistent, distinct communities which remained fairly steady even as outflows began to increase from major cities for LNY ( Fig.'}, {'name': 'RESULTS', 'text': '4, time point 2; see Supplement 6 for full time series).'}, {'name': 'RESULTS', 'text': 'Immediately following the implementation of travel restrictions, we identified a marked peak in modularity where the Qvalue for Wuhan City increased, indicating that it temporarily became more integrated into the travel network ( Fig.'}, {'name': 'RESULTS', 'text': '4a, time point 3).'}, {'name': 'RESULTS', 'text': 'This increase in modularity indicated relatively more connectivity between Wuhan and other communities, although there was decreased flow, so the actual number of travellers was much lower.'}, {'name': 'RESULTS', 'text': 'This could also reflect the large movement of medical and other resources to Wuhan following the implementation of restrictions 21 .'}, {'name': 'RESULTS', 'text': 'Overall connectivity decreased across China after the cordon sanitaire in Wuhan (Fig.'}, {'name': 'RESULTS', 'text': '4, time point 4).'}, {'name': 'RESULTS', 'text': 'This coincided with the implementation of disease control interventions in other prefectures, and a decrease in travel following LNY.'}, {'name': 'RESULTS', 'text': 'Consistent with a country-wide policy of restricted movement, we did not find large rerouting or the increasing importance of other transport connections after the restrictions in Wuhan.'}, {'name': 'RESULTS', 'text': 'This is critical as countries attempt to determine the efficacy of largescale movement restrictions.'}, {'name': 'DISCUSSION', 'text': 'The cordon sanitaire in Wuhan was an intensive travel restriction that completely stopped all non-essential incoming and outgoing traffic.'}, {'name': 'DISCUSSION', 'text': 'Previous studies have demonstrated that it may have had low effectiveness in preventing or delaying transmission to other regions of mainland China during the early phase of the COVID-19 pandemic 7,22 .'}, {'name': 'DISCUSSION', 'text': 'There is however potential for infectious disease control and prevention, especially when timeliness and the necessary scope of restrictions can be achieved 23 .'}, {'name': 'DISCUSSION', 'text': 'Travel restrictions will likely continue to be considered an important infectious disease intervention option against COVID-19 during the pandemic, and better understanding the mechanisms in play at different stages of travel restrictions is crucial to effective implementation.'}, {'name': 'DISCUSSION', 'text': 'We found a limited relationship between spatial proximity and epidemic spread where larger, distant populations detected their first COVID-19 cases earlier than smaller locations that are closer to Wuhan.'}, {'name': 'DISCUSSION', 'text': 'We also observed a hierarchical divergence of movement between prefectures of different populations sizes, with larger prefectures more connected to other large prefectures, and smaller prefectures more connected to other small prefectures.'}, {'name': 'DISCUSSION', 'text': 'Due to the highly connected modern mobility network, spatial proximity is not the only measure for closeness between two cities 24 We found a limited relationship between spatial proximity and epidemic spread where larger, distant populations detected their first COVID-19 cases earlier than smaller locations that are closer to Wuhan.'}, {'name': 'DISCUSSION', 'text': 'Due to the highly connected modern mobility network, spatial proximity is not the only measure for closeness between two cities 24 .'}, {'name': 'DISCUSSION', 'text': 'While planning for travel restrictions, either domestic or international, it may be worthwhile to consider other functional connectivity measures, such as human mobility studied here.'}, {'name': 'DISCUSSION', 'text': 'Although outbreaks may appear to have single source location in the beginning, such as the case in Europe 25 Week in 2020 and week start date The changes in the healthcare pressure (log 10 scale) related to COVID-19 each week in low and high healthcare capacity prefectures.'}, {'name': 'DISCUSSION', 'text': 'Healthcare capacity is measured by the number of hospitals per 100,000 residents (n low = 157, n high = 153).'}, {'name': 'DISCUSSION', 'text': 'Healthcare pressure is measured by confirmed COVID-19 cases divided by healthcare capacity.'}, {'name': 'DISCUSSION', 'text': 'Darker shade represents weeks when low healthcare capacity settings experienced significantly higher pressure than high healthcare capacity settings; lighter shade represents when differences are not statistically significant based on Mann-Whitney U test (5% type I error rate).'}, {'name': 'DISCUSSION', 'text': 'The comparison for week 7 has p-value = 0.06.'}, {'name': 'DISCUSSION', 'text': 'The boxplots in panel b display Median, IQR and whiskers +/− 1.5 times IQR.'}, {'name': 'DISCUSSION', 'text': 'immediate geographic surroundings may lead to missed opportunities for epidemic control.'}, {'name': 'DISCUSSION', 'text': 'The timing of LNY and the initial stage of the COVID-19 epidemic makes it difficult to untangle regular holiday travel from travel in response to the outbreak or to impending travel restrictions.'}, {'name': 'DISCUSSION', 'text': 'The increased outflow from Wuhan that we observed was not unique to the city, as similar patterns of outflow were observed in a large number of other prefectures, and so likely represents increased holiday travel.'}, {'name': 'DISCUSSION', 'text': 'We therefore did not find evidence of an association between the announcement of the cordon sanitaire and the number of outbound travellers leaving Wuhan.'}, {'name': 'DISCUSSION', 'text': 'Data from other countries not confounded by holiday travel (e.g., France 26 ) may yield insights on public responses to travel restrictions.'}, {'name': 'DISCUSSION', 'text': 'In addition, although the overall number of travellers leaving Wuhan was not exceptionally high before LNY, the composition of travellers may have changed, such as a shift from business to family travel, which could contribute to the spread of COVID-19 and could have implications for healthcare demand in destination locations 27 .'}, {'name': 'DISCUSSION', 'text': 'Finer resolution mobility data, including traveller characteristics such as age and occupation, could improve our understanding of the potential outbreak risk and the likely impacts of different interventions in the future.'}, {'name': 'DISCUSSION', 'text': 'Human mobility during Chunyun was marked by the general trend of people leaving large population centres for less populated locations.'}, {'name': 'DISCUSSION', 'text': 'This is a move by the population away from locations with high healthcare capacity.'}, {'name': 'DISCUSSION', 'text': 'During the peak of the epidemics in mainland China, areas with low healthcare capacity experienced significantly higher healthcare pressure related to COVID-19 compared to elsewhere.'}, {'name': 'DISCUSSION', 'text': 'Temporarily mobilising resources such as medical personnel and equipment could aid epidemic control in places receiving a higher-than-normal number of travellers from places with potentially high COVID-19 prevalence, and thus could be evaluated as a potential public health intervention under similar circumstances 28 .'}, {'name': 'DISCUSSION', 'text': 'The structure of the overall transportation network in China did not demonstrate compensatory responses to the cordon sanitaire.'}, {'name': 'DISCUSSION', 'text': 'There was a brief alteration of the network structure immediately following the restrictions, before the network settled quickly back into the same relatively stable communities that existed before the restrictions, albeit at markedly lower flow.'}, {'name': 'DISCUSSION', 'text': \"This implies that the overall transportation network did not undergo structural reorganisation as a result of Wuhan's cordon sanitaire and other regional travel restrictions.\"}, {'name': 'DISCUSSION', 'text': 'Short-term travel restrictions may therefore not incur lasting impacts on the mobility network, but assessing long-term impacts will require longer time-series analyses.'}, {'name': 'DISCUSSION', 'text': 'Mobility data from Baidu Huiyan has some limitations.'}, {'name': 'DISCUSSION', 'text': 'For example, travel volumes were collected on an eight-hourly basis between each pair of prefectures and then aggregated to day-level and prefecture-level, which does not allow analysis of trips longer than a day.'}, {'name': 'DISCUSSION', 'text': 'In a country the size of China, such trips may be relatively frequent.'}, {'name': 'DISCUSSION', 'text': 'Pairwise travel patterns before 1 January 2020 are not available, which makes it challenging to determine baseline travel patterns.'}, {'name': 'DISCUSSION', 'text': 'In addition, movement patterns from Baidu Huiyan reflect the movement of Baidu users, which may be a non-random subset of the general population in mainland China 29 .'}, {'name': 'DISCUSSION', 'text': \"This study analysed the human mobility patterns around China during different stages of the local COVID-19 epidemics, from early Chunyun to Wuhan's cordon sanitaire and other travel restrictions.\"}, {'name': 'DISCUSSION', 'text': 'Using a range of techniques, we assessed the patterns of movement specific to Wuhan and the characteristics of the travel network throughout China considering the implications of changing travel patterns on the spread of COVID-19.'}, {'name': 'DISCUSSION', 'text': 'We also explored the impact of travel patterns on Chinese prefectures, assessing the changes in healthcare pressure due to varying patterns of human mobility typically associated with LNY, which coincided with the early stages of the COVID-19 pandemic.'}, {'name': 'DISCUSSION', 'text': 'Many countries have now implemented similar travel restrictions to reduce disease transmission.'}, {'name': 'DISCUSSION', 'text': 'Understanding the implications of travel patterns before, during, and following travel restrictions is valuable for informing public health interventions, surveillance, and healthcare demand planning globally.'}, {'name': 'METHODS', 'text': 'Geographic information.'}, {'name': 'METHODS', 'text': 'The geographic unit of analysis in this study is prefecture, which is administrative level two in mainland China, just below the province (level one).'}, {'name': 'METHODS', 'text': 'There are currently more than 360 prefecture-level units in China.'}, {'name': 'METHODS', 'text': 'However, the four provincial level cities (Beijing, Tianjin, Shanghai and Chongqing) are exceptions.'}, {'name': 'METHODS', 'text': 'They do not have a level two unit -level one directly manages level three administrative units (i.e., counties) in these locations 30 .'}, {'name': 'METHODS', 'text': 'In this study, we analysed these province-level cities with prefectures for spatial completeness.'}, {'name': 'METHODS', 'text': 'Mobility data.'}, {'name': 'METHODS', 'text': 'The mobility data is publicly available through Baidu Huiyan 10 , a web service that supports government agencies and businesses with big-data spatio-temporal analytics.'}, {'name': 'METHODS', 'text': 'Estimates are based on over 120 billion location-based service (LBS) enquiries each day from over 1.1 billion mobile devices, while taking into consideration more than 1.5 billion points of interests (POI).'}, {'name': 'METHODS', 'text': 'We obtained two variables directly from Baidu Huiyan: overall migration index (specific to each prefecture) and percentage of travellers arriving in or leaving specific locations (specific to each pair of prefectures).'}, {'name': 'METHODS', 'text': 'Note that migration index is a relative measure of the magnitude of human mobility, scaled relative to the total volume of movement across the network.'}, {'name': 'METHODS', 'text': 'Baidu movement flow index is collected in 8-h windows and is provided as origin-destination flows between pairs of prefectures.'}, {'name': 'METHODS', 'text': 'We further processed these data to produce symmetrical matrices of daily travel between all Chinese prefectures.'}, {'name': 'METHODS', 'text': 'We calculate the volume of human mobility between each pair of prefectures on each day between 1st January 2020 and 1st March 2020 using the following equation: T ij;t ¼ F i;outbound;t p ij;outbound;tð1Þ where, for a given day, T ij,t is the volume of mobility from location i to location j on day t, F is the overall Baidu migration index with direction (inbound or outbound) at location i, and p ij;outbound is the proportion of all outbound travel that originated in i and ended in j. References to inbound and outbound travel are made in regards to a specific origin or destination location.'}, {'name': 'METHODS', 'text': 'We further validated this measure by assuming that inbound and outbound were equal, as: T ij;t ¼ F i;outbound;t p ij;outbound;t ¼ F j;inbound;t p ij;inbound;tð2Þ where p ij;inbound;t is the proportion of all inbound travel that end in j and originate in i.'}, {'name': 'METHODS', 'text': 'Note that p ij;outbound;t and p ij;inbound;t are only available for the top 100 connected prefectures.'}, {'name': 'METHODS', 'text': 'In other words, p ij;outbound;t is only available for the top 100 destinations originating in i; p ij;inbound;t is only available for the 100 origins with the most travellers to j.'}, {'name': 'METHODS', 'text': 'We were not able to validate for T ij,t in the cases where p ij;outbound;t and p ij;inbound;t are not simultaneously available.'}, {'name': 'METHODS', 'text': 'Using data from Baidu Huiyan, we created a symmetric, 366 × 366 connectivity matrix for each day between 1 January 2020 and 1 Mar 2020 (61 days).'}, {'name': 'METHODS', 'text': 'Demographic and healthcare system data.'}, {'name': 'METHODS', 'text': 'The 2018 population sizes were retrieved from the China Statistics Yearbook 31 .'}, {'name': 'METHODS', 'text': 'This metric accounts for migrant population, and thus is expected to may fluctuate during the holiday seasons.'}, {'name': 'METHODS', 'text': 'The geographic boundaries of prefectures and province-level cities were obtained from the Institute of Geographic Sciences and Natural Resources Research (Chinese Academy of Sciences) 32 .'}, {'name': 'METHODS', 'text': 'The original source of daily confirmed incidence is the COVID-19 dashboard published by DXY.cn, which updates in near-real time based on government press releases 33 .'}, {'name': 'METHODS', 'text': \"In addition, the package 'nCoV2019' 34 and 'DXY-COVID-19-Crawler' 35 have reduced the time required for data gathering and data cleaning.\"}, {'name': 'METHODS', 'text': 'Records of first case arrivals were cross-checked with news articles also found throughon DXY.cn 33 .'}, {'name': 'METHODS', 'text': 'Information on the Grade II and III hospitals in China was retrieved from the National Health Commission 36 and was then georeferenced using the non-commercial Amap API 37 .'}, {'name': 'METHODS', 'text': 'Time series analysis and surge evaluation.'}, {'name': 'METHODS', 'text': 'The patterns of movement out of Wuhan between 1st and 23rd January were analysed using cluster analysis of the magnitude-normalised timeseries of outflow over time.'}, {'name': 'METHODS', 'text': 'Outflow timeseries were selected using a threshold of journeys with an average flow index greater than 0.005 for the entire period.'}, {'name': 'METHODS', 'text': 'This threshold removed prefectures with negligible connectivity with the origin.'}, {'name': 'METHODS', 'text': 'In order to characterise the shape of the outflow from Wuhan, rather than the magnitude of certain outflows, we calculated the normalised flow, N, between origin (i) and destination (j) prefectures on each day (t), by dividing the outflow measured by the travel index T, by the total movement between the 1st and 23rd January 2020, as: N ij;t ¼ T ij;t P t¼23 t¼1 T ij;tð3Þ We classified the time series using k-means clustering with four clusters 38 .'}, {'name': 'METHODS', 'text': 'The number of clusters was chosen using a plot of average silhouette width against number of clusters, for between 4 and 12 clusters.'}, {'name': 'METHODS', 'text': 'The silhouette width decreased significantly at four clusters, and a similar number of time series were allocated to each cluster ( Supplementary Figs.'}, {'name': 'METHODS', 'text': '1-5).'}, {'name': 'METHODS', 'text': 'Furthermore, when using a greater number of clusters, we observed the same four overall temporal patterns with smaller differences between time series defining each cluster.'}, {'name': 'METHODS', 'text': 'We also observed an increasingly large number of clusters containing a small number of time series.'}, {'name': 'METHODS', 'text': 'Plots of the time series clustered using 2, 3, 4, 5 and 6 clusters are included in Supplementary Figs.'}, {'name': 'METHODS', 'text': '1-5.'}, {'name': 'METHODS', 'text': 'K-medioids, and Agglomerative Clustering were also explored as alternatives to K-means clustering.'}, {'name': 'METHODS', 'text': 'The different clustering methods did not result in substantial differences and identified similar patterns among outflow time series.'}, {'name': 'METHODS', 'text': 'We quantified the peak outflow from each prefecture in the five-day window before LNY (i.e., two to seven days before LNY, zero to five days before the cordon sanitaire).'}, {'name': 'METHODS', 'text': 'We used two parameters to characterise the magnitude of the change in outflow in 2020 compared to 2019 in each prefecture i: V 1;i ¼ mean F i;τ 2020 mean F i;τ 2019 À 1ð4Þ V 2;i ¼ mean F i;τ 2020 À mean F i;τ 2019 std F i;τ 2019ð5Þ where F i,τ is the total Baidu outflow from prefecture i in the time period τ. τ in 2019 corresponds to 29 January-3 February 2019, and in 2020 corresponds to 18 January-23 January.'}, {'name': 'METHODS', 'text': 'The dates are different each year because they are aligned to the date of LNY in 2019 and 2020.'}, {'name': 'METHODS', 'text': 'The Relationship between First Case Detection and Cluster Membership: We explored the association between average population size and first case detection for prefectures in each cluster.'}, {'name': 'METHODS', 'text': 'There is potential confounding due to surveillance bias such that larger prefectures may detect COVID-19 cases earlier due to better public health infrastructure resulting in earlier and greater use of diagnostic tests.'}, {'name': 'METHODS', 'text': 'However, there is no intuitive indicator that can capture surveillance efforts, and therefore we used population size as a proxy for surveillance effort.'}, {'name': 'METHODS', 'text': 'The implicit assumption is that places with larger populations are more equipped for detecting COVID-19, which is supported because early testing capacity relied on biosafety level 2+ laboratories, which are only found in large hospitals and universities 39 .'}, {'name': 'METHODS', 'text': 'We adjust for this potential confounding effect using a linear regression model: Detection date $ pop ðcluster membershipÞ ð 6Þ where pop represents the prefecture level population size as of 2018 and (Cluster membership) is a nominal unordered categorical variable with levels A through D. Assessing the healthcare capacity and COVID-19-related healthcare pressure.'}, {'name': 'METHODS', 'text': 'In this study, prefecture-level healthcare capacity was measured by the number of Grade II and III hospitals per 100,000 residents.'}, {'name': 'METHODS', 'text': 'In mainland China, Grade II and III hospitals have 100-499 or 500+ hospital beds, respectively, and are equipped with ventilators 40 .'}, {'name': 'METHODS', 'text': 'Thus, they are more important compared to community hospitals and clinics for COVID-19 management.'}, {'name': 'METHODS', 'text': 'Healthcare capacity in prefecture i (HC i ), therefore, can be expressed as: HC hospital;i Pop residential;ið7Þ where n hospital,i is the number of Grade II and III hospitals in prefecture i, and Pop residential,i is the residential population of prefecture i.'}, {'name': 'METHODS', 'text': 'We use the size of the residential population in 2018 from the China Statistics Yearbook 29 .'}, {'name': 'METHODS', 'text': 'HC i is stratified into high and low by taking the upper and lower 50% of prefectures with available data.'}, {'name': 'METHODS', 'text': 'Note that this metric cannot accurately reflect the prefecture level population sizes during LNY due to population movement.'}, {'name': 'METHODS', 'text': 'For example, the residential population size of Beijing is approximately 22 million, and over 10 million left the city for LNY 41 .'}, {'name': 'METHODS', 'text': 'Healthcare pressure in prefecture i during week w (Hp i,w ) was calculated by dividing weekly confirmed COVID-19 cases 31 by the healthcare capacity: HP i;w ¼ n confirmed;w HC ið8Þ where n confirmed,w is the number of confirmed COVID-19 cases during week w. We also performed a sensitivity analysis on the metric and considered an alternative measure of healthcare capacity that did not adjust for the background residential population sizes: HC hospital;ið9Þ The distributions of healthcare pressure were non-Gaussian.'}, {'name': 'METHODS', 'text': 'We therefore used non-parametric one-tailed Mann-Whitney U tests to compare the differences of healthcare pressure between low and high healthcare capacity settings.'}, {'name': 'METHODS', 'text': 'The null hypothesis was that the healthcare pressures in low healthcare capacity settings are comparable to that in high healthcare capacity settings; the alternative hypothesis was that healthcare pressures in low healthcare capacity settings are higher than those in high healthcare capacity settings (n1 = 157, n2 = 153).'}, {'name': 'METHODS', 'text': 'This test was repeated for each week from week three to nine (i.e., starting on 15 Jan 2020).'}, {'name': 'METHODS', 'text': 'Results were verified using two-tailed Mann-Whitney U tests, as well as one-tailed Mann-Whitney U tests with the opposite null hypotheses.'}, {'name': 'METHODS', 'text': 'Network analysis.'}, {'name': 'METHODS', 'text': 'Using the weighted movement flows between locations, we calculated community structure in the network using the Leiden algorithm 20 .'}, {'name': 'METHODS', 'text': 'The Leiden algorithm maximises the modularity, Q, on directed, weighted, time sliced NATURE COMMUNICATIONS | ARTICLE networks with an inter-slice weighting of 10 −5 , which is the order of magnitude of minimum intra-slice weight across all times 42 .'}, {'name': 'METHODS', 'text': 'Modularity is a metric of withincommunity vs. between-community connectivity, and the algorithm detects communities by optimising the within vs. between, thereby assigning nodes to communities.'}, {'name': 'METHODS', 'text': 'Using the community structure from this algorithm, we identified the relative contributions to modularity, Q, of 4 key communities: the community containing Wuhan prefecture, and then the communities of four other major cities in China: Beijing, Shanghai, Guangzhou, and Shenzhen.'}, {'name': 'METHODS', 'text': 'The latter two were always assigned to the same community and are marked together in Fig.'}, {'name': 'METHODS', 'text': '4.'}, {'name': 'METHODS', 'text': 'We presented 4 snapshots of communities in the travel network, but all are shown in Supplementary Fig.'}, {'name': 'METHODS', 'text': '17, and the spatial locations of those networks in Supplementary Fig.'}, {'name': 'METHODS', 'text': '18.'}, {'name': 'METHODS', 'text': 'Distance Kernels.'}, {'name': 'METHODS', 'text': 'To determine how the relationship between distance and travel flow changed over Chunyun and in response to the cordon sanitaire, we calculated the frequency of journeys of at least distance n kilometres, for n up to the maximum distance 4185 km, on each day of the study period.'}, {'name': 'METHODS', 'text': 'These plots are shown for Beijing, Guangzhou, Shanghai and Wuhan, for both inflow and outflow in Supplementary Fig.'}, {'name': 'METHODS', 'text': '14.'}, {'name': 'METHODS', 'text': 'Sensitivity analyses.'}, {'name': 'METHODS', 'text': 'We repeated clustering of temporal traveller flow time series to validate the method for assessing travel flux out of Wuhan between January 1st and January 23rd.'}, {'name': 'METHODS', 'text': 'Employing the same method of thresholding prefectures with little connectivity, the volume of travel to individual destination locations over time were normalised by dividing by the total flow along each route in the period.'}, {'name': 'METHODS', 'text': 'These normalised time series were then clustered using the same k-means clustering procedure discussed above.'}, {'name': 'METHODS', 'text': 'The number of clusters was determined using a silhouette plot in order to isolate the dominant temporal patterns of traveller movement to individual destinations.'}, {'name': 'TAB_1', 'text': 'Net change by migration index 0 −10'}, {'name': 'TAB_1', 'text': '0 −20'}, {'name': 'TAB_1', 'text': '0 0.03 0.10 0.30 1.00 3.00 0.03 0.10 0.30 1.00 3.00'}, {'name': 'TAB_1', 'text': '0 Number of hospitals per 100,000'}, {'name': 'TAB_1', 'text': '0 Low access to health care setting High access to healthcare setting'}, {'name': 'TAB_1', 'text': '10,000 0'}, {'name': 'TAB_1', 'text': '0 1000'}, {'name': 'TAB_1', 'text': '0 100'}, {'name': 'TAB_1', 'text': '0 10'}, {'name': 'TAB_1', 'text': '0 1'}, {'name': 'TAB_1', 'text': '0 3 4 5 6 7 8 9 3 4 5 6 7 8 9'}, {'name': 'TAB_1', 'text': '0 01−15 01−22 01−29 02−05 02−12 02−19 02−26 01−15 01−22 01−29 02−05 02−12 02−19 02−26'}]\n",
      "{'name': 'TITLE', 'text': 'Changing travel patterns in China during the early stages of the COVID-19 pandemic'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "6c6465d3-04b1-4f12-a2d8-4355410b4198\n",
      "{'name': None, 'text': 'T he COVID-19 pandemic was first identified in Wuhan, China, in late 2019, and came to prominence in January 2020, and quickly spread within the country.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "ce8795e1-9000-43be-9a18-687f7f729d6d\n",
      "{'name': None, 'text': 'January is also a major holiday period in China, and the 40-day period around Lunar New Year (LNY), or Chunyun, marks the largest annual human movement in the world, with major travel flows out of large cities 1 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "c0dd2385-eb57-46fc-9d5f-9e755499932e\n",
      "{'name': None, 'text': 'The purpose of this holiday travel is often to visit family members.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "5d40d885-434e-4f7a-803d-d641f08c07db\n",
      "{'name': None, 'text': 'The temporary displacement from residential addresses as a result of this holiday travel could last one to two weeks, up to a month.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "71ace7c4-6f5f-4c07-a478-cc1eb85447f5\n",
      "{'name': None, 'text': 'In 2019, nearly 3 billion individual journeys were made during Chunyun 2 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "2e917c00-a1a9-4bf8-a473-8d4a3d457863\n",
      "{'name': None, 'text': 'In 2020, Chunyun lasted from 10th January to 18th February 3 , with the first day of the LNY holidays on 24th January, followed by the first day of LNY on 25th January.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "7a5839b0-92f8-41bf-b907-cbef1bd390d3\n",
      "{'name': None, 'text': 'This period coincided with the initial phase of the COVID-19 pandemic, and there has been speculation that holiday travel may have accelerated the propagation of COVID-19 both within China and internationally 4 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "6b6930e8-d0ce-4418-88e3-e60b146e66c0\n",
      "{'name': None, 'text': 'As part of initial efforts to contain the outbreak, the Chinese government announced a cordon sanitaire for the city of Wuhan, Hubei Province, starting on 23rd January 2020, one day before LNY holidays.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "e9908692-87bb-43d3-9baf-fbc5fef9601a\n",
      "{'name': None, 'text': 'This intervention restricted all non-essential movement into and out of the city.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "63833dd8-1fab-484f-a9b0-bae8b45cb426\n",
      "{'name': None, 'text': 'Services at airports, train stations, long-distance bus stations, and commercial ports were all suspended 5 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "32ff487a-348c-4455-84d8-b3fea6add81a\n",
      "{'name': None, 'text': 'Several studies have focused on assessing the effectiveness of the cordon sanitaire in Wuhan and other domestic travel restrictions in China in the context of COVID-19 control As other affected regions worldwide begin implementing similar travel restrictions 9 , it is critical to understand human mobility patterns during the initial phase of the COVID-19 pandemic and their potential implications for other countries.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "4067b108-2e17-4d31-af6e-3bb60382bc68\n",
      "{'name': None, 'text': 'Out-going traffic from Wuhan was reduced by 89% within two days of the cordon sanitaire, according to data from Baidu Huiyan, an internet service company in China which uses location targeting to provide services to users.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "6e252b3a-d593-4d98-80d6-d87ed0d2bdd0\n",
      "{'name': None, 'text': \"Baidu's Location Based Service (LBS) 10 provides travel fluxes between prefectures in China during the annual Chunyun period to allow monitoring of movement of people using their services.\"}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "dad7af6d-9601-4c1b-b72b-5575e1fc7560\n",
      "{'name': None, 'text': 'Previous analyses of Baidu movement data have used mobility data in transmission models 6,11 , and others have examined the changes in patterns around Wuhan 7 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "695bffd5-7801-49b5-8cb1-5c3db0e11c7a\n",
      "{'name': None, 'text': 'A key unknown is to what extent the observed travel patterns in Wuhan and the rest of China were part of regular seasonal movements or were responses to the emerging epidemic or interventions against it, including the cordon sanitaire.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "185264b8-901b-4f7f-b4a1-1e442feee6a2\n",
      "{'name': None, 'text': 'Relying on a range of data scientific techniques, we examine human movement between Chinese prefectures on multiple geographic scales to provide a detailed examination of travel patterns during the early stages of the COVID-19 pandemic in China.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "7a72147c-7a96-45b6-95b9-124d50320a17\n",
      "{'name': None, 'text': 'We combine analyses of travel patterns from Wuhan, where the first COVID-19 epidemic was identified, and the first Chinese city to introduce large scale movement restrictions, with an analysis of the effects on the overall Chinese travel network.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "d1e5b3f5-451e-437f-a22c-e57cc88859b0\n",
      "{'name': None, 'text': 'We further explore the relationship between travel patterns during the LNY holidays and regional healthcare capacity, to understand the impact of the human movements on the healthcare pressure caused by the spreading epidemic.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "20a87904-53c6-4ef6-bdc0-a661712c881d\n",
      "{'name': None, 'text': 'This research is intended to provide a complete picture of the overall movement dynamics in China, and the public health implications of those movements, and has relevance to other countries implementing travel restrictions in an effort to limit the spread of COVID-19.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "65b11e77-a834-4788-a4bb-5cefc37318f5\n",
      "{'name': 'RESULTS', 'text': 'Human movement surrounding Wuhan, Hubei.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "a4596ea2-1042-4bb3-b87c-02901df7302c\n",
      "{'name': 'RESULTS', 'text': 'We used daily prefecture-level movement data across China provided by Baidu Huiyan 10 to understand the spatial and temporal characteristics of movement patterns before, during and after the COVID-19 epidemic in Wuhan.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "5eff6f8b-f642-440a-a4bb-d9531f328539\n",
      "{'name': 'RESULTS', 'text': 'Before the cordon sanitaire and during the initial phase of the COVID-19 epidemic, outbound travel volume from Wuhan was marked by an early-January peak, followed by a sharper second peak in the days before the LNY holidays ( Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "ca22e210-bbd4-41e2-96ad-2f5229e61d40\n",
      "{'name': 'RESULTS', 'text': '1a).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "f14c9bef-ee89-47b7-bc40-906d505e7a04\n",
      "{'name': 'RESULTS', 'text': 'The first peak was not observed in 2019, while the second peak was higher in 2020 than 2019.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "2b08c75f-21b0-48bb-b70f-ecdfb299206c\n",
      "{'name': 'RESULTS', 'text': \"Because the start of Wuhan's cordon sanitaire and the beginning of LNY holidays were only one day apart, we refer only to LNY while describing our results.\"}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "927d9281-60be-47fe-a612-02c6e331021e\n",
      "{'name': 'RESULTS', 'text': 'Using k-means clustering of the timeseries of daily outbound travel from Wuhan to other prefectures, we identified four general temporal patterns that captured the travel patterns from Wuhan ( Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "25b748ce-eead-43d4-816e-fe0af6ebe274\n",
      "{'name': 'RESULTS', 'text': '1e, Supplementary Table 1).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "79f81ff1-63e9-46b3-9b78-d5b41ac772fd\n",
      "{'name': 'RESULTS', 'text': 'Two of these clusters exhibited an increase in flow immediately before LNY (clusters A and B).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "877833e9-0dfe-476b-9583-7e61c4247d94\n",
      "{'name': 'RESULTS', 'text': 'Members of clusters A and B are geographically closer to Wuhan (Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "7e14bc7c-6927-4aba-8902-500a478724c1\n",
      "{'name': 'RESULTS', 'text': '1d), with fewer residents and overall lower population density ( Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "e470723f-3515-47dc-a337-7c6ebb2e235b\n",
      "{'name': 'RESULTS', 'text': '1e, Supplementary Tables 2-3).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "2f52e72e-53c9-4473-b6a3-4f72d6cd3a48\n",
      "{'name': 'RESULTS', 'text': 'Cluster C exhibited two peaks around 7 and 22 January 2020, respectively.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "1fd2a626-b99a-4d2a-ad97-71b0801c2e17\n",
      "{'name': 'RESULTS', 'text': 'Cluster D showed one peak in early-January 2020, with no peak immediately preceding the LNY holidays.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "6c730245-b1b1-476f-91bc-6874b8a4bf3c\n",
      "{'name': 'RESULTS', 'text': 'The findings are not sensitive to the number of clusters, (Supplementary Figs.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "707a8efa-e90d-4c81-8dfc-0ed221d4379b\n",
      "{'name': 'RESULTS', 'text': 'The earliest detection of COVID-19 outside of Wuhan was 17th January 2020 ( Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "0c182910-1ffd-49d6-bb84-6eb4eccecc2b\n",
      "{'name': 'RESULTS', 'text': '1b).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "a59084b1-e491-4ce7-8850-bfb63df4ac33\n",
      "{'name': 'RESULTS', 'text': 'By late March, over 90% of prefectures and province-level cities (further detail on administrative levels included in \"Methods\" section) in mainland China had at least one confirmed case of COVID-19.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "e254d751-b6c1-4e1f-ab29-343c72f9b559\n",
      "{'name': 'RESULTS', 'text': 'Most prefectures confirmed their first COVID-19 cases between 23rd and 26th January 2020.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "3efedfcb-7323-4862-9df7-47365013bc69\n",
      "{'name': 'RESULTS', 'text': 'Among the four clusters identified, cluster membership was associated with COVID-19 detection timing (p-value = 0.0004).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "9a40e052-ed06-4d0b-8c22-1d532eccb2e2\n",
      "{'name': 'RESULTS', 'text': 'Members of cluster D tended to have earlier COVID-19 detection.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "bfe65737-f656-4604-8161-5a78fdd895e4\n",
      "{'name': 'RESULTS', 'text': 'Such association persisted after adjusting for surveillance bias (p-value = 0.00002, see also Supplementary Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "8ceccf95-baba-4974-b4c3-83bbc940a771\n",
      "{'name': 'RESULTS', 'text': '6).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "28e4b4b7-4fad-4095-beac-33fedaba96c6\n",
      "{'name': 'RESULTS', 'text': 'Cluster membership was also associated with differences in prefecture-level population sizes ( Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "dd7da351-13e3-4741-b500-a4e72d2678f2\n",
      "{'name': 'RESULTS', 'text': '1c).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "8fd75b73-6ce3-4740-af74-3573ac29aab0\n",
      "{'name': 'RESULTS', 'text': 'Cluster D includes large population centres (e.g., Beijing, Shanghai, Guangzhou and Shenzhen) ( Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "5a708d5d-0b5e-481b-be06-6e3ce1d36696\n",
      "{'name': 'RESULTS', 'text': '1d).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "ea6df991-f244-4ab9-b06b-c4e4a475e9f1\n",
      "{'name': 'RESULTS', 'text': 'After the possible arrival of infected individuals from Wuhan, these highly connected cities could have contributed to the further spread of COVID-19 to places less directly connected to Wuhan.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "4356c020-353c-4b28-87aa-188636d97b31\n",
      "{'name': 'RESULTS', 'text': 'There were also a small number of prefectures that did not have any confirmed cases until 3 weeks after the cordon sanitaire in Wuhan.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "409b6f32-2adb-4b13-9713-99719b646205\n",
      "{'name': 'RESULTS', 'text': 'We repeated the same analyses for other large cities in China, finding that despite the different numbers of clusters identified, the general patterns in movement flows observed in Wuhan were seen elsewhere in mainland China, with an early January peak in travel, and another increase in travel volume preceding LNY .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "7dd7f025-770d-46ed-b99d-878406279223\n",
      "{'name': 'RESULTS', 'text': 'The association between the population size of destinations and geographic distance, however, was less apparent.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "c815bdbe-ae7f-4667-864f-ea5ae674454e\n",
      "{'name': 'RESULTS', 'text': 'The early-January peak in Wuhan coincided with the beginning of winter break for university students in China 12 , approximately one million of whom study in Wuhan 13 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "079f2f81-907c-4bc7-965a-121345181254\n",
      "{'name': 'RESULTS', 'text': 'Without information about the age composition of travellers at this time, we cannot provide a definite explanation of this observation.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "ac9426c1-4001-446d-8787-5931f6a95dd1\n",
      "{'name': 'RESULTS', 'text': 'There is anecdotal evidence implying an association between the announcement of a cordon sanitaire on 23rd January and temporarily increased outbound travel from Wuhan 14 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "c13e5ad4-0ac3-4b45-9296-38170809b034\n",
      "{'name': 'RESULTS', 'text': 'This relationship, if true, could have hindered the effectiveness of the cordon sanitaire.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "642ff29b-51f9-4508-bb5f-299c60e3d22f\n",
      "{'name': 'RESULTS', 'text': 'Focusing on the six-day period preceding LNY, we compared the outbound travel patterns from Wuhan with the rest of mainland China using 2019 as the baseline.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "190688c3-f29c-4592-85ed-84e64d0876a8\n",
      "{'name': 'RESULTS', 'text': 'We used two variability metrics to investigate potential outbound travel surges: (1) a proportion-based matric, Eq.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "db9a11e2-20a9-47e0-b2f8-598ca96b2d76\n",
      "{'name': 'RESULTS', 'text': '(3), that captures the relative between-year difference; and (2) an anomaly-based metric Eq.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "b586cb09-32ae-41ab-81de-6696da88e0a0\n",
      "{'name': 'RESULTS', 'text': '(4) that captures the deviation observed in 2020 compared to 2019.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "4798f71e-80af-466e-a249-5ad37e0c62ad\n",
      "{'name': 'RESULTS', 'text': 'We found that although there is evidence of an increase in outbound travel from Wuhan during this period, a similar increase was also observed in many other prefectures.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "117da2de-4cf5-493b-9f49-f95ba6616071\n",
      "{'name': 'RESULTS', 'text': 'Wuhan was ranked 46 (top 13%) and 88 (top 24%) of 305, by the two metrics for the change in flow ( Supplementary Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "db0e49ca-e746-49c6-a6cd-0f8551489bf5\n",
      "{'name': 'RESULTS', 'text': '12).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "904d1dc5-108d-49a9-9244-1a2859d1c302\n",
      "{'name': 'RESULTS', 'text': 'Movement patterns across China.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "852ba322-9ec6-4c4b-9dd7-fb9c69622c8e\n",
      "{'name': 'RESULTS', 'text': 'We explored the existence of hierarchical patterns of movement between differently-sized prefectures in mainland China, in an effort to understand differences in the connectivity between more and less populated prefectures during heightened travel during the LNY holidays.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "89831978-2952-46af-b0cf-8b03017596a7\n",
      "{'name': 'RESULTS', 'text': 'We divided prefectures and province-level cities into four population quartiles (i.e., Low (2000 to 1.44 million residents), Medium-low (1.45 to 2.96 million residents), Medium-high (2.98 to 4.90 million residents) and High (4.92 to 24.20 million residents).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "06afc6f8-6694-49d0-9af8-824e4218027c\n",
      "{'name': 'RESULTS', 'text': 'We found that the trends of inbound and outbound travel volume over time were relatively consistent across population quartiles ( Supplementary Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "693b5199-71d1-45e6-8cb4-aa57b1b2d09d\n",
      "{'name': 'RESULTS', 'text': '13).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "ac19af53-9002-435f-b7e8-c74c16419309\n",
      "{'name': 'RESULTS', 'text': \"The flow between all pairs of quartiles, measured in Baidu's migration index, increased prior to LNY and dropped sharply after Wuhan's cordon sanitaire, with an increase in within-quartile flow following 23rd January for all quartiles.\"}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "da71f52b-7373-4a0a-a639-94b9308d5352\n",
      "{'name': 'RESULTS', 'text': 'However, the underlying composition of these in-and outbound travel flows differed substantially by population quartile ( Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "52cb4494-1ed2-4be3-92a5-c7e4d0dc1198\n",
      "{'name': 'RESULTS', 'text': '2).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "51fdce11-f1b8-4dca-a5ef-8741fef98e72\n",
      "{'name': 'RESULTS', 'text': 'Before LNY, all regions saw increased inbound travel from highly populated prefectures ( Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "d9437acc-0d69-4fc5-a4d9-4c8ff21d2239\n",
      "{'name': 'RESULTS', 'text': '2a-d).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "c005cfa3-1797-4aa6-98d3-01ae020f7181\n",
      "{'name': 'RESULTS', 'text': 'These changes were more marked in prefectures of lower population sizes.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "24a78669-18f9-46e9-85ad-d81ccdcd532c\n",
      "{'name': 'RESULTS', 'text': 'After LNY, the contribution to inbound travel by prefectures in the middle quartiles stabilised at higher levels compared to pre-LNY.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "9e8275ee-2467-4f67-86fe-c9ea45fd7664\n",
      "{'name': 'RESULTS', 'text': 'As the volume of inbound travel recovered through February (Supplementary Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "3d5debc3-8066-4c81-adb7-e2b15de7f444\n",
      "{'name': 'RESULTS', 'text': '15), the relative proportion of travellers from the most populated quartiles remained low.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "514d811f-3389-498f-9a62-0c7bd5cf619f\n",
      "{'name': 'RESULTS', 'text': 'For outbound travel, a higher proportion of travellers from the most populated prefectures travelled to the middle quartiles before LNY, and a higher proportion from medium-sized prefectures travelled to low-population prefectures ( Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "ef4d8bf1-95df-4963-bcc0-bad6b66098f4\n",
      "{'name': 'RESULTS', 'text': '2e-h).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "96b1007e-707e-40cc-aeba-af9126dc1fb9\n",
      "{'name': 'RESULTS', 'text': 'Travel volumes and distance patterns in Beijing, Shanghai, and Guangzhou began to return to normal more quickly than in Wuhan, and outbound travel generally recovered more after LNY ( Supplementary Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "bd74da8d-362d-4352-863a-b3c494bd025d\n",
      "{'name': 'RESULTS', 'text': '14).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "f65dab0f-2b6c-454c-a854-7a11094a4bfb\n",
      "{'name': 'RESULTS', 'text': 'This analysis of origin or destination locations revealed diverging hierarchical effects, rather than a simple cascading flow of travellers from larger to smaller population prefectures.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "72461b15-438c-4abc-a512-038d84f36c80\n",
      "{'name': 'RESULTS', 'text': 'Travellers from large prefectures more often travelled to other large or medium size prefectures; travellers from medium and small prefectures more often travelled between medium and small prefectures.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "ec472e66-d911-4131-9447-17a4f71cfd89\n",
      "{'name': 'RESULTS', 'text': 'Holiday travel immediately preceding LNY can be considered an indicator of long-term migration in China, as people travel back along their long-term migration route temporarily to visit family.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "0d6395b7-4bb7-4fe4-8fb5-1aaebaac0766\n",
      "{'name': 'RESULTS', 'text': 'The patterns we observed are consistent with the migration step effect along the urban hierarchy, in which geographic regions of similar population size exchange members more often 15,16 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "bbd7b0fe-beea-4f07-9d89-4df2ecad3de2\n",
      "{'name': 'RESULTS', 'text': 'The divergence in hierarchical flow between high and low population prefectures means that middle population prefectures could play a key role in limiting the spread of COVID-19 to prefectures with fewer residents.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "e5654b7c-97f8-4fea-a371-dbee2997bfb7\n",
      "{'name': 'RESULTS', 'text': 'Non-pharmaceutical interventions could target these mediumsized prefectures to prevent epidemics from reaching the relatively rural parts of China.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "ac815608-0e8b-49af-93ae-879414f5665e\n",
      "{'name': 'RESULTS', 'text': 'NATURE COMMUNICATIONS | ARTICLE Healthcare capacity and COVID-19-related healthcare pressure.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "4e43d5ad-0b3c-445c-b5f4-afe0142bf876\n",
      "{'name': 'RESULTS', 'text': 'Before the LNY, the move away from larger population centres was also a move away from high healthcare capacity, measured by the number of Grade II and III hospitals per 100,000 residents ( Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "a418125c-a694-4d14-90d2-356b51fb55b0\n",
      "{'name': 'RESULTS', 'text': '3).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "f306d5bb-9553-48b4-b162-e9c8de376da8\n",
      "{'name': 'RESULTS', 'text': 'Prefectures with higher healthcare capacity had more outgoing than incoming travellers, and after LNY, travellers gradually returned to high healthcare capacity settings, but the overall geographic distribution of residents had not recovered to its pre-LNY conditions by 1st March 2020 ( Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "c9b2ec26-96a4-4df1-b74d-414d00245521\n",
      "{'name': 'RESULTS', 'text': '3a).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "1c76bf06-e80f-4a64-b91c-6811a74de323\n",
      "{'name': 'RESULTS', 'text': 'This pattern persisted when we used an alternative healthcare capacity measure of the number of Grade II and III hospitals without adjusting for background population size ( Supplementary Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "96df8997-18b5-47df-8b80-55b1f754c22e\n",
      "{'name': 'RESULTS', 'text': '16).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "af480f05-f2f0-4240-9235-86ffd9961554\n",
      "{'name': 'RESULTS', 'text': 'The movement observed was associated with COVID-19related healthcare pressure (see \"Methods\" section), a measure of confirmed cases compared with healthcare capacity (Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "e8097996-ffe9-48ea-a358-921882f041a5\n",
      "{'name': 'RESULTS', 'text': '3b).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "21accd8c-f2d1-4ef2-bb63-295f2eeb52ca\n",
      "{'name': 'RESULTS', 'text': 'From the week before LNY to two weeks after, locations with low healthcare capacity experienced significantly higher pressure compared to locations with high healthcare capacity.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "5543d399-a2e8-4361-905d-0b39d7a7d6cc\n",
      "{'name': 'RESULTS', 'text': 'Therefore Chunyun not only increased the chance of infection along mobility networks, but also shifted healthcare pressure caused by COVID-19 to regions with low healthcare capacity, an effect seen in other countries and during natural disasters Using the alternative healthcare capacity measure that considers number of hospitals only, we found similar relative associations (Supplementary Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "e903b8ee-ce85-4372-9f2a-5252825f6374\n",
      "{'name': 'RESULTS', 'text': '16).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "58ec2a69-7e20-4b3e-8f58-b38aea8faffa\n",
      "{'name': 'RESULTS', 'text': 'Changes in overall travel network structure.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "71818246-1a00-4586-a61b-ec53a9ded225\n",
      "{'name': 'RESULTS', 'text': 'In order to understand broad changes in the Chinese transportation network, we identified communities of highly connected prefectures and assessed the change in these communities during LNY and the introduction of local interventions in Chinese prefectures.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "19fabefa-a674-4fd3-8517-e03035848695\n",
      "{'name': 'RESULTS', 'text': 'We determined the community structure of the local travel network by calculating the daily modularity, Q, of the directed network 20 from 1st January to 1st March 2020.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "2aa5fcce-6c3a-46b3-bbca-535c63a4f832\n",
      "{'name': 'RESULTS', 'text': 'Each community (or module) has more connections within vs. between communities, and modularity is one method for measuring community structure in networks.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "136dff47-889f-41ce-b5e5-87e842fe00bf\n",
      "{'name': 'RESULTS', 'text': 'The changing modularity provides a holistic view of transport throughout the country, highlighting macroscopic changes in the network, e.g., rerouting behaviour or increased linkages between new prefectures, as the movement network adjusted to travel restrictions in Wuhan.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "1c64b17d-bf14-41e3-8b86-838492a64b57\n",
      "{'name': 'RESULTS', 'text': 'Preceding the implementation of travel restrictions, there was a stable pattern of communities connected to large cities, with significant flows between communities (Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "5f9df581-d339-421a-a449-9f230bcc3024\n",
      "{'name': 'RESULTS', 'text': '4).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "83cba7e6-f430-475e-a358-178b83ab3cb8\n",
      "{'name': 'RESULTS', 'text': 'A lower Modularity value (Q) indicates weaker connections between prefectures within a community, or higher volumes of travel between different communities, rather than within the same communities.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "73a58036-f53c-4df6-b0a3-6ffc1cabca9c\n",
      "{'name': 'RESULTS', 'text': 'The low values of Q preceding LNY indicate a high volume of travel between communities, with increased interconnection of the movement network.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "acf8f2a5-669f-4aa8-8f2e-16826ec9fff0\n",
      "{'name': 'RESULTS', 'text': 'Early January before LNY represents typical travel in China with flow between major population centres.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "d3352b1c-d849-464f-8a20-23421c3c1f5a\n",
      "{'name': 'RESULTS', 'text': 'During this period, travel within China was generally structured into well-defined communities, with high modularity, Q (Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "0d2a8768-7b57-4e72-ad24-535574766992\n",
      "{'name': 'RESULTS', 'text': '4, time point 1).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "2dc3a5ac-bf29-49f3-a179-58a882fae50e\n",
      "{'name': 'RESULTS', 'text': 'Major cities had consistent, distinct communities which remained fairly steady even as outflows began to increase from major cities for LNY ( Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "e3672d5e-ac8e-4de5-9a1b-525da636ea41\n",
      "{'name': 'RESULTS', 'text': '4, time point 2; see Supplement 6 for full time series).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "0f0e86f9-9d3f-4ecf-b3af-7bd5e1c1f2c2\n",
      "{'name': 'RESULTS', 'text': 'Immediately following the implementation of travel restrictions, we identified a marked peak in modularity where the Qvalue for Wuhan City increased, indicating that it temporarily became more integrated into the travel network ( Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "e35a846d-3ad3-4c66-a24b-341d2ae89892\n",
      "{'name': 'RESULTS', 'text': '4a, time point 3).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "36ab3225-dca4-4b1a-b326-9370afa91a85\n",
      "{'name': 'RESULTS', 'text': 'This increase in modularity indicated relatively more connectivity between Wuhan and other communities, although there was decreased flow, so the actual number of travellers was much lower.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "58453c8c-9de3-41b8-92d6-46d2eef36fcf\n",
      "{'name': 'RESULTS', 'text': 'This could also reflect the large movement of medical and other resources to Wuhan following the implementation of restrictions 21 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "d741a245-e641-4ed7-af59-adc055f895b4\n",
      "{'name': 'RESULTS', 'text': 'Overall connectivity decreased across China after the cordon sanitaire in Wuhan (Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "f6556346-0fc8-4fb8-87ef-7e6a9a2fd0f8\n",
      "{'name': 'RESULTS', 'text': '4, time point 4).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "c0cced67-5204-4a13-8011-8c507636b98a\n",
      "{'name': 'RESULTS', 'text': 'This coincided with the implementation of disease control interventions in other prefectures, and a decrease in travel following LNY.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "d53ffd46-885c-4043-958c-ab41206d9cb0\n",
      "{'name': 'RESULTS', 'text': 'Consistent with a country-wide policy of restricted movement, we did not find large rerouting or the increasing importance of other transport connections after the restrictions in Wuhan.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "cf2aba46-b952-41f8-8c3e-67abe6720c95\n",
      "{'name': 'RESULTS', 'text': 'This is critical as countries attempt to determine the efficacy of largescale movement restrictions.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "9de6991d-43b1-40b3-a66b-17c37df162c7\n",
      "{'name': 'DISCUSSION', 'text': 'The cordon sanitaire in Wuhan was an intensive travel restriction that completely stopped all non-essential incoming and outgoing traffic.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "85e825b9-e967-406d-ac71-19ef8c5be59e\n",
      "{'name': 'DISCUSSION', 'text': 'Previous studies have demonstrated that it may have had low effectiveness in preventing or delaying transmission to other regions of mainland China during the early phase of the COVID-19 pandemic 7,22 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "68edae4f-26f4-4423-8db5-b1ab14ef0a62\n",
      "{'name': 'DISCUSSION', 'text': 'There is however potential for infectious disease control and prevention, especially when timeliness and the necessary scope of restrictions can be achieved 23 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "08b277f4-391c-4d7a-815f-67cfaad91903\n",
      "{'name': 'DISCUSSION', 'text': 'Travel restrictions will likely continue to be considered an important infectious disease intervention option against COVID-19 during the pandemic, and better understanding the mechanisms in play at different stages of travel restrictions is crucial to effective implementation.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "9778c0b0-321b-47c0-b0d4-1447c133e9dd\n",
      "{'name': 'DISCUSSION', 'text': 'We found a limited relationship between spatial proximity and epidemic spread where larger, distant populations detected their first COVID-19 cases earlier than smaller locations that are closer to Wuhan.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "83f70083-a4cb-4423-9fd0-79b766d884a2\n",
      "{'name': 'DISCUSSION', 'text': 'We also observed a hierarchical divergence of movement between prefectures of different populations sizes, with larger prefectures more connected to other large prefectures, and smaller prefectures more connected to other small prefectures.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "03f18076-7bd2-4c6a-ac8f-00a3e9a104e0\n",
      "{'name': 'DISCUSSION', 'text': 'Due to the highly connected modern mobility network, spatial proximity is not the only measure for closeness between two cities 24 We found a limited relationship between spatial proximity and epidemic spread where larger, distant populations detected their first COVID-19 cases earlier than smaller locations that are closer to Wuhan.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "a47ff02d-a98b-4a3f-bdba-3487a078b091\n",
      "{'name': 'DISCUSSION', 'text': 'Due to the highly connected modern mobility network, spatial proximity is not the only measure for closeness between two cities 24 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "bc6ec144-f849-4955-8c06-3c40cf5e7a94\n",
      "{'name': 'DISCUSSION', 'text': 'While planning for travel restrictions, either domestic or international, it may be worthwhile to consider other functional connectivity measures, such as human mobility studied here.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "b71a6652-1471-4891-a126-b3a99c92cd05\n",
      "{'name': 'DISCUSSION', 'text': 'Although outbreaks may appear to have single source location in the beginning, such as the case in Europe 25 Week in 2020 and week start date The changes in the healthcare pressure (log 10 scale) related to COVID-19 each week in low and high healthcare capacity prefectures.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "d6694ddf-456e-490b-9962-41f869ceddde\n",
      "{'name': 'DISCUSSION', 'text': 'Healthcare capacity is measured by the number of hospitals per 100,000 residents (n low = 157, n high = 153).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "120ced87-bd77-4335-a03d-2dc0313f2fa3\n",
      "{'name': 'DISCUSSION', 'text': 'Healthcare pressure is measured by confirmed COVID-19 cases divided by healthcare capacity.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "b5c9922b-95fb-48be-b9dd-f63882070e32\n",
      "{'name': 'DISCUSSION', 'text': 'Darker shade represents weeks when low healthcare capacity settings experienced significantly higher pressure than high healthcare capacity settings; lighter shade represents when differences are not statistically significant based on Mann-Whitney U test (5% type I error rate).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "96f7783f-0e5e-4b33-aa18-359ae676656f\n",
      "{'name': 'DISCUSSION', 'text': 'The comparison for week 7 has p-value = 0.06.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "a66ca501-93e7-4e0e-b2d5-7287a7a0e77a\n",
      "{'name': 'DISCUSSION', 'text': 'The boxplots in panel b display Median, IQR and whiskers +/− 1.5 times IQR.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "01583aec-865b-498c-af2a-7bd2f14ec1f0\n",
      "{'name': 'DISCUSSION', 'text': 'immediate geographic surroundings may lead to missed opportunities for epidemic control.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "c6298cfc-33f5-44ea-94cb-ba04f0f550a7\n",
      "{'name': 'DISCUSSION', 'text': 'The timing of LNY and the initial stage of the COVID-19 epidemic makes it difficult to untangle regular holiday travel from travel in response to the outbreak or to impending travel restrictions.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "646fb3e9-0fa9-4f31-81a2-2d61972c891a\n",
      "{'name': 'DISCUSSION', 'text': 'The increased outflow from Wuhan that we observed was not unique to the city, as similar patterns of outflow were observed in a large number of other prefectures, and so likely represents increased holiday travel.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "5ee1dc49-3915-4520-9e0c-fa44ff0e4c7c\n",
      "{'name': 'DISCUSSION', 'text': 'We therefore did not find evidence of an association between the announcement of the cordon sanitaire and the number of outbound travellers leaving Wuhan.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "cc81e5bf-1220-4e41-bcf1-8f5f26eb8ab5\n",
      "{'name': 'DISCUSSION', 'text': 'Data from other countries not confounded by holiday travel (e.g., France 26 ) may yield insights on public responses to travel restrictions.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "007fdd6e-cc0d-4d1c-a221-0554aa61f8b0\n",
      "{'name': 'DISCUSSION', 'text': 'In addition, although the overall number of travellers leaving Wuhan was not exceptionally high before LNY, the composition of travellers may have changed, such as a shift from business to family travel, which could contribute to the spread of COVID-19 and could have implications for healthcare demand in destination locations 27 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "7c3380af-c9ab-424e-a799-5fdee75b87c5\n",
      "{'name': 'DISCUSSION', 'text': 'Finer resolution mobility data, including traveller characteristics such as age and occupation, could improve our understanding of the potential outbreak risk and the likely impacts of different interventions in the future.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "989bcba0-5dcc-49ae-98cd-cd94918b4842\n",
      "{'name': 'DISCUSSION', 'text': 'Human mobility during Chunyun was marked by the general trend of people leaving large population centres for less populated locations.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "7c4b60c8-ab3e-46d0-bf92-40f6c5eae700\n",
      "{'name': 'DISCUSSION', 'text': 'This is a move by the population away from locations with high healthcare capacity.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "735382fa-c4ff-4c99-aa03-f97d095a26b9\n",
      "{'name': 'DISCUSSION', 'text': 'During the peak of the epidemics in mainland China, areas with low healthcare capacity experienced significantly higher healthcare pressure related to COVID-19 compared to elsewhere.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "a974ac1c-89c8-4f6e-8880-6325d7921f48\n",
      "{'name': 'DISCUSSION', 'text': 'Temporarily mobilising resources such as medical personnel and equipment could aid epidemic control in places receiving a higher-than-normal number of travellers from places with potentially high COVID-19 prevalence, and thus could be evaluated as a potential public health intervention under similar circumstances 28 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "ba87ede1-1137-4ea8-9e89-655ef5609b71\n",
      "{'name': 'DISCUSSION', 'text': 'The structure of the overall transportation network in China did not demonstrate compensatory responses to the cordon sanitaire.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "3a2952d1-a940-4d15-a369-5f2c9dd0085d\n",
      "{'name': 'DISCUSSION', 'text': 'There was a brief alteration of the network structure immediately following the restrictions, before the network settled quickly back into the same relatively stable communities that existed before the restrictions, albeit at markedly lower flow.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "f0d50e23-8d1d-4477-9b27-46097b48b046\n",
      "{'name': 'DISCUSSION', 'text': \"This implies that the overall transportation network did not undergo structural reorganisation as a result of Wuhan's cordon sanitaire and other regional travel restrictions.\"}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "fb66efc6-8a04-4aae-a094-822dc762628b\n",
      "{'name': 'DISCUSSION', 'text': 'Short-term travel restrictions may therefore not incur lasting impacts on the mobility network, but assessing long-term impacts will require longer time-series analyses.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "2115ff00-2434-44cc-934d-88035a99b845\n",
      "{'name': 'DISCUSSION', 'text': 'Mobility data from Baidu Huiyan has some limitations.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "8f1d79a2-e8b2-4084-a3fa-9250cf0abb2c\n",
      "{'name': 'DISCUSSION', 'text': 'For example, travel volumes were collected on an eight-hourly basis between each pair of prefectures and then aggregated to day-level and prefecture-level, which does not allow analysis of trips longer than a day.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "d722f7e2-ed14-4217-a2c5-7139b5beb53e\n",
      "{'name': 'DISCUSSION', 'text': 'In a country the size of China, such trips may be relatively frequent.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "736fc78f-9aa6-43d3-9007-29527fd4849b\n",
      "{'name': 'DISCUSSION', 'text': 'Pairwise travel patterns before 1 January 2020 are not available, which makes it challenging to determine baseline travel patterns.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "dd7a69c3-493f-4d5d-8db9-ccfd0ed23938\n",
      "{'name': 'DISCUSSION', 'text': 'In addition, movement patterns from Baidu Huiyan reflect the movement of Baidu users, which may be a non-random subset of the general population in mainland China 29 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "716c9a5f-06ae-4c85-8b7c-62a5b5b11e11\n",
      "{'name': 'DISCUSSION', 'text': \"This study analysed the human mobility patterns around China during different stages of the local COVID-19 epidemics, from early Chunyun to Wuhan's cordon sanitaire and other travel restrictions.\"}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "01ea3bf9-ea83-4823-a805-7051a87c7585\n",
      "{'name': 'DISCUSSION', 'text': 'Using a range of techniques, we assessed the patterns of movement specific to Wuhan and the characteristics of the travel network throughout China considering the implications of changing travel patterns on the spread of COVID-19.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "bfd770ca-c365-493c-97e8-e4d112e94b1f\n",
      "{'name': 'DISCUSSION', 'text': 'We also explored the impact of travel patterns on Chinese prefectures, assessing the changes in healthcare pressure due to varying patterns of human mobility typically associated with LNY, which coincided with the early stages of the COVID-19 pandemic.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "c0e20909-cbb0-4cb0-82b8-f3b3924bd387\n",
      "{'name': 'DISCUSSION', 'text': 'Many countries have now implemented similar travel restrictions to reduce disease transmission.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "f3ae1288-9b10-4682-b727-8ad9d5623ef9\n",
      "{'name': 'DISCUSSION', 'text': 'Understanding the implications of travel patterns before, during, and following travel restrictions is valuable for informing public health interventions, surveillance, and healthcare demand planning globally.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "b5d8ea4a-e095-45e4-8052-143eeac1334d\n",
      "{'name': 'METHODS', 'text': 'Geographic information.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "516a7c8a-c22a-4d4a-a2be-d151d7f96315\n",
      "{'name': 'METHODS', 'text': 'The geographic unit of analysis in this study is prefecture, which is administrative level two in mainland China, just below the province (level one).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "7f80e24f-d97b-4e95-b15a-46a6cc1cfc9b\n",
      "{'name': 'METHODS', 'text': 'There are currently more than 360 prefecture-level units in China.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "b7e3d3d5-f761-4bbd-a6ec-00a160e38bd8\n",
      "{'name': 'METHODS', 'text': 'However, the four provincial level cities (Beijing, Tianjin, Shanghai and Chongqing) are exceptions.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "f3dc0366-2db9-4378-afb5-b906dc0eea71\n",
      "{'name': 'METHODS', 'text': 'They do not have a level two unit -level one directly manages level three administrative units (i.e., counties) in these locations 30 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "20aa9619-961c-4b65-a25e-36d0ad0813c4\n",
      "{'name': 'METHODS', 'text': 'In this study, we analysed these province-level cities with prefectures for spatial completeness.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "fe0ac136-96b0-4867-9a54-701edfd2f06a\n",
      "{'name': 'METHODS', 'text': 'Mobility data.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "7752612f-fdfd-4382-92f4-ebf8027db6e9\n",
      "{'name': 'METHODS', 'text': 'The mobility data is publicly available through Baidu Huiyan 10 , a web service that supports government agencies and businesses with big-data spatio-temporal analytics.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "8c6c959c-fcfa-4ca0-ae68-76edcf57c5e9\n",
      "{'name': 'METHODS', 'text': 'Estimates are based on over 120 billion location-based service (LBS) enquiries each day from over 1.1 billion mobile devices, while taking into consideration more than 1.5 billion points of interests (POI).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "91da988a-f787-4b48-ae50-38fc5bfe88c0\n",
      "{'name': 'METHODS', 'text': 'We obtained two variables directly from Baidu Huiyan: overall migration index (specific to each prefecture) and percentage of travellers arriving in or leaving specific locations (specific to each pair of prefectures).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "c5da9973-ee3a-4a55-9862-aae0c80b0fe1\n",
      "{'name': 'METHODS', 'text': 'Note that migration index is a relative measure of the magnitude of human mobility, scaled relative to the total volume of movement across the network.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "5441ab06-2159-49c7-b628-53fb74aab9b5\n",
      "{'name': 'METHODS', 'text': 'Baidu movement flow index is collected in 8-h windows and is provided as origin-destination flows between pairs of prefectures.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "ef6998f1-7694-4126-88aa-242f121390a7\n",
      "{'name': 'METHODS', 'text': 'We further processed these data to produce symmetrical matrices of daily travel between all Chinese prefectures.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "b3bdce22-89f5-4534-80c3-3903c1e6ba40\n",
      "{'name': 'METHODS', 'text': 'We calculate the volume of human mobility between each pair of prefectures on each day between 1st January 2020 and 1st March 2020 using the following equation: T ij;t ¼ F i;outbound;t p ij;outbound;tð1Þ where, for a given day, T ij,t is the volume of mobility from location i to location j on day t, F is the overall Baidu migration index with direction (inbound or outbound) at location i, and p ij;outbound is the proportion of all outbound travel that originated in i and ended in j. References to inbound and outbound travel are made in regards to a specific origin or destination location.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "5ad7aa37-6a1b-47b9-b100-29d91f01433d\n",
      "{'name': 'METHODS', 'text': 'We further validated this measure by assuming that inbound and outbound were equal, as: T ij;t ¼ F i;outbound;t p ij;outbound;t ¼ F j;inbound;t p ij;inbound;tð2Þ where p ij;inbound;t is the proportion of all inbound travel that end in j and originate in i.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "dc7aad87-0ea1-45f5-bd1e-1a5cab14d5d3\n",
      "{'name': 'METHODS', 'text': 'Note that p ij;outbound;t and p ij;inbound;t are only available for the top 100 connected prefectures.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "2c9b1084-ac74-459d-9d8d-f8ca149fe131\n",
      "{'name': 'METHODS', 'text': 'In other words, p ij;outbound;t is only available for the top 100 destinations originating in i; p ij;inbound;t is only available for the 100 origins with the most travellers to j.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "a83c5345-852e-4840-b205-0ebcc674f178\n",
      "{'name': 'METHODS', 'text': 'We were not able to validate for T ij,t in the cases where p ij;outbound;t and p ij;inbound;t are not simultaneously available.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "e27ee70a-131d-4e4c-9ec2-1df62f2fd1d1\n",
      "{'name': 'METHODS', 'text': 'Using data from Baidu Huiyan, we created a symmetric, 366 × 366 connectivity matrix for each day between 1 January 2020 and 1 Mar 2020 (61 days).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "7a00d5b8-2e90-4347-966a-87668eeac16b\n",
      "{'name': 'METHODS', 'text': 'Demographic and healthcare system data.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "d811670c-5709-422f-a199-e8e9debd865c\n",
      "{'name': 'METHODS', 'text': 'The 2018 population sizes were retrieved from the China Statistics Yearbook 31 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "51815a2b-eb92-4a67-823b-27369b7480a0\n",
      "{'name': 'METHODS', 'text': 'This metric accounts for migrant population, and thus is expected to may fluctuate during the holiday seasons.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "82f69820-086a-48f6-9879-d777e042aea6\n",
      "{'name': 'METHODS', 'text': 'The geographic boundaries of prefectures and province-level cities were obtained from the Institute of Geographic Sciences and Natural Resources Research (Chinese Academy of Sciences) 32 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "5508e396-9e52-4237-9c45-2bb81fbcc5eb\n",
      "{'name': 'METHODS', 'text': 'The original source of daily confirmed incidence is the COVID-19 dashboard published by DXY.cn, which updates in near-real time based on government press releases 33 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "1781f2bc-5c2b-47ce-90eb-784a23528357\n",
      "{'name': 'METHODS', 'text': \"In addition, the package 'nCoV2019' 34 and 'DXY-COVID-19-Crawler' 35 have reduced the time required for data gathering and data cleaning.\"}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "f59b5da6-6490-407c-a7d7-a38dd0a5d17e\n",
      "{'name': 'METHODS', 'text': 'Records of first case arrivals were cross-checked with news articles also found throughon DXY.cn 33 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "0f47d17d-fb52-475d-acb5-6cc8ed431a8c\n",
      "{'name': 'METHODS', 'text': 'Information on the Grade II and III hospitals in China was retrieved from the National Health Commission 36 and was then georeferenced using the non-commercial Amap API 37 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "dca47fc4-4d49-4ace-9db7-682cd5c49462\n",
      "{'name': 'METHODS', 'text': 'Time series analysis and surge evaluation.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "65f3a9d2-c083-45a1-8bbf-ffffff820cef\n",
      "{'name': 'METHODS', 'text': 'The patterns of movement out of Wuhan between 1st and 23rd January were analysed using cluster analysis of the magnitude-normalised timeseries of outflow over time.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "87cf3ab7-b765-4686-b1aa-39a9094f5757\n",
      "{'name': 'METHODS', 'text': 'Outflow timeseries were selected using a threshold of journeys with an average flow index greater than 0.005 for the entire period.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "c8e6803e-22d4-4fc4-83c8-f0de13d336e9\n",
      "{'name': 'METHODS', 'text': 'This threshold removed prefectures with negligible connectivity with the origin.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "b4ff6c3f-4c05-46b0-a258-63bb66b5d0d5\n",
      "{'name': 'METHODS', 'text': 'In order to characterise the shape of the outflow from Wuhan, rather than the magnitude of certain outflows, we calculated the normalised flow, N, between origin (i) and destination (j) prefectures on each day (t), by dividing the outflow measured by the travel index T, by the total movement between the 1st and 23rd January 2020, as: N ij;t ¼ T ij;t P t¼23 t¼1 T ij;tð3Þ We classified the time series using k-means clustering with four clusters 38 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "8a1a085c-438d-4c87-be1e-19e2b8d599f2\n",
      "{'name': 'METHODS', 'text': 'The number of clusters was chosen using a plot of average silhouette width against number of clusters, for between 4 and 12 clusters.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "3123e0a2-374a-44bf-83bb-7c1a5072e45c\n",
      "{'name': 'METHODS', 'text': 'The silhouette width decreased significantly at four clusters, and a similar number of time series were allocated to each cluster ( Supplementary Figs.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "5569cbb0-cf98-4c31-adad-8280f637e020\n",
      "{'name': 'METHODS', 'text': '1-5).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "fc168f69-7435-4027-924c-d764fc18ded3\n",
      "{'name': 'METHODS', 'text': 'Furthermore, when using a greater number of clusters, we observed the same four overall temporal patterns with smaller differences between time series defining each cluster.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "3d48676a-2b79-4fe0-bece-a0cc9a912637\n",
      "{'name': 'METHODS', 'text': 'We also observed an increasingly large number of clusters containing a small number of time series.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "9ded5250-c14c-4925-92a8-ce322b785e91\n",
      "{'name': 'METHODS', 'text': 'Plots of the time series clustered using 2, 3, 4, 5 and 6 clusters are included in Supplementary Figs.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "c428f656-b035-431b-afda-3de53913e4bc\n",
      "{'name': 'METHODS', 'text': '1-5.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "ffa8720a-ca6e-490b-b01b-ad0a3d2c9ddf\n",
      "{'name': 'METHODS', 'text': 'K-medioids, and Agglomerative Clustering were also explored as alternatives to K-means clustering.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "19613f58-d6e4-4066-b2a3-e269c425b7f5\n",
      "{'name': 'METHODS', 'text': 'The different clustering methods did not result in substantial differences and identified similar patterns among outflow time series.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "4d4f9234-731d-4736-bc58-b43062955654\n",
      "{'name': 'METHODS', 'text': 'We quantified the peak outflow from each prefecture in the five-day window before LNY (i.e., two to seven days before LNY, zero to five days before the cordon sanitaire).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "48172b8f-98e0-49d8-9c0e-2fcb56b5b84a\n",
      "{'name': 'METHODS', 'text': 'We used two parameters to characterise the magnitude of the change in outflow in 2020 compared to 2019 in each prefecture i: V 1;i ¼ mean F i;τ 2020 mean F i;τ 2019 À 1ð4Þ V 2;i ¼ mean F i;τ 2020 À mean F i;τ 2019 std F i;τ 2019ð5Þ where F i,τ is the total Baidu outflow from prefecture i in the time period τ. τ in 2019 corresponds to 29 January-3 February 2019, and in 2020 corresponds to 18 January-23 January.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "5ea844e5-dbe4-4bb6-953b-8656544d598a\n",
      "{'name': 'METHODS', 'text': 'The dates are different each year because they are aligned to the date of LNY in 2019 and 2020.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "834c400a-c8b8-4f50-8831-55be25af57e5\n",
      "{'name': 'METHODS', 'text': 'The Relationship between First Case Detection and Cluster Membership: We explored the association between average population size and first case detection for prefectures in each cluster.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "38978208-876d-4bc6-900c-ebd36275d74e\n",
      "{'name': 'METHODS', 'text': 'There is potential confounding due to surveillance bias such that larger prefectures may detect COVID-19 cases earlier due to better public health infrastructure resulting in earlier and greater use of diagnostic tests.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "52ec7c4f-c0a1-44f9-8376-772326078c81\n",
      "{'name': 'METHODS', 'text': 'However, there is no intuitive indicator that can capture surveillance efforts, and therefore we used population size as a proxy for surveillance effort.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "91258ddd-3663-44d2-9b9c-809fe9cfe73a\n",
      "{'name': 'METHODS', 'text': 'The implicit assumption is that places with larger populations are more equipped for detecting COVID-19, which is supported because early testing capacity relied on biosafety level 2+ laboratories, which are only found in large hospitals and universities 39 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "8171b43c-55c9-4934-b162-1aac732f2bea\n",
      "{'name': 'METHODS', 'text': 'We adjust for this potential confounding effect using a linear regression model: Detection date $ pop ðcluster membershipÞ ð 6Þ where pop represents the prefecture level population size as of 2018 and (Cluster membership) is a nominal unordered categorical variable with levels A through D. Assessing the healthcare capacity and COVID-19-related healthcare pressure.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "b65b91a0-d9cb-4e07-825e-490fb58623c1\n",
      "{'name': 'METHODS', 'text': 'In this study, prefecture-level healthcare capacity was measured by the number of Grade II and III hospitals per 100,000 residents.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "5e6cd7e8-ff0a-4d04-b968-ad4d9dede9d8\n",
      "{'name': 'METHODS', 'text': 'In mainland China, Grade II and III hospitals have 100-499 or 500+ hospital beds, respectively, and are equipped with ventilators 40 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "b170aea1-d233-437e-817c-9bc8702098fc\n",
      "{'name': 'METHODS', 'text': 'Thus, they are more important compared to community hospitals and clinics for COVID-19 management.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "ef0fec21-a654-4f7b-bdb7-801585a319c4\n",
      "{'name': 'METHODS', 'text': 'Healthcare capacity in prefecture i (HC i ), therefore, can be expressed as: HC hospital;i Pop residential;ið7Þ where n hospital,i is the number of Grade II and III hospitals in prefecture i, and Pop residential,i is the residential population of prefecture i.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "7917c080-031d-4349-9507-ea33e590d504\n",
      "{'name': 'METHODS', 'text': 'We use the size of the residential population in 2018 from the China Statistics Yearbook 29 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "f672ff5e-517f-46de-8ac2-ce976cf8e1c5\n",
      "{'name': 'METHODS', 'text': 'HC i is stratified into high and low by taking the upper and lower 50% of prefectures with available data.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "88f967bf-aeec-4687-865b-42875db14df0\n",
      "{'name': 'METHODS', 'text': 'Note that this metric cannot accurately reflect the prefecture level population sizes during LNY due to population movement.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "c31e72c4-a1f6-45fd-a59d-c345764e128d\n",
      "{'name': 'METHODS', 'text': 'For example, the residential population size of Beijing is approximately 22 million, and over 10 million left the city for LNY 41 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "c383ec29-4f7a-4bab-9ee6-8df4f951e41a\n",
      "{'name': 'METHODS', 'text': 'Healthcare pressure in prefecture i during week w (Hp i,w ) was calculated by dividing weekly confirmed COVID-19 cases 31 by the healthcare capacity: HP i;w ¼ n confirmed;w HC ið8Þ where n confirmed,w is the number of confirmed COVID-19 cases during week w. We also performed a sensitivity analysis on the metric and considered an alternative measure of healthcare capacity that did not adjust for the background residential population sizes: HC hospital;ið9Þ The distributions of healthcare pressure were non-Gaussian.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "486eedb9-897b-4e94-bace-87ac3f9a5e2e\n",
      "{'name': 'METHODS', 'text': 'We therefore used non-parametric one-tailed Mann-Whitney U tests to compare the differences of healthcare pressure between low and high healthcare capacity settings.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "12b16185-f5bf-4d37-8489-96216c4b02e5\n",
      "{'name': 'METHODS', 'text': 'The null hypothesis was that the healthcare pressures in low healthcare capacity settings are comparable to that in high healthcare capacity settings; the alternative hypothesis was that healthcare pressures in low healthcare capacity settings are higher than those in high healthcare capacity settings (n1 = 157, n2 = 153).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "0a87cd72-a00a-4bdb-b048-f596252ede49\n",
      "{'name': 'METHODS', 'text': 'This test was repeated for each week from week three to nine (i.e., starting on 15 Jan 2020).'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "ac2dfb42-eba5-42b9-9d53-69fdc697425b\n",
      "{'name': 'METHODS', 'text': 'Results were verified using two-tailed Mann-Whitney U tests, as well as one-tailed Mann-Whitney U tests with the opposite null hypotheses.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "eb6d73d0-c2aa-4e9a-aea9-64f35c004de6\n",
      "{'name': 'METHODS', 'text': 'Network analysis.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "f6564191-cdce-4c08-9606-ba4cb231400e\n",
      "{'name': 'METHODS', 'text': 'Using the weighted movement flows between locations, we calculated community structure in the network using the Leiden algorithm 20 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "9381e7bc-99a1-4cce-ad52-9395d1588d1d\n",
      "{'name': 'METHODS', 'text': 'The Leiden algorithm maximises the modularity, Q, on directed, weighted, time sliced NATURE COMMUNICATIONS | ARTICLE networks with an inter-slice weighting of 10 −5 , which is the order of magnitude of minimum intra-slice weight across all times 42 .'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "bc944d82-aba9-4fdf-b06f-1e66c78fe9b2\n",
      "{'name': 'METHODS', 'text': 'Modularity is a metric of withincommunity vs. between-community connectivity, and the algorithm detects communities by optimising the within vs. between, thereby assigning nodes to communities.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "7df3398c-a82e-42af-8335-84db88d55cc0\n",
      "{'name': 'METHODS', 'text': 'Using the community structure from this algorithm, we identified the relative contributions to modularity, Q, of 4 key communities: the community containing Wuhan prefecture, and then the communities of four other major cities in China: Beijing, Shanghai, Guangzhou, and Shenzhen.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "4f1814d8-3922-447a-8d9d-f945675f45da\n",
      "{'name': 'METHODS', 'text': 'The latter two were always assigned to the same community and are marked together in Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "a7b0e6ad-064c-4aa0-b964-8151deb59dbf\n",
      "{'name': 'METHODS', 'text': '4.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "4c0d8c42-da24-4df4-8c30-cd26332534f5\n",
      "{'name': 'METHODS', 'text': 'We presented 4 snapshots of communities in the travel network, but all are shown in Supplementary Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "9ebf60dd-a78a-4d9c-877f-24153c071e5f\n",
      "{'name': 'METHODS', 'text': '17, and the spatial locations of those networks in Supplementary Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "9aafdc3b-a75f-40f1-9737-8360055b970f\n",
      "{'name': 'METHODS', 'text': '18.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "1a1ce382-754f-40ad-b7a8-be5dd0f7c976\n",
      "{'name': 'METHODS', 'text': 'Distance Kernels.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "4fc0e368-cc74-406e-80b2-95b763c3d009\n",
      "{'name': 'METHODS', 'text': 'To determine how the relationship between distance and travel flow changed over Chunyun and in response to the cordon sanitaire, we calculated the frequency of journeys of at least distance n kilometres, for n up to the maximum distance 4185 km, on each day of the study period.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "5102b2ac-b5f2-4e75-9192-a89c02ae56c4\n",
      "{'name': 'METHODS', 'text': 'These plots are shown for Beijing, Guangzhou, Shanghai and Wuhan, for both inflow and outflow in Supplementary Fig.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "5222bcd0-9f95-4d61-b1e5-2814bd6acb7e\n",
      "{'name': 'METHODS', 'text': '14.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "14d9a2cc-25fb-4f28-882f-c7027b8da353\n",
      "{'name': 'METHODS', 'text': 'Sensitivity analyses.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "d2ecb7d1-4864-4d2c-810d-c130ddf26c41\n",
      "{'name': 'METHODS', 'text': 'We repeated clustering of temporal traveller flow time series to validate the method for assessing travel flux out of Wuhan between January 1st and January 23rd.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "3b449bf5-0a04-4f08-81dc-8be3339e24a9\n",
      "{'name': 'METHODS', 'text': 'Employing the same method of thresholding prefectures with little connectivity, the volume of travel to individual destination locations over time were normalised by dividing by the total flow along each route in the period.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "b656d91e-8023-4d22-95c0-0d04b4d53d53\n",
      "{'name': 'METHODS', 'text': 'These normalised time series were then clustered using the same k-means clustering procedure discussed above.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "a0dd5c51-7653-4037-a9e1-200078dbb5e1\n",
      "{'name': 'METHODS', 'text': 'The number of clusters was determined using a silhouette plot in order to isolate the dominant temporal patterns of traveller movement to individual destinations.'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "43611b8d-6ace-49e6-a52c-6af4eb4d0bef\n",
      "{'name': 'TAB_1', 'text': 'Net change by migration index 0 −10'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "22d1c345-766e-4b9a-8761-20c71542acc9\n",
      "{'name': 'TAB_1', 'text': '0 −20'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "1dd50bbd-c429-4458-9862-f314da700f94\n",
      "{'name': 'TAB_1', 'text': '0 0.03 0.10 0.30 1.00 3.00 0.03 0.10 0.30 1.00 3.00'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "8afc2ff3-9393-49b9-997b-0012ce6bc07f\n",
      "{'name': 'TAB_1', 'text': '0 Number of hospitals per 100,000'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "15c128ea-ad34-4426-84c7-38e2dbe130f8\n",
      "{'name': 'TAB_1', 'text': '0 Low access to health care setting High access to healthcare setting'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "ba32bc53-c9b9-4005-9677-1af48e2811df\n",
      "{'name': 'TAB_1', 'text': '10,000 0'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "3069d3df-d629-4b5d-a6e1-3cafe7daa8fb\n",
      "{'name': 'TAB_1', 'text': '0 1000'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "15f311a9-04bc-4db2-8983-8b7eed25cbfa\n",
      "{'name': 'TAB_1', 'text': '0 100'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "4b616cfd-70e5-4088-a4f0-0e9d8ea74b5e\n",
      "{'name': 'TAB_1', 'text': '0 10'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "6664c2d4-e69c-4f88-b477-3bf16d676d61\n",
      "{'name': 'TAB_1', 'text': '0 1'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "6fe2d5a1-0aab-440f-abbd-b6148262ef1f\n",
      "{'name': 'TAB_1', 'text': '0 3 4 5 6 7 8 9 3 4 5 6 7 8 9'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "8cec6b08-8384-47ec-ac07-42e6c4fe1990\n",
      "{'name': 'TAB_1', 'text': '0 01−15 01−22 01−29 02−05 02−12 02−19 02−26 01−15 01−22 01−29 02−05 02−12 02−19 02−26'}\n",
      "author\n",
      "649bf9d6-72ba-4d84-a8e9-dc9cfbca8427\n",
      "paper\n",
      "ee4a300a-5750-4907-bc63-fcc326311606\n",
      "yext_uuid\n",
      "8174cc8a-8886-470d-b49e-cd1ef2b279a4\n"
     ]
    }
   ],
   "source": [
    "c.ingest_data(\"/home/cesar/Projects/Lammps_agent/test/tei.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "author = c.client.collections.get(\"Author\")\n",
    "\n",
    "\n",
    "response = author.query.bm25(query=\"Vercelli\", limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryReturn(objects=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/anaconda3/lib/python3.11/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdfa\n",
      "[{'name': 'TITLE', 'text': 'Scaling Instructable Agents Across Many Simulated Worlds SIMA Team: 1'}, {'name': 'ABSTRACT', 'text': ' Google DeepMind unless otherwise noted, authors listed in alphabetical order, contributions listed at end of'}, {'name': 'INTRODUCTION', 'text': 'Despite the impressive capabilities of large language models (Brown et al., 2020;Hoffmann et al., 2022;OpenAI, 2023;Anil et al., 2023;Gemini Team et al., 2023), connecting them to the embodied world that we inhabit remains challenging.Modern AI can write computer programs (Li et al., 2022) or play chess at super-human level (Silver et al., 2018), but the ability of AI to perceive and act in the world remains far below human level.Competence in language alone is easier for AI than grounded perception and behavior, underscoring the well-known paradox that what is easier for AI is harder for humans, and vice versa (Moravec, 1988).Team et al., 2023).Thus, in contrast to prior works (e.g., Abramson et al., 2020;Vinyals et al., 2019;Berner et al., 2019;Lifshitz et al., 2023), we are attempting to tackle this problem across many simulated environments, in the most general and scalable way possible, by making few assumptions beyond interacting with the environments in the same way as humans do.'}, {'name': 'INTRODUCTION', 'text': 'To this end, have made a number of design decisions that make our approach more general, but also more challenging: • We incorporate many rich, visually complex, open-ended video games containing hundreds of objects in a scene and a large number of possible interactions.• These environments are asynchronous (e.g., Berner et al., 2019;Vinyals et al., 2019); unlike many research environments, they do not stop and wait while the agent computes its next action.'}, {'name': 'INTRODUCTION', 'text': '• Each instance of a commercial video game needs to run on a GPU; thus, we cannot run hundreds or thousands of actors per game per experiment as often done in RL (cf., Espeholt et al., 2018).• Agents receive the same screen observations that a human playing the game would without access to internal game state, rewards, or any other privileged information (cf., Berner et al., 2019;Vinyals et al., 2019).• To interact with the environments, agents use the same keyboard-and-mouse controls that humans do (e.g., Baker et al., 2022;Humphreys et al., 2022;Lifshitz et al., 2023), rather than handcrafted action spaces or high-level APIs.• We focus on following language instructions (e.g., Abramson et al., 2020) rather than simply playing the games to maximize a win-rate or generating plausible behavior (cf., Berner et al., 2019;Vinyals et al., 2019).• We train and test our agents using open-ended natural language, rather than simplified grammars or command sets (e.g., Abramson et al., 2020).'}, {'name': 'INTRODUCTION', 'text': 'These design choices make the learning problem harder, but their generality makes expanding to new environments easier: agents use the same interface across environments without requiring a custom design of control and observation spaces for each new game.Furthermore, since the agent-environment interface is human compatible, it allows agents the potential to achieve anything that a human could, and allows direct imitation learning from human behavior.This general interface from language instructions to embodied behavior can also enable agents to transfer previously learned skills zero-shot to never-before-seen games.Doing research in generic virtual environments allows us to test our agents in a broad and challenging range of situations-where the lessons learned are likely to be more applicable to real-world applications with visually rich perception and control such as robotics-without the risks and costs of real-world testing: if the agent crashes a spaceship in a video game, we can just restart the game.'}, {'name': 'INTRODUCTION', 'text': 'In the SIMA project thus far, we have created an agent that performs short-horizon tasks based on language instructions produced by a user; though instructions could also be produced by a language model (e.g., Jiang et al., 2019;Driess et al., 2023;Wang et al., 2023b;Hu et al., 2023;Ajay et al., 2023).We have a portfolio of over ten 3D environments, consisting of research environments and commercial video games.For research environments we evaluate agents using the ground truth state, but commercial video games are not designed to report on the completion of arbitrary language tasks.We have therefore developed a variety of methods for evaluation in video games, including using optical character recognition (OCR) to detect onscreen text describing task completion, and using human evaluation of recorded videos of agent behavior.In the rest of this tech report, we describe the high-level approach (illustrated in Figure 1) and our initial progress towards the ultimate goal of SIMA: developing an instructable agent that can accomplish anything a human can do in any simulated 3D environment.'}, {'name': 'RELATED WORK', 'text': 'SIMA builds on a long history of using games as a platform for AI research.For example, backgammon provided the initial proving ground for early deep reinforcement learning methods (Tesauro et al., 1995), and later works have achieved superhuman performance even in complex board games like Go (Silver et al., 2016(Silver et al., , 2018)).'}, {'name': 'RELATED WORK', 'text': 'Video games Over the last ten years, video games have provided an increasingly important setting for research focused on embodied agents that perform visuomotor control in rich environments.Researchers have used many video game environments, covering a wide spectrum from Atari (Bellemare et al., 2013) to DoTA (Berner et al., 2019) and StarCraft II (Vinyals et al., 2019).In SIMA, however, we restrict our focus to games that resemble 3D physical embodiment most closely, in particular games where the player interacts with a 3D world from a first or over-the-shoulder pseudo-first-person view.This focus excludes many of the games which have previously been used for research, such as the ones listed above.There has however been notable interest in first-person embodied video games as a platform for AI research (Johnson et al., 2016;Tessler et al., 2017;Guss et al., 2019;Pearce and Zhu, 2022;Hafner et al., 2023;Durante et al., 2024;Tan et al., 2024).These video game AI projects have driven the development of many innovative techniques, e.g., learning from videos by annotating them with estimated player keyboard-and-mouse actions using inverse dynamics models (Pearce and Zhu, 2022;Baker et al., 2022).More recently, games that offer API access to the environment have served as a platform for grounding large language models (Wang et al., 2023a), and some works have even considered grounding a language model in a game through direct perception and action of a lower-level controller (Wang et al., 2023b).Instead of focusing on a single game or environment, however, SIMA considers a range of diverse games to train agents on a larger variety of content.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': 'Other works have focused on custom, controlled environments designed for research.Many of these environments focus on particular domains of real-world knowledge.For example, AI2-THOR (Kolve et al., 2017), VirtualHome (Puig et al., 2018), ProcTHOR (Deitke et al., 2022), AI Habitat (Savva et al., 2019;Szot et al., 2021;Puig et al., 2023), ALFRED (Shridhar et al., 2020), and Behavior (Srivastava et al., 2021) simulate embodied agents behaving in naturalistic rendered scenes.CARLA (Dosovitskiy et al., 2017) provides a simulator for autonomous driving.MuJoCo (Todorov et al., 2012), PyBullet (Coumans and Bai, 2016-2023), and Isaac Gym (Makoviychuk et al., 2021) provide high quality physics simulators for learning low-level control and are used by benchmarks for robotic manipulation such as Meta-World (Yu et al., 2020) and Ravens (Zeng et al., 2021).Albrecht et al.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': '(2022) propose a unified environment encompassing a variety of skills afforded through ecologically-inspired interactions.The Playhouse (Abramson et al., 2020;DeepMind Interactive Agents Team et al., 2021;Abramson et al., 2022a) and WorldLab (e.g., Gulcehre et al., 2019) environments are built using Unity (see Ward et al., 2020).Open Ended Learning Team et al.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': '(2021) and Adaptive Agent Team et al.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': '(2023) also use Unity to instantiate a broad distribution of procedurally generated tasks with shared underlying principles.For the results in this work, we also use Playhouse, WorldLab, and ProcTHOR.In addition, we introduce a new environment, called the Construction Lab.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': 'Robotics Robotics is a key area for research in embodied intelligence.A variety of robotics projects have used simulations for training, to transfer efficiently to real-world robotic deployments (Höfer et al., 2021), though generally within a single, constrained setting.More recent work has focused on environment-generality, including scaling robotic learning datasets across multiple tasks and embodiments (Brohan et al., 2022(Brohan et al., , 2023a;;Stone et al., 2023;Padalkar et al., 2023)-thereby creating Vision-Language-Action (VLA) models (Brohan et al., 2023a), similar to the SIMA agent.The latter challenge of generalizing or quickly adapting to new embodiments has some parallels to acting in a new 3D environment or computer game where the mechanics are different.Moreover, a variety of recent works have applied pretrained (vision-)language models as a planner for a lower-level instruction-conditional robotic control policy (Brohan et al., 2023b;Driess et al., 2023;Vemprala et al., 2023;Hu et al., 2023).Our approach shares a similar philosophy to the many works that attempt to ground language via robotics.SIMA, however, avoids the additional challenges of costly hardware requirements, resource-intensive data collection, and the practical limitations on diversity of real-world evaluation settings.Instead, SIMA makes progress towards embodied AI by leveraging many simulated environments and commercial video games to obtain the sufficient breadth and richness that we conjecture to be necessary for effectively scaling embodied agents-with the hope that lessons learned (and possibly even the agents themselves) will be applicable to robotic embodiments in the future.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': 'Learning environment models Some works attempt to leverage learned models of environments to train agents in these learned simulations (e.g., Ha and Schmidhuber, 2018;Hafner et al., 2020Hafner et al., , 2023;;Yang et al., 2023).These methods, however, tend to be difficult to scale to diverse sets of visually complex environments that need to be self-consistent across long periods of time.Nevertheless, learning imperfect models can still be valuable.In SIMA, we build on video models (Villegas et al., 2022), which we fine-tune on game environments.However, we only use the internal state representations of the video models rather than explicit rollouts-in keeping with other approaches that use generative modeling as an objective function for learning state representations (e.g., Gregor et al., 2019;Zolna et al., 2024).'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': 'Grounding language Another stream of work-overlapping with those above-has focused on grounding language in simulated 3D environments, through agents that are trained in controlled settings with semi-natural synthetic language (Hermann et al., 2017;Hill et al., 2019), or by imitating human interactions in a virtual house to learn a broader ability to follow natural language instructions (Abramson et al., 2020;DeepMind Interactive Agents Team et al., 2021;Abramson et al., 2022a,b).Moreover, a range of recent works develop agents that connect language to embodied action, generally as part of a hierarchy controlled by a language model (Jiang et al., 2019;Driess et al., 2023;Wang et al., 2023b;Hu et al., 2023;Ajay et al., 2023).We likewise draw inspiration from the idea that language is an ideal interface for directing an agent, but extend our scope beyond the limited affordances of a single controlled environment.In that sense, SIMA overlaps more with several recent works (Reed et al., 2022;Huang et al., 2023;Durante et al., 2024) that also explore training a single model to perform a broad range of tasks involving actions, vision, and language.However, SIMA is distinct in our focus on simultaneously (1) taking a language-first perspective, with all training experiences being language-driven; (2) adopting a unified, human-like interface across environments with language and vision to keyboard-and-mouse control; and (3) exploring a broad range of visually rich, diverse, and human-compatible environments that afford a wide range of complex skills.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': 'Language supports grounded learning, and grounded learning supports language A key motivation of SIMA is the idea that learning language and learning about environments are mutually reinforcing.A variety of studies have found that even when language is not necessary for solving a task, learning language can help agents to learn generalizable representations and abstractions, or to learn more efficiently.Language abstractions can accelerate grounded learning, for example accelerating novelty-based exploration in reinforcement learning by providing better state abstractions (Tam et al., 2022;Mu et al., 2022), or composing known goals into new ones (Colas et al., 2020;Nottingham et al., 2023).Moreover, learning to predict natural-language explanations (Lampinen et al., 2022), descriptions (Kumar et al., 2022), or plans (Hu and Clune, 2023) can help agents to learn more efficiently, and to generalize better out of distribution.Language may be a powerful tool for shaping agent capabilities (Colas et al., 2022).'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': 'Conversely, richly grounded learning can also support language learning.Since human language use is deeply integrated with our understanding of grounded situations (McClelland et al., 2020), understanding the subtleties of human language will likely benefit from this grounding.Beyond this theoretical argument, empirical evidence shows that grounding can support even fundamental kinds of generalization- Hill et al.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': \"(2019) show that agents grounded in richer, more-embodied environments exhibit more systematic compositional generalization.These findings motivate the possibility that learning both language and its grounding will not only improve grounded actions, but improve a system's knowledge of language itself.\"}, {'name': 'APPROACH', 'text': 'Many overlapping areas of previous and concurrent work share some of our philosophy, motivations, and approaches.What distinguishes the SIMA project is our focus on language-conditional behavior across a diverse range of visually and mechanically complex simulated environments that afford a rich set of skills.In this section, we provide a high-level overview of our approach: our environments, data, agents, and evaluations.'}, {'name': 'ENVIRONMENTS', 'text': \"SIMA aims to ground language across many rich 3D environments (Figure 2).Thus, we selected 3D embodied environments that offer a broad range of open-ended interactions-such environments afford the possibility of rich and deep language interactions.We focus on environments that are either in a) first-person or b) third-person with the camera over the player's shoulder.To achieve diversity and depth of experience, we use a variety of commercial video games, as well as several environments created specifically for agent research.Each type of environment offers distinct advantages, ranging from open-ended diverse experiences to targeted assessments of agent skills.We have deliberately sought to build a portfolio of games that covers a wide range of settings-from mundane tasks in semi-realistic environments, to acting as a mischevious goat in a world with exaggerated physics, to exploring mythological worlds or science-fiction universes.Below, we briefly describe the environments we have used in SIMA thus far by category and in alphabetical order.\"}, {'name': 'COMMERCIAL VIDEO GAMES', 'text': 'Commercial video games offer exciting, open-ended worlds full of visual richness and the potential for complex interactions.In SIMA, we have partnered with games developers whose games we used for training agents, and we are continuing to develop relationships with new developers-for our full list of current partners, please see our Acknowledgements section.We focus on a variety of open-world or sandbox games that contain diverse skills, while avoiding games containing harmful content such as extreme violence or biases.We have also sought a broad diversity of worlds and stories, but with a focus on games that exhibit a depth of interesting mechanics.Accordingly, games from our portfolio offer a wide range of distinct challenges in perception and action, from flying a spaceship to mining minerals or crafting armor, as well as more common core features, such as navigation or gathering resources.Games also often include interactions that extend beyond the skillset of typical embodied research environments, such as menu use and interfaces more similar to those faced in computer control benchmarks (e.g., Humphreys et al., 2022;Koh et al., 2024).For the results in this report, we focus on single-player interactions within these games.'}, {'name': 'COMMERCIAL VIDEO GAMES', 'text': 'We run instances of each game in a secure Google Cloud environment, using hardware accelerated rendering to a virtual display.This display is streamed to a browser for human gameplay, or to a remote agent client process during evaluation.To instantiate repeatable evaluation or data collection scenarios within each game, we build datasets of save-game files from expert play, and use scripted processes to automate the process of installing game-files, booting the game, navigating its main menu, and loading a specific save-game.'}, {'name': 'COMMERCIAL VIDEO GAMES', 'text': 'We now provide a brief description of the games we used.'}, {'name': 'GOAT SIMULATOR 3:', 'text': 'A third-person game where the player is a goat in a world with exaggerated physics.The player can complete quests, most of which involve wreaking havoc.The goat is able to lick, headbutt, climb, drive, equip a wide range of visual and functional items, and perform various other actions.Throughout the course of the game, the goat unlocks new abilities, such as the ability to fly.'}, {'name': 'GOAT SIMULATOR 3:', 'text': 'Hydroneer: A first-person mining and base building sandbox where the player is tasked with digging for gold and other resources to turn a profit and enhance their mining operation.To do this, they must build and upgrade their set-ups and increase the complexity and levels of automation until they have a fully automated mining system.Players can also complete quests from non-player characters to craft bespoke objects and gain extra money.Hydroneer requires careful planning and managing of resources.'}, {'name': \"NO MAN'S SKY:\", 'text': \"A first-or third-person survival game where the player seeks to explore a galaxy full of procedurally-generated planets.This involves flying between planets to gather resources, trade, build bases, and craft items that are needed to upgrade their equipment and spaceship while surviving a hazardous environment.No Man's Sky includes a large amount of visual diversity-which poses important challenges for agent perception-and rich interactions and skills.\"}, {'name': \"NO MAN'S SKY:\", 'text': 'Satisfactory: A first-person, open-world exploration and factory building game, in which players attempt to build a space elevator on an alien planet.This requires building increasingly complex production chains to extract natural resources and convert them into industrial goods, tools, and structures-whilst navigating increasingly hostile areas of a large open environment.'}, {'name': \"NO MAN'S SKY:\", 'text': \"Teardown: A first-person, sandbox-puzzle game in a fully destructible voxel world where players are tasked with completing heists to gain money, acquiring better tools, and undertaking even more high-risk heists.Each heist is a unique scenario in one of a variety of locations where players must assess the situation, plan the execution of their mission, avoid triggering alarms, and escape before a timer expires.Teardown involves planning and using the environment to one's advantage to complete the tasks with precision and speed.\"}, {'name': \"NO MAN'S SKY:\", 'text': 'Valheim: A third-person survival and sandbox game in a world inspired by Norse mythology.Players must explore various biomes, gather resources, hunt animals, build shelter, craft equipment, sail the oceans and defeat mythological monsters to advance in the game-while surviving challenges like hunger and cold.'}, {'name': \"NO MAN'S SKY:\", 'text': 'Wobbly Life: A third-person, open-world sandbox game where the player can explore the world, unlock secrets, and complete various jobs to earn money and buy items, leading up to buying their own house.They must complete these jobs whilst contending with the rag-doll physics of their characters and competing against the clock.The jobs require timing, planning, and precision to be completed.The world is extensive and varied, with a diverse range of interactive objects.'}, {'name': 'CONSTRUCTION LAB', 'text': 'Figure 2 | Environments.We use over ten 3D environments in SIMA, consisting of commercial video games and research environments.The diversity of these environments is seen in their wide range of visual observations and environmental affordances.Yet, because these are all 3D environments, basic aspects of 3D embodied interaction, such as navigation, are shared.Commercial video games offer a higher degree of rich interactions and visual fidelity, while research environments serve as a useful testbed for probing agent capabilities.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': 'In contrast to commercial video games, AI research environments are typically more controllable, offering the ability to instill and carefully assess particular skills, and more rapid and reliable evaluations of task completion.Unlike many of the games in our portfolio, several of these research environments also tend to feature more real-world analogous-if still simplified-physical interactions.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': 'We have drawn on several prior research environments and developed a new environment-the Construction Lab-that incorporates important challenges which were not otherwise well-captured by our other environments.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': 'Construction Lab: A new research environment where agents need to build novel items and sculptures from interconnecting building blocks, including ramps to climb, bridges to cross, and dynamic contraptions.Construction Lab focuses on cognitive capabilities such as object manipulation and an intuitive understanding of the physical world.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': 'Playhouse: An environment used in various prior works (Abramson et al., 2020;DeepMind Interactive Agents Team et al., 2021;Abramson et al., 2022a), consisting of a procedurally-generated house environment with various objects.We have augmented this environment with improved graphics and richer interactions, including skills like cooking or painting.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': 'ProcTHOR: An environment consisting of procedurally-generated rooms with realistic contents, such as offices and libraries, introduced by Deitke et al.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': '(2022).Although benchmark task sets exist in this environment, prior works have not used keyboard and mouse actions for agents; thus we focus on this environment primarily for data collection rather than evaluation.'}, {'name': 'RESEARCH ENVIRONMENTS', 'text': 'WorldLab: An environment used in prior work (e.g., Gulcehre et al., 2019), further specialized for testing embodied agents by using a limited set of intuitive mechanics, such as sensors and doors, and relying primarily on the use of simulated physics on a range of objects.The SIMA dataset includes a broad range of text instructions that can be roughly clustered into a hierarchy.Due to the common 3D embodied nature of the environments that we consider, many generic tasks, such as navigation and object manipulation, are present in multiple environments.Categories were derived from a data-driven hierarchical clustering analysis of the human-generated text instructions within a fixed, pretrained word embedding space.Note that the area of each cluster in the wheel in Figure 3 does not correspond to the exact number of instructions from that cluster in the dataset.'}, {'name': 'DATA', 'text': 'Our approach relies on training agents at scale via behavioral cloning, i.e., supervised learning of the mapping from observations to actions on data generated by humans.Thus, a major focus of our effort is on collecting and incorporating gameplay data from human experts.This includes videos, language instructions and dialogue, recorded actions, and various annotations such as descriptions or marks of success or failure.These data constitute a rich, multi-modal dataset of embodied interaction within over 10 simulated environments, with more to come.'}, {'name': 'DATA', 'text': '1 Our data can be used to augment and leverage existing training data (e.g., Abramson et al., 2020), or to fine-tune pretrained models to endow them with more situated understanding.These datasets cover a broad range of instructed tasks: Figure 3 shows instruction clusters derived from hierarchically clustering the text instructions present in the data within a fixed, pretrained word embedding space.'}, {'name': 'DATA', 'text': 'Yet, collecting data at scale is not sufficient for training successful agents.Data quality processes 1 Note: Due to a limited amount of collected data and/or evaluations, we present agent evaluation results (Section 4) on a subset of 7 of these environments.are critical to ensuring an accurate and unconfounded mapping between language and behavior.This presents various technical challenges.We take care to engineer our data collections, including preprocessing and filtering the raw data, to highlight important skills and effectively train our agents.'}, {'name': 'DATA COLLECTIONS', 'text': 'We collect data using a variety of methods, including allowing single players to freely play, and then annotating these trajectories with instructions post-hoc.We also perform two-player setter-solver collections (Abramson et al., 2020;DeepMind Interactive Agents Team et al., 2021), in which one player instructs another what to do in selected scenarios while sharing a single player view in order to match the single-player collections.All our data collections were performed with participants contracting with Google.The full details of our data collection protocols, including compensation rates, were reviewed and approved by an independent Human Behavioral Research Committee for ethics and privacy.All participants provided informed consent prior to completing tasks and were reimbursed for their time.'}, {'name': 'DATA COLLECTIONS', 'text': 'Preprocessing, filtering, and weighting Before training, we perform a variety of offline preprocessing steps, including resizing data for agent input, filtering out low-quality data using a variety of heuristics, and remixing and weighting data across environments and collections to prioritize the most effective learning experiences.'}, {'name': 'AGENT', 'text': 'The SIMA agent maps visual observations and language instructions to keyboard-and-mouse actions (Figure 4).Given the complexity of this undertaking-such as the high dimensionality of the input and output spaces, and the breadth of possible instructions over long timescales-we predominantly focus on training the agent to perform instructions that can be completed in less than approximately 10 seconds.Breaking tasks into simpler sub-tasks enables their reuse across different settings and entirely different environments, given an appropriate sequence of instructions from the user.'}, {'name': 'AGENT', 'text': 'Our agent architecture builds on prior related work (Abramson et al., 2020(Abramson et al., , 2022a)), but with various changes and adaptations to our more general goals.First, our agent incorporates not only trained-from-scratch components, but also several pretrained models-including a model trained on fine-grained image-text alignment, SPARC (Bica et al., 2024), and a video prediction model, Phenaki (Villegas et al., 2022)-which we further fine-tune on our data through behavioral cloning and video prediction, respectively.In preliminary experiments, we found that these models offer complementary benefits.Combining these pre-trained models with fine-tuning and from-scratch training allows the agent to utilize internet-scale pretraining while still specializing to particular aspects of the environments and the control tasks that it encounters.'}, {'name': 'AGENT', 'text': 'More specifically, our agent (Figure 4) utilizes trained-from-scratch transformers that cross-attend to the different pretrained vision components, the encoded language instruction, and a Transformer-XL (Dai et al., 2019) that attends to past memory states to construct a state representation.The resulting state representation is provided as input to a policy network that produces keyboard-and-mouse actions for sequences of 8 actions.We train this agent with behavioral cloning, as well as an auxiliary objective of predicting goal completion.'}, {'name': 'AGENT', 'text': 'We use Classifier-Free Guidance (CFG; Ho and Salimans, 2022;Lifshitz et al., 2023) to improve the language-conditionality of a trained agent when running it in an environment.CFG was originally proposed for strengthening text-conditioning in diffusion models (Ho and Salimans, 2022), but has also proven useful for similar purposes with language models (Sanchez et al., 2023) and languageconditioned agents (Lifshitz et al., 2023).That is, we compute the policy, , with and without language conditioning, and shift the policy logits in the direction of the difference between the two: = (image, language) + ( (image, language) - (image, •)) .'}, {'name': 'EVALUATION METHODS', 'text': 'Our focus on generality in SIMA introduces challenges for evaluation.While research environments may provide automated methods for assessing whether language-following tasks have been successfully completed, such success criteria may not be generally available.That is, language instructions may not correspond to goal states recorded by an environment (e.g.'}, {'name': 'EVALUATION METHODS', 'text': 'a user might instruct \"make a pile of rocks to mark this spot\" or \"see if you can jump over this chasm\").'}, {'name': 'EVALUATION METHODS', 'text': 'Evaluating agents in commercial video games poses substantial additional challenges.Video game evaluations cannot rely on access to privileged information about the state of an environment.Additionally, it is difficult to reinstate agents in precisely the same state in environments that are not designed as reproducible benchmarks, and loading each task in commercial video games is considerably slower and more costly than those in research environments.Achieving fast, stable, and reliable evaluations comparable across environments is thus challenging.We therefore use a range of distinct evaluation types that provide different trade-offs in efficiency, cost, accuracy, and coverage.Moreover, ensuring that our evaluations truly assess language conditionality, rather than environmental affordances, requires care.For instance, if a task contains a knife, a cutting board, and a carrot, the agent may ascertain the goal (\"cut the carrot on the cutting board\") without relying on the language instruction.Thus, task settings need to afford a diversity of actions, ideally testing multiple instructions from a single initial state, to properly evaluate whether the agent\\'s actions are driven by language.'}, {'name': 'EVALUATION METHODS', 'text': 'Action log-probabilities One simple approach is to evaluate agents based on their action predictions on held-out evaluation data.However, consistent with prior findings (Abramson et al., 2022b;Baker et al., 2022), we observed that agent action log-probabilities on evaluation data show at most a weak correlation with agent performance beyond the most basic skills.Thus, online evaluations, in which the agent interacts with the environment, are needed to understand agent performance in detail.'}, {'name': 'STATIC VISUAL INPUT', 'text': 'Similar to predicting actions on held-out data, we can provide the agent with a static visual input and a language instruction to perform a particular valid action (e.g., \"jump\") to assess simple responses directly mapping to particular keyboard and/or mouse actions.We have used evaluations of this form for our commercial video game environments, as they have the advantage of not requiring actually loading a game.While these evaluations can be a useful early signal, they do not reliably predict success on prolonged tasks.'}, {'name': 'STATIC VISUAL INPUT', 'text': 'Ground-truth Our internally-developed research environments (Construction Lab, Playhouse, and WorldLab) are capable of providing ground-truth assessments of whether language-following tasks have been successfully completed.These tasks can depend on the state of the agent (\"move forward\") and the surrounding environment (\"lift the green cube\"), as well as more complex interactions (\"attach a connector point to the top of the large block\" or \"use the knife to chop the carrots\").Such tasks enable robust testing of a range of particular skills, with a highly reliable signal of task success.Moreover, we design the task settings and evaluation to be strong tests of precision; for example, many tasks include distractor objects, for which the episode is marked as an immediate failure if the agent interacts with the distractors rather than the instruction target-even if the agent might have completed the actual task later.We also include other types of assessments, such as instructing the agent to complete one goal, and then interrupting with another goal to evaluate whether it switches appropriately-this ensures that agents are sufficiently responsive to changes in commands.A subset of our research environment tasks are used to provide a fast evaluation signal of agent progress during training.'}, {'name': 'OPTICAL CHARACTER RECOGNITION (OCR)', 'text': 'Many of our commercial video game environments provide on-screen text signalling the completion of tasks or quests, or even the results of lower-level actions like collecting resources or entering certain areas of a game.By detecting on-screen text using OCR in pre-defined evaluation scenarios, sometimes in combination with detecting specific keyboard-andmouse actions, we can cheaply assess whether the agent has successfully performed particular tasks.This form of automated evaluation also avoids the subjectivity of human evaluations.We make use of OCR evaluation in particular for two games, No Man\\'s Sky and Valheim, which both feature a significant amount of on-screen text.In No Man\\'s Sky, for example, we have developed evaluation tasks such as \"mine carbon/salt/ferrite\", \"use the analysis visor\", or \"open the exosuit menu\".Similarly, in Valheim we have tasks such as \"collect wood/stone/raspberries\", \"use the workbench\", or \"cook food\".In general, however, OCR evaluations are restricted to tasks that signal completion with game-specific text rather than arbitrary tasks that can be specified with language instructions and which we would expect a general agent to be able to solve.Other video games also have significantly less on-screen text, which makes the range of behaviors that can be evaluated in these games with OCR very narrow.'}, {'name': 'HUMAN EVALUATION', 'text': 'In the many cases where we cannot automatically derive a signal of task success, we turn to humans to provide this assessment.While this is our most general evaluation method, it is also the slowest and most expensive.We use human judges who are game experts, i.e., they have played these specific games for at least 16 hours, and often over the course of several weeks.We ask them to review recorded agent videos, collecting multiple ratings of the same video from different judges (typically 5) to ensure reliable assessments.We also encourage strict evaluations: we instruct judges to mark an episode as a failure in cases where the agent performs irrelevant actions first, even if the agent successfully completes the instructed task afterward.'}, {'name': 'HUMAN EVALUATION', 'text': 'We curated our human-evaluation tasks by identifying a list of frequently-occurring verbs in English, and combined it with a list of verbs that naturally emerged from gameplay and interactive testing of our agents.We use this verb list as a foundation for our evaluations across all video game environments.We assign each task (save state and instruction pair) to a single, most-representative skill category (e.g.'}, {'name': 'HUMAN EVALUATION', 'text': '\"craft items\"), even though most tasks require a wide range of implicit skills to succeed (e.g.crafting often requires menu use).The resulting evaluation set provides a long term challenge for agent research that spans a wide range of difficulties-from simple game agnostic tasks such as \"turn left\", to ones testing specialized game knowledge \"compare the crafting cost of antimatter and antimatter housing\", to ones utilising broader semantic knowledge such as \"take the pitchfork from the person shoveling hay\".Grounding our evaluation framework in the distribution of natural language allows us to test our agents in both common and adversarial scenarios, and thereby to measure our progress towards our long-term goal of developing an instructable agent that can accomplish anything a human can do in any simulated 3D environment.'}, {'name': 'HUMAN EVALUATION', 'text': 'In the results below (Section 4), we primarily report evaluation scores based on ground-truth evaluations for research environments and combined OCR and human evaluations for commercial video game environments.Across the 7 environments for which we have evaluations, we have a total of 1,485 unique tasks, spanning a range of 9 skill categories, from movement (\"go ahead\", \"look up\", \"jump\") to navigation (\"go to the HUB terminal\", \"go to your ship\"), resource gathering (\"collect carbon\", \"get raspberries\"), object management (\"use the analysis visor\", \"cut the potato\"), and more.'}, {'name': 'HUMAN EVALUATION', 'text': '(For reference, MineDojo (Fan et al., 2022), a related work investigating language-conditional agents in MineCraft, used 1,581 unique tasks spanning 4 skill categories: survival, harvest, tech-free, and combat).Given the diversity and coverage of our current evaluations, they provide a reasonable assessment of the fundamental language-conditional skills that we expect from our agent.Yet, there remains ongoing work in developing more scalable, general, and reliable evaluations, particularly as we move toward more complex and open-ended tasks.'}, {'name': 'LATENCY MITIGATIONS', 'text': 'Our agent is evaluated in several environments that run in real-time, asynchronously to the agent.This can pose challenges for the timely execution of agent-generated actions.Latencies or delays (Bratko et al., 1995) are introduced by the computation of actions and the transmission of observations and actions over the network.We account for this latency during behavioral cloning by predicting actions that are offset in time relative to the visual input to the agent, and mirror this offset during evaluation by appropriate buffering of observations and actions during neural-network inference.We additionally minimize latencies with appropriate scheduling of action computation on TPU accelerators, on-device caching of neural-network state across timesteps, and by careful choices of batch size and other implementation details.'}, {'name': 'RESPONSIBILITY', 'text': \"We follow a structured approach to responsible model development, to identify, measure, and manage foreseeable ethics and safety challenges.These are informed by academic literature reviews, engaging with internal ethics teams, and developing comprehensive ethical assessments that document key risks with mitigation strategies.We ensure that our research projects uphold Google's AI Principles.2 SIMA was carefully assessed and reviewed to ensure that its societal benefits outweigh the risks, and that appropriate risk mitigations are incorporated.\"}, {'name': 'NO MAN\\'S SKY -\"GO TO THE SPACESHIP\"', 'text': 'Valheim -\"chop down a tree\" Goat Simulator 3 -\"drive the car\" Satisfactory -\"go to the HUB\" Teardown -\"go through the gate\" Figure 5 | Agent Trajectories.The SIMA agent is capable of performing a range of language-instructed tasks across diverse 3D virtual environments.Here, we provide several representative, visually salient examples of the agent\\'s capabilities that demonstrate basic navigation and tool use skills.'}, {'name': 'NO MAN\\'S SKY -\"GO TO THE SPACESHIP\"', 'text': 'Benefits SIMA is a cutting-edge research initiative which focuses on how to develop instructable agents in simulated environments.This research presents interesting opportunities for the future of humans and AI collaborating together; unlike LLMs, SIMA is able to both understand natural language instructions and dynamic, interactive 3D environments.This presents a new paradigm for working with AI agents, and the potential for exciting new immersive 3D experiences with AI.Finally, simulated environments present a safer alternative for research compared to other AI deployments.'}, {'name': 'NO MAN\\'S SKY -\"GO TO THE SPACESHIP\"', 'text': 'Risks As well as these benefits, we have reflected on potential risks associated with training on video game data.These include risks associated with training an agent on games that include violent, explicit or otherwise harmful behaviors.We have also reflected on the implications on representational harms, as the agent may learn from stereotyped depictions or actions in game settings.Besides these risks, there are also down stream risks associated with the future hypothetical deployments of SIMA, through either intentional misuse or benign action.'}, {'name': 'MITIGATIONS', 'text': 'We have worked to ameliorate these risks through a holistic approach, including: • Careful curation of content.We avoided a number of games that have scientifically interesting, but violent environments.We also outlined behavioral \"red-lines\" with our ethics and safety teams; games with content that violates these red-lines are not used.• Continuous evaluations of SIMA\\'s safety performance.'}, {'name': 'MITIGATIONS', 'text': \"• Ensuring SIMA's deployments and agreements are transparent, and for now remain in a controlled, closed environment.\"}, {'name': 'MITIGATIONS', 'text': 'Ultimately, given the careful training data selection and constrained deployment environment of SIMA, we are confident we can maximize the benefits while minimising the ethical risks.'}, {'name': 'INITIAL RESULTS', 'text': \"In this section, we report initial evaluation results of the SIMA agent.After presenting several qualitative examples of the SIMA agent's capabilities, we start by considering the quantitative performance of the SIMA agent, broken down by environment and skill category.We then compare these results with several baselines and ablations, allowing us to assess the generalization capabilities of the agent and the efficacy of our design choices.Finally, we investigate a subset of evaluation tasks to estimate human-level performance as an additional comparison.\"}, {'name': 'INITIAL RESULTS', 'text': 'Qualitative examples To provide a sense of the agent\\'s general capabilities, Figure 5 displays several representative examples of the agent in our commercial video game environments.Despite the visual diversity of the environments, the agent is capable of performing these tasks, demonstrating basic navigation and tool use skills.Even when the instructed target is not in view (\"go to the spaceship\" and \"go to the HUB\"), the agent is able to find the target.For further qualitative examples, please refer to the accompanying website.3'}, {'name': 'PERFORMANCE ACROSS ENVIRONMENTS AND SKILLS', 'text': 'In Figure 6, we report the average performance of the SIMA agent across the seven environments for which we have quantitative evaluations.Averages are calculated across multiple episodes per task (in research environments, one episode per task in video games), multiple tasks per environment, and across three training runs with different random seeds.Error bars denote the 95% confidence intervals (CIs) across the tasks within that environment and the three training runs with different random seeds.We note that developing informative evaluation tasks is in itself an ongoing effort, and the quantitative results in this work reflect only the range of particular behaviors that are evaluated at this point in time.'}, {'name': 'PERFORMANCE ACROSS ENVIRONMENTS AND SKILLS', 'text': 'Overall, the results show that the SIMA agent is able to complete a range of tasks across many environments, but there remains substantial room for improvement.Performance is better for Playhouse and WorldLab, which are comparatively simpler research environments.For the more complex commercial video game environments, we see that performance is, understandably, somewhat lower.Notably, performance on Construction Lab is lower as well, highlighting the relative difficulty of this research environment and its evaluation tasks.This enables the SIMA platform to serve as a useful testbed for further development of agents that can connect language to perception and action.'}, {'name': 'PERFORMANCE ACROSS ENVIRONMENTS AND SKILLS', 'text': 'In order to better understand the performance of the SIMA agent across an increasing variety of simulated environments, we developed an evaluation framework grounded in natural language for adding and clustering evaluation tasks, as detailed in our evaluation methods.As these skill clusters are derived from our evaluation tasks rather than the training data, they are similar to, yet distinct from, those in Figure 3.As shown in Figure 7, performance varies across different skill categories, including within skill clusters such as \"movement\" or \"game progression\".Note that even seemingly simple skill clusters can involve nontrivial game interactions, e.g., some of the \"look\" tasks involve Agents achieve notable success, but are far from perfect; their success rates vary by environment.Colors indicate the evaluation method(s) used to assess performance for that environment.'}, {'name': 'PERFORMANCE ACROSS ENVIRONMENTS AND SKILLS', 'text': '(Note that humans would also find some of these tasks challenging, and thus human-level performance would not be 100%, see Section 4.3.'}, {'name': 'PERFORMANCE ACROSS ENVIRONMENTS AND SKILLS', 'text': ')skills like steering a spaceship (\"look at a planet\") or orienting based on the surrounding terrain (\"look downhill\").While there are many subtleties depending on these additional interactions and the mechanics of the environment in which the skill is used, in general, skills that require more precise actions or spatial understanding (\"combat\", \"use tools\", \"build\") tend to be more challenging.'}, {'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': 'We compare our main SIMA agent to various baselines and ablations, both in aggregate (Figure 8) and broken down across our environments (Figure 9).The agents we report across all environments include: • SIMA: Our main SIMA agent, which is trained across all environments except for Hydroneer and Wobbly Life, which we use for qualitative zero-shot evaluation.• Zero-shot: Separate SIMA agents trained like the main agent, but only on -1 of our environments, and evaluated zero-shot on the held-out environment-that is, without any BC training on it.These agents assess the transfer ability of our agent in a controlled setting.'}, {'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': '(Note that these agents use the same pretrained encoders as the main SIMA agent, which were finetuned on data from a subset of our environments; thus, in some cases the pretrained encoders will have been tuned with visual inputs from the held-out environment, even though the agent has not been trained to act in that environment.However, the encoders were not fine-tuned on data from Goat Simulator 3, thus the transfer results in that case are unconfounded.'}, {'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': ')• No pretraining ablation: An agent where we removed the pretrained encoders in the SIMA agent.We replaced these models with a ResNet vision model that is trained from scratch (as in Abramson et al., 2022a), as in preliminary experiments we found training the SPARC/Phenaki encoders through agent training resulted in poor performance.Comparing to this agent tests the benefits of pretrained models for agent performance.• No language ablation: An agent that lacks language inputs, during training as well as evaluation.'}, {'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': \"Comparing to this agent shows the degree to which our agent's performance can be explained by simple language-agnostic behavioral priors.• Environment-specialized: We additionally train an expert agent on each environment, which is trained only on data corresponding to that environment, but still includes the more broadly pretrained encoders.We normalize the performance of all other agents by the expert agent on Agents exhibit varying degrees of performance across the diverse skills that we evaluate, performing some skills reliably and others with more limited success.Skill categories are grouped into clusters (color), which are derived from our evaluation tasks.\"}, {'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': 'each environment, as a measure of what is possible using our methods and the data we have for that environment.'}, {'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': 'Note that due to the number of comparison agents, we only ran a single seed for each, rather than the three seeds used for the main SIMA agent.Each agent is evaluated after 1.2 million training steps.'}, {'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': '4The bars in Figure 8 and Figure 9 represent average performance (normalized relative to the environment-specialist); the errorbars are parametric 95%-CIs across tasks and seeds (where multiple seeds are available).'}, {'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': 'Figure 8 shows a summary of our results, while Figure 9 shows the results by environment.SIMA outperforms environment-specialized agents overall (67% average improvement over environmentspecialized agent performance), thus demonstrating positive transfer across environments.We statistically quantify this benefit by using a permutation test on the mean difference across the per-task performance of the SIMA agent and the environment-specialized agent within each domain; in every case SIMA significantly outperforms the environment-specialized agent (-values on each environment respectively: 0.001, 0.002, 0.036, 0.0002, 0.008, 0.004, and 0.0002).Furthermore, SIMA performs much better than the baselines.SIMA substantially outperforms the no-pretraining baseline overall (permutation test < 0.001), thus showing that internet-scale knowledge supports grounded learning-though the magnitude and significance of the benefit varies across the environments (permutation test -values respectively 0.0002, 0.14, 0.041, 0.0002, 0.244, 0.052, 0.032).Finally, the no-language ablation performs very poorly (all permutation tests < 0.001).Importantly, this demonstrates not only that our agent is in fact using language, but also that our evaluation tasks are effectively designed to test this capability, rather than being solvable by simply executing plausible behaviors.Comparing the SIMA agent to an ablation without classifier-free guidance (CFG), CFG substantially improves language conditionality.However, even without CFG, the agent still exhibits language-conditional behavior, outperforming the No Language ablation.Note that this evaluation was performed only on a subset of our research environments: Construction Lab, Playhouse, and WorldLab.'}, {'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': 'The zero-shot evaluations are also promising.Even when tested in an environment on which it has not been trained to act the agent demonstrates strong performance on general tasks, though of course it falls short in achieving environment-specific skills.Zero-shot agents are capable of performing generic navigation skills that appear across many games (e.g.'}, {'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': '\"go down the hill\"), and show some more complex abilities like grabbing an object by its color, using the fact that color is consistent across games, and the consistent pattern that most games use left mouse to grab or interact with objects.Importantly, even on the Goat Simulator 3 environment, where the agents have not even received visual finetuning, the zero-shot agent still performs comparably to the environmentspecialized one-thus showing transfer is not driven by the visual components alone.Note that even where the numerical performance of the zero-shot and environment-specialized agents is similar, they are generally good at different skills-with the environment-specialized agent performing well on game-specific interactions, but performing more weakly on common skills that are supported across many games, and that the zero-shot agent therefore can execute.'}, {'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': 'Note that zero-shot performance is especially strong on the WorldLab environment for three reasons.First, the evaluation tasks for this environment contain a relatively larger proportion of domain-general skills, such as recognizing objects by color, because we use them as rapid tests of agent capabilities.Second, this environment uses the same underlying engine and shares some implementation details with the other internal research environments, which may support behavioral transfer despite their varied visual styles, asset libraries, physical mechanics, and environment affordances.Furthermore, environment-specialized agent performance may be slightly weaker on this environment because there is a non-trivial distribution shift from training to test.This is because some of our data comes from earlier versions of the environment with differences in dynamics, and task distributions.Agents trained across multiple environments may be more robust to this distribution shift.'}, {'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': 'Classifier-free guidance Finally, Figure 10 compares the performance of agents with and without classifier-free guidance (CFG; Lifshitz et al., 2023), evaluated on a subset of our research environments: Construction Lab, Playhouse, and WorldLab.Without CFG ( = 0), the SIMA agent performs noticeably worse.However, the No CFG agent still exhibits a high degree of language conditionality, significantly outperforming the No Language baseline.These results show the benefit of CFG, highlighting the impact that inference-time interventions can have on agent controllability.No Language (Ablation)'}, {'name': 'HUMAN BASELINE', 'text': \"Figure 11 | Comparison with Human Performance on No Man's Sky.Evaluating on a subset of tasks from No Man's Sky, human game experts outperform all agents.Yet, humans only achieve 60% success on this evaluation.This highlights the difficulty of the tasks considered in this project.\"}, {'name': 'HUMAN COMPARISON', 'text': 'To provide an additional baseline comparison, we evaluated our agents against expert human performance on an additional set of tasks from No Man\\'s Sky, which were chosen to test a focused set of skills in a diverse range of settings.These tasks range in difficulty, from simple instructions (\"walk forward\") to more complex instructions (\"use the analysis visor to identify new animals\").The humans who performed the tasks were players who participated in our data collection and had experience with the game.We evaluated human performance using the same judges and evaluation setup that was used for our agents; the judges were not told that they were evaluating human performance rather than agents.'}, {'name': 'HUMAN COMPARISON', 'text': 'Results are summarized in Figure 11 with error bars denoting parametric 95%-CIs.The human players achieved a success rate of only 60% on these tasks, demonstrating the difficulty of the tasks we considered in this project and the stringency of our evaluation criteria.For example, some human failures appear to be due to engaging in unnecessary behaviors before completing the task, like initially opening and interacting with the starship menu when instructed to \"recharge the mining beam,\" or entering analysis mode after scanning when told to \"mine oxygen.'}, {'name': 'HUMAN COMPARISON', 'text': '\"Despite these challenging evaluations, the SIMA agent achieved non-trivial performance (34% success), far exceeding that of the No Language baseline (11% success), for example.We note that 100% success may not necessarily be achievable, due to disagreement between human judges on more ambiguous tasks.Nevertheless, there is still considerable progress needed to match human performance.This underscores the utility of the entire SIMA setup for providing a challenging, yet informative, metric for assessing grounded language interactions in embodied agents.'}, {'name': 'LOOKING AHEAD', 'text': \"SIMA is a work in progress.In this tech report, we have described our goal and philosophy, and presented some preliminary results showing our agent's ability to ground language instructions in behavior across a variety of rich 3D environments.We see notable performance and early signs of transfer across environments, as well as zero-shot transfer of basic skills to held-out environments.Still, many skills and tasks remain out of reach.In our future work, we aim to a) scale to more environments and datasets by continuing to expand our portfolio of games, environments, and datasets; b) increase the robustness and controllability of agents; c) leverage increasingly high-quality pretrained models (Gemini Team et al., 2023); and d) develop more comprehensive and carefully controlled evaluations.\"}, {'name': 'LOOKING AHEAD', 'text': 'We believe that by doing so, we will make SIMA an ideal platform for doing cutting-edge research on grounding language and pretrained models safely in complex environments, thereby helping to tackle a fundamental challenge of AGI.Our research also has the potential to enrich the learning experiences and deployment environments of future foundation models; one of our goals is to ground the abstract capabilities of large language models in embodied environments.We hope that SIMA will help us learn how to overcome the fundamental challenge of linking language to perception and action at scale, and we are excited to share more details about our research in the future.'}]\n",
      "{'name': 'TITLE', 'text': 'Scaling Instructable Agents Across Many Simulated Worlds SIMA Team: 1'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "c40e37fb-28e9-4e30-a39a-daf79d85a918\n",
      "{'name': 'ABSTRACT', 'text': ' Google DeepMind unless otherwise noted, authors listed in alphabetical order, contributions listed at end of'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "4036640b-317e-4429-a117-a3fee1c03447\n",
      "{'name': 'INTRODUCTION', 'text': 'Despite the impressive capabilities of large language models (Brown et al., 2020;Hoffmann et al., 2022;OpenAI, 2023;Anil et al., 2023;Gemini Team et al., 2023), connecting them to the embodied world that we inhabit remains challenging.Modern AI can write computer programs (Li et al., 2022) or play chess at super-human level (Silver et al., 2018), but the ability of AI to perceive and act in the world remains far below human level.Competence in language alone is easier for AI than grounded perception and behavior, underscoring the well-known paradox that what is easier for AI is harder for humans, and vice versa (Moravec, 1988).Team et al., 2023).Thus, in contrast to prior works (e.g., Abramson et al., 2020;Vinyals et al., 2019;Berner et al., 2019;Lifshitz et al., 2023), we are attempting to tackle this problem across many simulated environments, in the most general and scalable way possible, by making few assumptions beyond interacting with the environments in the same way as humans do.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "79be30cc-aae6-46de-ab9f-bf8000cc72bf\n",
      "{'name': 'INTRODUCTION', 'text': 'To this end, have made a number of design decisions that make our approach more general, but also more challenging: • We incorporate many rich, visually complex, open-ended video games containing hundreds of objects in a scene and a large number of possible interactions.• These environments are asynchronous (e.g., Berner et al., 2019;Vinyals et al., 2019); unlike many research environments, they do not stop and wait while the agent computes its next action.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "f61e9c58-3f5a-451e-9649-a7293e1b812c\n",
      "{'name': 'INTRODUCTION', 'text': '• Each instance of a commercial video game needs to run on a GPU; thus, we cannot run hundreds or thousands of actors per game per experiment as often done in RL (cf., Espeholt et al., 2018).• Agents receive the same screen observations that a human playing the game would without access to internal game state, rewards, or any other privileged information (cf., Berner et al., 2019;Vinyals et al., 2019).• To interact with the environments, agents use the same keyboard-and-mouse controls that humans do (e.g., Baker et al., 2022;Humphreys et al., 2022;Lifshitz et al., 2023), rather than handcrafted action spaces or high-level APIs.• We focus on following language instructions (e.g., Abramson et al., 2020) rather than simply playing the games to maximize a win-rate or generating plausible behavior (cf., Berner et al., 2019;Vinyals et al., 2019).• We train and test our agents using open-ended natural language, rather than simplified grammars or command sets (e.g., Abramson et al., 2020).'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "1b496422-5a5d-4eb7-8d4d-9e4654fbfdbb\n",
      "{'name': 'INTRODUCTION', 'text': 'These design choices make the learning problem harder, but their generality makes expanding to new environments easier: agents use the same interface across environments without requiring a custom design of control and observation spaces for each new game.Furthermore, since the agent-environment interface is human compatible, it allows agents the potential to achieve anything that a human could, and allows direct imitation learning from human behavior.This general interface from language instructions to embodied behavior can also enable agents to transfer previously learned skills zero-shot to never-before-seen games.Doing research in generic virtual environments allows us to test our agents in a broad and challenging range of situations-where the lessons learned are likely to be more applicable to real-world applications with visually rich perception and control such as robotics-without the risks and costs of real-world testing: if the agent crashes a spaceship in a video game, we can just restart the game.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "2c22eda8-fcc6-436e-8424-39ff03e6890d\n",
      "{'name': 'INTRODUCTION', 'text': 'In the SIMA project thus far, we have created an agent that performs short-horizon tasks based on language instructions produced by a user; though instructions could also be produced by a language model (e.g., Jiang et al., 2019;Driess et al., 2023;Wang et al., 2023b;Hu et al., 2023;Ajay et al., 2023).We have a portfolio of over ten 3D environments, consisting of research environments and commercial video games.For research environments we evaluate agents using the ground truth state, but commercial video games are not designed to report on the completion of arbitrary language tasks.We have therefore developed a variety of methods for evaluation in video games, including using optical character recognition (OCR) to detect onscreen text describing task completion, and using human evaluation of recorded videos of agent behavior.In the rest of this tech report, we describe the high-level approach (illustrated in Figure 1) and our initial progress towards the ultimate goal of SIMA: developing an instructable agent that can accomplish anything a human can do in any simulated 3D environment.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "f860d5da-189e-44d9-9ed3-27897d274462\n",
      "{'name': 'RELATED WORK', 'text': 'SIMA builds on a long history of using games as a platform for AI research.For example, backgammon provided the initial proving ground for early deep reinforcement learning methods (Tesauro et al., 1995), and later works have achieved superhuman performance even in complex board games like Go (Silver et al., 2016(Silver et al., , 2018)).'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "486d5b65-7e64-4c83-b204-d38668945c62\n",
      "{'name': 'RELATED WORK', 'text': 'Video games Over the last ten years, video games have provided an increasingly important setting for research focused on embodied agents that perform visuomotor control in rich environments.Researchers have used many video game environments, covering a wide spectrum from Atari (Bellemare et al., 2013) to DoTA (Berner et al., 2019) and StarCraft II (Vinyals et al., 2019).In SIMA, however, we restrict our focus to games that resemble 3D physical embodiment most closely, in particular games where the player interacts with a 3D world from a first or over-the-shoulder pseudo-first-person view.This focus excludes many of the games which have previously been used for research, such as the ones listed above.There has however been notable interest in first-person embodied video games as a platform for AI research (Johnson et al., 2016;Tessler et al., 2017;Guss et al., 2019;Pearce and Zhu, 2022;Hafner et al., 2023;Durante et al., 2024;Tan et al., 2024).These video game AI projects have driven the development of many innovative techniques, e.g., learning from videos by annotating them with estimated player keyboard-and-mouse actions using inverse dynamics models (Pearce and Zhu, 2022;Baker et al., 2022).More recently, games that offer API access to the environment have served as a platform for grounding large language models (Wang et al., 2023a), and some works have even considered grounding a language model in a game through direct perception and action of a lower-level controller (Wang et al., 2023b).Instead of focusing on a single game or environment, however, SIMA considers a range of diverse games to train agents on a larger variety of content.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "06faf14d-c435-4647-a151-ea8f55b7dd4e\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': 'Other works have focused on custom, controlled environments designed for research.Many of these environments focus on particular domains of real-world knowledge.For example, AI2-THOR (Kolve et al., 2017), VirtualHome (Puig et al., 2018), ProcTHOR (Deitke et al., 2022), AI Habitat (Savva et al., 2019;Szot et al., 2021;Puig et al., 2023), ALFRED (Shridhar et al., 2020), and Behavior (Srivastava et al., 2021) simulate embodied agents behaving in naturalistic rendered scenes.CARLA (Dosovitskiy et al., 2017) provides a simulator for autonomous driving.MuJoCo (Todorov et al., 2012), PyBullet (Coumans and Bai, 2016-2023), and Isaac Gym (Makoviychuk et al., 2021) provide high quality physics simulators for learning low-level control and are used by benchmarks for robotic manipulation such as Meta-World (Yu et al., 2020) and Ravens (Zeng et al., 2021).Albrecht et al.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "c03b86a0-3696-4fed-94c6-1375120e64bf\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': '(2022) propose a unified environment encompassing a variety of skills afforded through ecologically-inspired interactions.The Playhouse (Abramson et al., 2020;DeepMind Interactive Agents Team et al., 2021;Abramson et al., 2022a) and WorldLab (e.g., Gulcehre et al., 2019) environments are built using Unity (see Ward et al., 2020).Open Ended Learning Team et al.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "a14477d4-a1df-4a5b-925e-eea08fc87640\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': '(2021) and Adaptive Agent Team et al.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "1131d093-73ef-4729-981e-25446cf14e12\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': '(2023) also use Unity to instantiate a broad distribution of procedurally generated tasks with shared underlying principles.For the results in this work, we also use Playhouse, WorldLab, and ProcTHOR.In addition, we introduce a new environment, called the Construction Lab.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "b85ffec1-7136-4ed3-aeea-17f878f25e06\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': 'Robotics Robotics is a key area for research in embodied intelligence.A variety of robotics projects have used simulations for training, to transfer efficiently to real-world robotic deployments (Höfer et al., 2021), though generally within a single, constrained setting.More recent work has focused on environment-generality, including scaling robotic learning datasets across multiple tasks and embodiments (Brohan et al., 2022(Brohan et al., , 2023a;;Stone et al., 2023;Padalkar et al., 2023)-thereby creating Vision-Language-Action (VLA) models (Brohan et al., 2023a), similar to the SIMA agent.The latter challenge of generalizing or quickly adapting to new embodiments has some parallels to acting in a new 3D environment or computer game where the mechanics are different.Moreover, a variety of recent works have applied pretrained (vision-)language models as a planner for a lower-level instruction-conditional robotic control policy (Brohan et al., 2023b;Driess et al., 2023;Vemprala et al., 2023;Hu et al., 2023).Our approach shares a similar philosophy to the many works that attempt to ground language via robotics.SIMA, however, avoids the additional challenges of costly hardware requirements, resource-intensive data collection, and the practical limitations on diversity of real-world evaluation settings.Instead, SIMA makes progress towards embodied AI by leveraging many simulated environments and commercial video games to obtain the sufficient breadth and richness that we conjecture to be necessary for effectively scaling embodied agents-with the hope that lessons learned (and possibly even the agents themselves) will be applicable to robotic embodiments in the future.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "7c372d79-6786-489c-9b18-d0128756d487\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': 'Learning environment models Some works attempt to leverage learned models of environments to train agents in these learned simulations (e.g., Ha and Schmidhuber, 2018;Hafner et al., 2020Hafner et al., , 2023;;Yang et al., 2023).These methods, however, tend to be difficult to scale to diverse sets of visually complex environments that need to be self-consistent across long periods of time.Nevertheless, learning imperfect models can still be valuable.In SIMA, we build on video models (Villegas et al., 2022), which we fine-tune on game environments.However, we only use the internal state representations of the video models rather than explicit rollouts-in keeping with other approaches that use generative modeling as an objective function for learning state representations (e.g., Gregor et al., 2019;Zolna et al., 2024).'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "6da431cf-44f6-4084-9e7c-fc3c73c33784\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': 'Grounding language Another stream of work-overlapping with those above-has focused on grounding language in simulated 3D environments, through agents that are trained in controlled settings with semi-natural synthetic language (Hermann et al., 2017;Hill et al., 2019), or by imitating human interactions in a virtual house to learn a broader ability to follow natural language instructions (Abramson et al., 2020;DeepMind Interactive Agents Team et al., 2021;Abramson et al., 2022a,b).Moreover, a range of recent works develop agents that connect language to embodied action, generally as part of a hierarchy controlled by a language model (Jiang et al., 2019;Driess et al., 2023;Wang et al., 2023b;Hu et al., 2023;Ajay et al., 2023).We likewise draw inspiration from the idea that language is an ideal interface for directing an agent, but extend our scope beyond the limited affordances of a single controlled environment.In that sense, SIMA overlaps more with several recent works (Reed et al., 2022;Huang et al., 2023;Durante et al., 2024) that also explore training a single model to perform a broad range of tasks involving actions, vision, and language.However, SIMA is distinct in our focus on simultaneously (1) taking a language-first perspective, with all training experiences being language-driven; (2) adopting a unified, human-like interface across environments with language and vision to keyboard-and-mouse control; and (3) exploring a broad range of visually rich, diverse, and human-compatible environments that afford a wide range of complex skills.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "3b2ecdc8-a543-48a5-a144-191ed8dd6d0e\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': 'Language supports grounded learning, and grounded learning supports language A key motivation of SIMA is the idea that learning language and learning about environments are mutually reinforcing.A variety of studies have found that even when language is not necessary for solving a task, learning language can help agents to learn generalizable representations and abstractions, or to learn more efficiently.Language abstractions can accelerate grounded learning, for example accelerating novelty-based exploration in reinforcement learning by providing better state abstractions (Tam et al., 2022;Mu et al., 2022), or composing known goals into new ones (Colas et al., 2020;Nottingham et al., 2023).Moreover, learning to predict natural-language explanations (Lampinen et al., 2022), descriptions (Kumar et al., 2022), or plans (Hu and Clune, 2023) can help agents to learn more efficiently, and to generalize better out of distribution.Language may be a powerful tool for shaping agent capabilities (Colas et al., 2022).'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "3fa34c5c-0960-4e31-aba3-9b7231a6a837\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': 'Conversely, richly grounded learning can also support language learning.Since human language use is deeply integrated with our understanding of grounded situations (McClelland et al., 2020), understanding the subtleties of human language will likely benefit from this grounding.Beyond this theoretical argument, empirical evidence shows that grounding can support even fundamental kinds of generalization- Hill et al.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "4041c9bb-40b1-47ba-8a58-90eb5c46d524\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': \"(2019) show that agents grounded in richer, more-embodied environments exhibit more systematic compositional generalization.These findings motivate the possibility that learning both language and its grounding will not only improve grounded actions, but improve a system's knowledge of language itself.\"}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "654f5fbd-9430-40aa-b3fb-d2b72720814c\n",
      "{'name': 'APPROACH', 'text': 'Many overlapping areas of previous and concurrent work share some of our philosophy, motivations, and approaches.What distinguishes the SIMA project is our focus on language-conditional behavior across a diverse range of visually and mechanically complex simulated environments that afford a rich set of skills.In this section, we provide a high-level overview of our approach: our environments, data, agents, and evaluations.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "064730bf-d6a6-4ebb-9d6b-4b56b54b2f21\n",
      "{'name': 'ENVIRONMENTS', 'text': \"SIMA aims to ground language across many rich 3D environments (Figure 2).Thus, we selected 3D embodied environments that offer a broad range of open-ended interactions-such environments afford the possibility of rich and deep language interactions.We focus on environments that are either in a) first-person or b) third-person with the camera over the player's shoulder.To achieve diversity and depth of experience, we use a variety of commercial video games, as well as several environments created specifically for agent research.Each type of environment offers distinct advantages, ranging from open-ended diverse experiences to targeted assessments of agent skills.We have deliberately sought to build a portfolio of games that covers a wide range of settings-from mundane tasks in semi-realistic environments, to acting as a mischevious goat in a world with exaggerated physics, to exploring mythological worlds or science-fiction universes.Below, we briefly describe the environments we have used in SIMA thus far by category and in alphabetical order.\"}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "ea3fe601-bad6-45ce-a71d-d284ce891d77\n",
      "{'name': 'COMMERCIAL VIDEO GAMES', 'text': 'Commercial video games offer exciting, open-ended worlds full of visual richness and the potential for complex interactions.In SIMA, we have partnered with games developers whose games we used for training agents, and we are continuing to develop relationships with new developers-for our full list of current partners, please see our Acknowledgements section.We focus on a variety of open-world or sandbox games that contain diverse skills, while avoiding games containing harmful content such as extreme violence or biases.We have also sought a broad diversity of worlds and stories, but with a focus on games that exhibit a depth of interesting mechanics.Accordingly, games from our portfolio offer a wide range of distinct challenges in perception and action, from flying a spaceship to mining minerals or crafting armor, as well as more common core features, such as navigation or gathering resources.Games also often include interactions that extend beyond the skillset of typical embodied research environments, such as menu use and interfaces more similar to those faced in computer control benchmarks (e.g., Humphreys et al., 2022;Koh et al., 2024).For the results in this report, we focus on single-player interactions within these games.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "72de8237-2fee-4438-82dc-618a039b2635\n",
      "{'name': 'COMMERCIAL VIDEO GAMES', 'text': 'We run instances of each game in a secure Google Cloud environment, using hardware accelerated rendering to a virtual display.This display is streamed to a browser for human gameplay, or to a remote agent client process during evaluation.To instantiate repeatable evaluation or data collection scenarios within each game, we build datasets of save-game files from expert play, and use scripted processes to automate the process of installing game-files, booting the game, navigating its main menu, and loading a specific save-game.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "5392c900-a8b4-4c0c-ae35-d6c10f014604\n",
      "{'name': 'COMMERCIAL VIDEO GAMES', 'text': 'We now provide a brief description of the games we used.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "c0340e21-68d8-4cfc-846f-6cbb33fa5304\n",
      "{'name': 'GOAT SIMULATOR 3:', 'text': 'A third-person game where the player is a goat in a world with exaggerated physics.The player can complete quests, most of which involve wreaking havoc.The goat is able to lick, headbutt, climb, drive, equip a wide range of visual and functional items, and perform various other actions.Throughout the course of the game, the goat unlocks new abilities, such as the ability to fly.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "40d6c4dd-e875-4d6a-9478-f82918c52579\n",
      "{'name': 'GOAT SIMULATOR 3:', 'text': 'Hydroneer: A first-person mining and base building sandbox where the player is tasked with digging for gold and other resources to turn a profit and enhance their mining operation.To do this, they must build and upgrade their set-ups and increase the complexity and levels of automation until they have a fully automated mining system.Players can also complete quests from non-player characters to craft bespoke objects and gain extra money.Hydroneer requires careful planning and managing of resources.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "39e12831-63ff-44ff-a2e3-b4ddb67ae4a8\n",
      "{'name': \"NO MAN'S SKY:\", 'text': \"A first-or third-person survival game where the player seeks to explore a galaxy full of procedurally-generated planets.This involves flying between planets to gather resources, trade, build bases, and craft items that are needed to upgrade their equipment and spaceship while surviving a hazardous environment.No Man's Sky includes a large amount of visual diversity-which poses important challenges for agent perception-and rich interactions and skills.\"}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "d6146358-9c35-4283-861a-98bbe9e8524e\n",
      "{'name': \"NO MAN'S SKY:\", 'text': 'Satisfactory: A first-person, open-world exploration and factory building game, in which players attempt to build a space elevator on an alien planet.This requires building increasingly complex production chains to extract natural resources and convert them into industrial goods, tools, and structures-whilst navigating increasingly hostile areas of a large open environment.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "fd20d4d9-9ab2-4c5d-83f2-c80da60c85a2\n",
      "{'name': \"NO MAN'S SKY:\", 'text': \"Teardown: A first-person, sandbox-puzzle game in a fully destructible voxel world where players are tasked with completing heists to gain money, acquiring better tools, and undertaking even more high-risk heists.Each heist is a unique scenario in one of a variety of locations where players must assess the situation, plan the execution of their mission, avoid triggering alarms, and escape before a timer expires.Teardown involves planning and using the environment to one's advantage to complete the tasks with precision and speed.\"}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "c73d995d-7843-4fea-9efb-7ca7b4db4902\n",
      "{'name': \"NO MAN'S SKY:\", 'text': 'Valheim: A third-person survival and sandbox game in a world inspired by Norse mythology.Players must explore various biomes, gather resources, hunt animals, build shelter, craft equipment, sail the oceans and defeat mythological monsters to advance in the game-while surviving challenges like hunger and cold.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "bfd27d7e-0064-4c09-a097-910bb9cfc106\n",
      "{'name': \"NO MAN'S SKY:\", 'text': 'Wobbly Life: A third-person, open-world sandbox game where the player can explore the world, unlock secrets, and complete various jobs to earn money and buy items, leading up to buying their own house.They must complete these jobs whilst contending with the rag-doll physics of their characters and competing against the clock.The jobs require timing, planning, and precision to be completed.The world is extensive and varied, with a diverse range of interactive objects.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "1910dfc7-89f2-42bf-8233-9104ad17dbd6\n",
      "{'name': 'CONSTRUCTION LAB', 'text': 'Figure 2 | Environments.We use over ten 3D environments in SIMA, consisting of commercial video games and research environments.The diversity of these environments is seen in their wide range of visual observations and environmental affordances.Yet, because these are all 3D environments, basic aspects of 3D embodied interaction, such as navigation, are shared.Commercial video games offer a higher degree of rich interactions and visual fidelity, while research environments serve as a useful testbed for probing agent capabilities.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "4611c64d-e49d-4b66-85a5-9918ec22bf1f\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': 'In contrast to commercial video games, AI research environments are typically more controllable, offering the ability to instill and carefully assess particular skills, and more rapid and reliable evaluations of task completion.Unlike many of the games in our portfolio, several of these research environments also tend to feature more real-world analogous-if still simplified-physical interactions.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "2ec7b426-6fa6-4dca-8b1d-be9dd0b11cdd\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': 'We have drawn on several prior research environments and developed a new environment-the Construction Lab-that incorporates important challenges which were not otherwise well-captured by our other environments.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "eef3bf73-27ce-45e2-a138-4a66325fdcdd\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': 'Construction Lab: A new research environment where agents need to build novel items and sculptures from interconnecting building blocks, including ramps to climb, bridges to cross, and dynamic contraptions.Construction Lab focuses on cognitive capabilities such as object manipulation and an intuitive understanding of the physical world.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "fc82ed3c-ac6b-40bc-90d4-e35075f0d431\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': 'Playhouse: An environment used in various prior works (Abramson et al., 2020;DeepMind Interactive Agents Team et al., 2021;Abramson et al., 2022a), consisting of a procedurally-generated house environment with various objects.We have augmented this environment with improved graphics and richer interactions, including skills like cooking or painting.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "cc2258cd-cadb-4401-ac86-e806f591506b\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': 'ProcTHOR: An environment consisting of procedurally-generated rooms with realistic contents, such as offices and libraries, introduced by Deitke et al.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "9bc55822-993b-4b51-be13-b4adf1f07372\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': '(2022).Although benchmark task sets exist in this environment, prior works have not used keyboard and mouse actions for agents; thus we focus on this environment primarily for data collection rather than evaluation.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "a6337282-de9c-424b-8027-bf87bef93126\n",
      "{'name': 'RESEARCH ENVIRONMENTS', 'text': 'WorldLab: An environment used in prior work (e.g., Gulcehre et al., 2019), further specialized for testing embodied agents by using a limited set of intuitive mechanics, such as sensors and doors, and relying primarily on the use of simulated physics on a range of objects.The SIMA dataset includes a broad range of text instructions that can be roughly clustered into a hierarchy.Due to the common 3D embodied nature of the environments that we consider, many generic tasks, such as navigation and object manipulation, are present in multiple environments.Categories were derived from a data-driven hierarchical clustering analysis of the human-generated text instructions within a fixed, pretrained word embedding space.Note that the area of each cluster in the wheel in Figure 3 does not correspond to the exact number of instructions from that cluster in the dataset.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "63c89769-e6f3-4551-8a61-bdc7fb87c06e\n",
      "{'name': 'DATA', 'text': 'Our approach relies on training agents at scale via behavioral cloning, i.e., supervised learning of the mapping from observations to actions on data generated by humans.Thus, a major focus of our effort is on collecting and incorporating gameplay data from human experts.This includes videos, language instructions and dialogue, recorded actions, and various annotations such as descriptions or marks of success or failure.These data constitute a rich, multi-modal dataset of embodied interaction within over 10 simulated environments, with more to come.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "f51548ad-0d1b-438e-8080-3013b8d6945f\n",
      "{'name': 'DATA', 'text': '1 Our data can be used to augment and leverage existing training data (e.g., Abramson et al., 2020), or to fine-tune pretrained models to endow them with more situated understanding.These datasets cover a broad range of instructed tasks: Figure 3 shows instruction clusters derived from hierarchically clustering the text instructions present in the data within a fixed, pretrained word embedding space.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "5656e191-2f6a-46a7-a440-0e11206f892d\n",
      "{'name': 'DATA', 'text': 'Yet, collecting data at scale is not sufficient for training successful agents.Data quality processes 1 Note: Due to a limited amount of collected data and/or evaluations, we present agent evaluation results (Section 4) on a subset of 7 of these environments.are critical to ensuring an accurate and unconfounded mapping between language and behavior.This presents various technical challenges.We take care to engineer our data collections, including preprocessing and filtering the raw data, to highlight important skills and effectively train our agents.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "518ebf11-56fe-4fe1-8b00-97baa658bcbf\n",
      "{'name': 'DATA COLLECTIONS', 'text': 'We collect data using a variety of methods, including allowing single players to freely play, and then annotating these trajectories with instructions post-hoc.We also perform two-player setter-solver collections (Abramson et al., 2020;DeepMind Interactive Agents Team et al., 2021), in which one player instructs another what to do in selected scenarios while sharing a single player view in order to match the single-player collections.All our data collections were performed with participants contracting with Google.The full details of our data collection protocols, including compensation rates, were reviewed and approved by an independent Human Behavioral Research Committee for ethics and privacy.All participants provided informed consent prior to completing tasks and were reimbursed for their time.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "68d872ea-d294-4c50-8bce-76a30a4b469c\n",
      "{'name': 'DATA COLLECTIONS', 'text': 'Preprocessing, filtering, and weighting Before training, we perform a variety of offline preprocessing steps, including resizing data for agent input, filtering out low-quality data using a variety of heuristics, and remixing and weighting data across environments and collections to prioritize the most effective learning experiences.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "662ed515-bc63-4825-996c-65abcfe9f5bc\n",
      "{'name': 'AGENT', 'text': 'The SIMA agent maps visual observations and language instructions to keyboard-and-mouse actions (Figure 4).Given the complexity of this undertaking-such as the high dimensionality of the input and output spaces, and the breadth of possible instructions over long timescales-we predominantly focus on training the agent to perform instructions that can be completed in less than approximately 10 seconds.Breaking tasks into simpler sub-tasks enables their reuse across different settings and entirely different environments, given an appropriate sequence of instructions from the user.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "82f36e08-21df-4d00-a6d1-edd9826a0f6a\n",
      "{'name': 'AGENT', 'text': 'Our agent architecture builds on prior related work (Abramson et al., 2020(Abramson et al., , 2022a)), but with various changes and adaptations to our more general goals.First, our agent incorporates not only trained-from-scratch components, but also several pretrained models-including a model trained on fine-grained image-text alignment, SPARC (Bica et al., 2024), and a video prediction model, Phenaki (Villegas et al., 2022)-which we further fine-tune on our data through behavioral cloning and video prediction, respectively.In preliminary experiments, we found that these models offer complementary benefits.Combining these pre-trained models with fine-tuning and from-scratch training allows the agent to utilize internet-scale pretraining while still specializing to particular aspects of the environments and the control tasks that it encounters.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "d3fcd7ed-d9e1-4a85-a17f-1d21f5b913a3\n",
      "{'name': 'AGENT', 'text': 'More specifically, our agent (Figure 4) utilizes trained-from-scratch transformers that cross-attend to the different pretrained vision components, the encoded language instruction, and a Transformer-XL (Dai et al., 2019) that attends to past memory states to construct a state representation.The resulting state representation is provided as input to a policy network that produces keyboard-and-mouse actions for sequences of 8 actions.We train this agent with behavioral cloning, as well as an auxiliary objective of predicting goal completion.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "9de99737-ecd4-423d-8b01-7d783f8e19f0\n",
      "{'name': 'AGENT', 'text': 'We use Classifier-Free Guidance (CFG; Ho and Salimans, 2022;Lifshitz et al., 2023) to improve the language-conditionality of a trained agent when running it in an environment.CFG was originally proposed for strengthening text-conditioning in diffusion models (Ho and Salimans, 2022), but has also proven useful for similar purposes with language models (Sanchez et al., 2023) and languageconditioned agents (Lifshitz et al., 2023).That is, we compute the policy, , with and without language conditioning, and shift the policy logits in the direction of the difference between the two: = (image, language) + ( (image, language) - (image, •)) .'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "6b910901-e165-4f2a-920c-4394d1e838c6\n",
      "{'name': 'EVALUATION METHODS', 'text': 'Our focus on generality in SIMA introduces challenges for evaluation.While research environments may provide automated methods for assessing whether language-following tasks have been successfully completed, such success criteria may not be generally available.That is, language instructions may not correspond to goal states recorded by an environment (e.g.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "7fba7ec7-1419-4def-8e13-7aac2fd6db06\n",
      "{'name': 'EVALUATION METHODS', 'text': 'a user might instruct \"make a pile of rocks to mark this spot\" or \"see if you can jump over this chasm\").'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "7461a6bc-b0fc-45a3-8dd4-89a5f1d04801\n",
      "{'name': 'EVALUATION METHODS', 'text': 'Evaluating agents in commercial video games poses substantial additional challenges.Video game evaluations cannot rely on access to privileged information about the state of an environment.Additionally, it is difficult to reinstate agents in precisely the same state in environments that are not designed as reproducible benchmarks, and loading each task in commercial video games is considerably slower and more costly than those in research environments.Achieving fast, stable, and reliable evaluations comparable across environments is thus challenging.We therefore use a range of distinct evaluation types that provide different trade-offs in efficiency, cost, accuracy, and coverage.Moreover, ensuring that our evaluations truly assess language conditionality, rather than environmental affordances, requires care.For instance, if a task contains a knife, a cutting board, and a carrot, the agent may ascertain the goal (\"cut the carrot on the cutting board\") without relying on the language instruction.Thus, task settings need to afford a diversity of actions, ideally testing multiple instructions from a single initial state, to properly evaluate whether the agent\\'s actions are driven by language.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "3a111ee7-abc0-4eb1-9a2b-5e37ec3e76df\n",
      "{'name': 'EVALUATION METHODS', 'text': 'Action log-probabilities One simple approach is to evaluate agents based on their action predictions on held-out evaluation data.However, consistent with prior findings (Abramson et al., 2022b;Baker et al., 2022), we observed that agent action log-probabilities on evaluation data show at most a weak correlation with agent performance beyond the most basic skills.Thus, online evaluations, in which the agent interacts with the environment, are needed to understand agent performance in detail.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "d92171d2-f4c6-4cc3-8e4e-100f6bcea55d\n",
      "{'name': 'STATIC VISUAL INPUT', 'text': 'Similar to predicting actions on held-out data, we can provide the agent with a static visual input and a language instruction to perform a particular valid action (e.g., \"jump\") to assess simple responses directly mapping to particular keyboard and/or mouse actions.We have used evaluations of this form for our commercial video game environments, as they have the advantage of not requiring actually loading a game.While these evaluations can be a useful early signal, they do not reliably predict success on prolonged tasks.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "44d64660-d0d5-4053-956a-862605617f99\n",
      "{'name': 'STATIC VISUAL INPUT', 'text': 'Ground-truth Our internally-developed research environments (Construction Lab, Playhouse, and WorldLab) are capable of providing ground-truth assessments of whether language-following tasks have been successfully completed.These tasks can depend on the state of the agent (\"move forward\") and the surrounding environment (\"lift the green cube\"), as well as more complex interactions (\"attach a connector point to the top of the large block\" or \"use the knife to chop the carrots\").Such tasks enable robust testing of a range of particular skills, with a highly reliable signal of task success.Moreover, we design the task settings and evaluation to be strong tests of precision; for example, many tasks include distractor objects, for which the episode is marked as an immediate failure if the agent interacts with the distractors rather than the instruction target-even if the agent might have completed the actual task later.We also include other types of assessments, such as instructing the agent to complete one goal, and then interrupting with another goal to evaluate whether it switches appropriately-this ensures that agents are sufficiently responsive to changes in commands.A subset of our research environment tasks are used to provide a fast evaluation signal of agent progress during training.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "f228de33-3836-4fd4-bcf3-c9e051bee5fa\n",
      "{'name': 'OPTICAL CHARACTER RECOGNITION (OCR)', 'text': 'Many of our commercial video game environments provide on-screen text signalling the completion of tasks or quests, or even the results of lower-level actions like collecting resources or entering certain areas of a game.By detecting on-screen text using OCR in pre-defined evaluation scenarios, sometimes in combination with detecting specific keyboard-andmouse actions, we can cheaply assess whether the agent has successfully performed particular tasks.This form of automated evaluation also avoids the subjectivity of human evaluations.We make use of OCR evaluation in particular for two games, No Man\\'s Sky and Valheim, which both feature a significant amount of on-screen text.In No Man\\'s Sky, for example, we have developed evaluation tasks such as \"mine carbon/salt/ferrite\", \"use the analysis visor\", or \"open the exosuit menu\".Similarly, in Valheim we have tasks such as \"collect wood/stone/raspberries\", \"use the workbench\", or \"cook food\".In general, however, OCR evaluations are restricted to tasks that signal completion with game-specific text rather than arbitrary tasks that can be specified with language instructions and which we would expect a general agent to be able to solve.Other video games also have significantly less on-screen text, which makes the range of behaviors that can be evaluated in these games with OCR very narrow.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "c2e243cd-7c1b-43c0-be43-512d9acdb2c2\n",
      "{'name': 'HUMAN EVALUATION', 'text': 'In the many cases where we cannot automatically derive a signal of task success, we turn to humans to provide this assessment.While this is our most general evaluation method, it is also the slowest and most expensive.We use human judges who are game experts, i.e., they have played these specific games for at least 16 hours, and often over the course of several weeks.We ask them to review recorded agent videos, collecting multiple ratings of the same video from different judges (typically 5) to ensure reliable assessments.We also encourage strict evaluations: we instruct judges to mark an episode as a failure in cases where the agent performs irrelevant actions first, even if the agent successfully completes the instructed task afterward.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "b872542b-ca58-4542-98f3-30b9eee111c3\n",
      "{'name': 'HUMAN EVALUATION', 'text': 'We curated our human-evaluation tasks by identifying a list of frequently-occurring verbs in English, and combined it with a list of verbs that naturally emerged from gameplay and interactive testing of our agents.We use this verb list as a foundation for our evaluations across all video game environments.We assign each task (save state and instruction pair) to a single, most-representative skill category (e.g.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "cfbfdf98-d985-4150-878c-9c1d34bdf970\n",
      "{'name': 'HUMAN EVALUATION', 'text': '\"craft items\"), even though most tasks require a wide range of implicit skills to succeed (e.g.crafting often requires menu use).The resulting evaluation set provides a long term challenge for agent research that spans a wide range of difficulties-from simple game agnostic tasks such as \"turn left\", to ones testing specialized game knowledge \"compare the crafting cost of antimatter and antimatter housing\", to ones utilising broader semantic knowledge such as \"take the pitchfork from the person shoveling hay\".Grounding our evaluation framework in the distribution of natural language allows us to test our agents in both common and adversarial scenarios, and thereby to measure our progress towards our long-term goal of developing an instructable agent that can accomplish anything a human can do in any simulated 3D environment.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "82509cf5-72ac-4f8a-b90f-71b664aaf152\n",
      "{'name': 'HUMAN EVALUATION', 'text': 'In the results below (Section 4), we primarily report evaluation scores based on ground-truth evaluations for research environments and combined OCR and human evaluations for commercial video game environments.Across the 7 environments for which we have evaluations, we have a total of 1,485 unique tasks, spanning a range of 9 skill categories, from movement (\"go ahead\", \"look up\", \"jump\") to navigation (\"go to the HUB terminal\", \"go to your ship\"), resource gathering (\"collect carbon\", \"get raspberries\"), object management (\"use the analysis visor\", \"cut the potato\"), and more.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "fdaca710-d35d-4aa7-a4aa-9afc8681bfd5\n",
      "{'name': 'HUMAN EVALUATION', 'text': '(For reference, MineDojo (Fan et al., 2022), a related work investigating language-conditional agents in MineCraft, used 1,581 unique tasks spanning 4 skill categories: survival, harvest, tech-free, and combat).Given the diversity and coverage of our current evaluations, they provide a reasonable assessment of the fundamental language-conditional skills that we expect from our agent.Yet, there remains ongoing work in developing more scalable, general, and reliable evaluations, particularly as we move toward more complex and open-ended tasks.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "3c6b0f92-e669-4c2c-9265-7b76c506337e\n",
      "{'name': 'LATENCY MITIGATIONS', 'text': 'Our agent is evaluated in several environments that run in real-time, asynchronously to the agent.This can pose challenges for the timely execution of agent-generated actions.Latencies or delays (Bratko et al., 1995) are introduced by the computation of actions and the transmission of observations and actions over the network.We account for this latency during behavioral cloning by predicting actions that are offset in time relative to the visual input to the agent, and mirror this offset during evaluation by appropriate buffering of observations and actions during neural-network inference.We additionally minimize latencies with appropriate scheduling of action computation on TPU accelerators, on-device caching of neural-network state across timesteps, and by careful choices of batch size and other implementation details.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "49c16add-72db-43a9-af56-48163499bd57\n",
      "{'name': 'RESPONSIBILITY', 'text': \"We follow a structured approach to responsible model development, to identify, measure, and manage foreseeable ethics and safety challenges.These are informed by academic literature reviews, engaging with internal ethics teams, and developing comprehensive ethical assessments that document key risks with mitigation strategies.We ensure that our research projects uphold Google's AI Principles.2 SIMA was carefully assessed and reviewed to ensure that its societal benefits outweigh the risks, and that appropriate risk mitigations are incorporated.\"}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "398df0e7-b3c6-4e7d-873a-5cecc05e33b4\n",
      "{'name': 'NO MAN\\'S SKY -\"GO TO THE SPACESHIP\"', 'text': 'Valheim -\"chop down a tree\" Goat Simulator 3 -\"drive the car\" Satisfactory -\"go to the HUB\" Teardown -\"go through the gate\" Figure 5 | Agent Trajectories.The SIMA agent is capable of performing a range of language-instructed tasks across diverse 3D virtual environments.Here, we provide several representative, visually salient examples of the agent\\'s capabilities that demonstrate basic navigation and tool use skills.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "ea33620c-da36-41bd-9b72-9abbf6e956bf\n",
      "{'name': 'NO MAN\\'S SKY -\"GO TO THE SPACESHIP\"', 'text': 'Benefits SIMA is a cutting-edge research initiative which focuses on how to develop instructable agents in simulated environments.This research presents interesting opportunities for the future of humans and AI collaborating together; unlike LLMs, SIMA is able to both understand natural language instructions and dynamic, interactive 3D environments.This presents a new paradigm for working with AI agents, and the potential for exciting new immersive 3D experiences with AI.Finally, simulated environments present a safer alternative for research compared to other AI deployments.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "0a460597-141d-4c79-9b10-a7bf550c66f2\n",
      "{'name': 'NO MAN\\'S SKY -\"GO TO THE SPACESHIP\"', 'text': 'Risks As well as these benefits, we have reflected on potential risks associated with training on video game data.These include risks associated with training an agent on games that include violent, explicit or otherwise harmful behaviors.We have also reflected on the implications on representational harms, as the agent may learn from stereotyped depictions or actions in game settings.Besides these risks, there are also down stream risks associated with the future hypothetical deployments of SIMA, through either intentional misuse or benign action.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "79c0a9f8-617e-455e-8243-6679be6b0126\n",
      "{'name': 'MITIGATIONS', 'text': 'We have worked to ameliorate these risks through a holistic approach, including: • Careful curation of content.We avoided a number of games that have scientifically interesting, but violent environments.We also outlined behavioral \"red-lines\" with our ethics and safety teams; games with content that violates these red-lines are not used.• Continuous evaluations of SIMA\\'s safety performance.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "ef9826b6-0d11-4b45-b326-0e66ae9420f2\n",
      "{'name': 'MITIGATIONS', 'text': \"• Ensuring SIMA's deployments and agreements are transparent, and for now remain in a controlled, closed environment.\"}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "f8220549-cec1-4c14-83d8-ba0fc8e6ac01\n",
      "{'name': 'MITIGATIONS', 'text': 'Ultimately, given the careful training data selection and constrained deployment environment of SIMA, we are confident we can maximize the benefits while minimising the ethical risks.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "f2d776e5-d131-47f6-b4ff-32a2feec2bb1\n",
      "{'name': 'INITIAL RESULTS', 'text': \"In this section, we report initial evaluation results of the SIMA agent.After presenting several qualitative examples of the SIMA agent's capabilities, we start by considering the quantitative performance of the SIMA agent, broken down by environment and skill category.We then compare these results with several baselines and ablations, allowing us to assess the generalization capabilities of the agent and the efficacy of our design choices.Finally, we investigate a subset of evaluation tasks to estimate human-level performance as an additional comparison.\"}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "51d3a0bd-a255-422f-8de3-aa4e9bb055f3\n",
      "{'name': 'INITIAL RESULTS', 'text': 'Qualitative examples To provide a sense of the agent\\'s general capabilities, Figure 5 displays several representative examples of the agent in our commercial video game environments.Despite the visual diversity of the environments, the agent is capable of performing these tasks, demonstrating basic navigation and tool use skills.Even when the instructed target is not in view (\"go to the spaceship\" and \"go to the HUB\"), the agent is able to find the target.For further qualitative examples, please refer to the accompanying website.3'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "87267cf9-00a8-4517-af40-58f54845568f\n",
      "{'name': 'PERFORMANCE ACROSS ENVIRONMENTS AND SKILLS', 'text': 'In Figure 6, we report the average performance of the SIMA agent across the seven environments for which we have quantitative evaluations.Averages are calculated across multiple episodes per task (in research environments, one episode per task in video games), multiple tasks per environment, and across three training runs with different random seeds.Error bars denote the 95% confidence intervals (CIs) across the tasks within that environment and the three training runs with different random seeds.We note that developing informative evaluation tasks is in itself an ongoing effort, and the quantitative results in this work reflect only the range of particular behaviors that are evaluated at this point in time.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "2b860640-386f-48ae-9361-55456651f224\n",
      "{'name': 'PERFORMANCE ACROSS ENVIRONMENTS AND SKILLS', 'text': 'Overall, the results show that the SIMA agent is able to complete a range of tasks across many environments, but there remains substantial room for improvement.Performance is better for Playhouse and WorldLab, which are comparatively simpler research environments.For the more complex commercial video game environments, we see that performance is, understandably, somewhat lower.Notably, performance on Construction Lab is lower as well, highlighting the relative difficulty of this research environment and its evaluation tasks.This enables the SIMA platform to serve as a useful testbed for further development of agents that can connect language to perception and action.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "6b181954-7361-49ea-a5b2-9068febc9f07\n",
      "{'name': 'PERFORMANCE ACROSS ENVIRONMENTS AND SKILLS', 'text': 'In order to better understand the performance of the SIMA agent across an increasing variety of simulated environments, we developed an evaluation framework grounded in natural language for adding and clustering evaluation tasks, as detailed in our evaluation methods.As these skill clusters are derived from our evaluation tasks rather than the training data, they are similar to, yet distinct from, those in Figure 3.As shown in Figure 7, performance varies across different skill categories, including within skill clusters such as \"movement\" or \"game progression\".Note that even seemingly simple skill clusters can involve nontrivial game interactions, e.g., some of the \"look\" tasks involve Agents achieve notable success, but are far from perfect; their success rates vary by environment.Colors indicate the evaluation method(s) used to assess performance for that environment.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "b7f8de61-4146-4987-9129-641802c9776f\n",
      "{'name': 'PERFORMANCE ACROSS ENVIRONMENTS AND SKILLS', 'text': '(Note that humans would also find some of these tasks challenging, and thus human-level performance would not be 100%, see Section 4.3.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "49ffcf33-6edb-461b-8d8d-348d2402390d\n",
      "{'name': 'PERFORMANCE ACROSS ENVIRONMENTS AND SKILLS', 'text': ')skills like steering a spaceship (\"look at a planet\") or orienting based on the surrounding terrain (\"look downhill\").While there are many subtleties depending on these additional interactions and the mechanics of the environment in which the skill is used, in general, skills that require more precise actions or spatial understanding (\"combat\", \"use tools\", \"build\") tend to be more challenging.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "b61d4c5d-b5f1-40d2-a852-07a6b450bfb6\n",
      "{'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': 'We compare our main SIMA agent to various baselines and ablations, both in aggregate (Figure 8) and broken down across our environments (Figure 9).The agents we report across all environments include: • SIMA: Our main SIMA agent, which is trained across all environments except for Hydroneer and Wobbly Life, which we use for qualitative zero-shot evaluation.• Zero-shot: Separate SIMA agents trained like the main agent, but only on -1 of our environments, and evaluated zero-shot on the held-out environment-that is, without any BC training on it.These agents assess the transfer ability of our agent in a controlled setting.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "8c713b19-689c-466f-9441-83928ed4c496\n",
      "{'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': '(Note that these agents use the same pretrained encoders as the main SIMA agent, which were finetuned on data from a subset of our environments; thus, in some cases the pretrained encoders will have been tuned with visual inputs from the held-out environment, even though the agent has not been trained to act in that environment.However, the encoders were not fine-tuned on data from Goat Simulator 3, thus the transfer results in that case are unconfounded.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "4185f2c4-9f3f-4f4e-9768-7d51115905ee\n",
      "{'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': ')• No pretraining ablation: An agent where we removed the pretrained encoders in the SIMA agent.We replaced these models with a ResNet vision model that is trained from scratch (as in Abramson et al., 2022a), as in preliminary experiments we found training the SPARC/Phenaki encoders through agent training resulted in poor performance.Comparing to this agent tests the benefits of pretrained models for agent performance.• No language ablation: An agent that lacks language inputs, during training as well as evaluation.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "cbd432ca-5c14-4aad-aa76-03a0765a93f2\n",
      "{'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': \"Comparing to this agent shows the degree to which our agent's performance can be explained by simple language-agnostic behavioral priors.• Environment-specialized: We additionally train an expert agent on each environment, which is trained only on data corresponding to that environment, but still includes the more broadly pretrained encoders.We normalize the performance of all other agents by the expert agent on Agents exhibit varying degrees of performance across the diverse skills that we evaluate, performing some skills reliably and others with more limited success.Skill categories are grouped into clusters (color), which are derived from our evaluation tasks.\"}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "50c28b60-afd7-42ec-b4c7-c2c11cb04a58\n",
      "{'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': 'each environment, as a measure of what is possible using our methods and the data we have for that environment.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "6265e804-b39d-44ab-8c2f-52c3863f4fbf\n",
      "{'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': 'Note that due to the number of comparison agents, we only ran a single seed for each, rather than the three seeds used for the main SIMA agent.Each agent is evaluated after 1.2 million training steps.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "e48f89a3-dee6-4434-b7ce-ff2737bb9643\n",
      "{'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': '4The bars in Figure 8 and Figure 9 represent average performance (normalized relative to the environment-specialist); the errorbars are parametric 95%-CIs across tasks and seeds (where multiple seeds are available).'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "91405250-465b-4d7d-9aa3-8d5d6dc827f7\n",
      "{'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': 'Figure 8 shows a summary of our results, while Figure 9 shows the results by environment.SIMA outperforms environment-specialized agents overall (67% average improvement over environmentspecialized agent performance), thus demonstrating positive transfer across environments.We statistically quantify this benefit by using a permutation test on the mean difference across the per-task performance of the SIMA agent and the environment-specialized agent within each domain; in every case SIMA significantly outperforms the environment-specialized agent (-values on each environment respectively: 0.001, 0.002, 0.036, 0.0002, 0.008, 0.004, and 0.0002).Furthermore, SIMA performs much better than the baselines.SIMA substantially outperforms the no-pretraining baseline overall (permutation test < 0.001), thus showing that internet-scale knowledge supports grounded learning-though the magnitude and significance of the benefit varies across the environments (permutation test -values respectively 0.0002, 0.14, 0.041, 0.0002, 0.244, 0.052, 0.032).Finally, the no-language ablation performs very poorly (all permutation tests < 0.001).Importantly, this demonstrates not only that our agent is in fact using language, but also that our evaluation tasks are effectively designed to test this capability, rather than being solvable by simply executing plausible behaviors.Comparing the SIMA agent to an ablation without classifier-free guidance (CFG), CFG substantially improves language conditionality.However, even without CFG, the agent still exhibits language-conditional behavior, outperforming the No Language ablation.Note that this evaluation was performed only on a subset of our research environments: Construction Lab, Playhouse, and WorldLab.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "8b661fc7-3b20-4e6c-8e77-7a6f278c5760\n",
      "{'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': 'The zero-shot evaluations are also promising.Even when tested in an environment on which it has not been trained to act the agent demonstrates strong performance on general tasks, though of course it falls short in achieving environment-specific skills.Zero-shot agents are capable of performing generic navigation skills that appear across many games (e.g.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "070ec2e4-3246-47b9-8038-40626e628f9c\n",
      "{'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': '\"go down the hill\"), and show some more complex abilities like grabbing an object by its color, using the fact that color is consistent across games, and the consistent pattern that most games use left mouse to grab or interact with objects.Importantly, even on the Goat Simulator 3 environment, where the agents have not even received visual finetuning, the zero-shot agent still performs comparably to the environmentspecialized one-thus showing transfer is not driven by the visual components alone.Note that even where the numerical performance of the zero-shot and environment-specialized agents is similar, they are generally good at different skills-with the environment-specialized agent performing well on game-specific interactions, but performing more weakly on common skills that are supported across many games, and that the zero-shot agent therefore can execute.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "77f778d9-95d7-4110-b263-0dbfea4650af\n",
      "{'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': 'Note that zero-shot performance is especially strong on the WorldLab environment for three reasons.First, the evaluation tasks for this environment contain a relatively larger proportion of domain-general skills, such as recognizing objects by color, because we use them as rapid tests of agent capabilities.Second, this environment uses the same underlying engine and shares some implementation details with the other internal research environments, which may support behavioral transfer despite their varied visual styles, asset libraries, physical mechanics, and environment affordances.Furthermore, environment-specialized agent performance may be slightly weaker on this environment because there is a non-trivial distribution shift from training to test.This is because some of our data comes from earlier versions of the environment with differences in dynamics, and task distributions.Agents trained across multiple environments may be more robust to this distribution shift.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "fd71fb17-e208-4731-91fb-4c0223927548\n",
      "{'name': 'EVALUATING ENVIRONMENT GENERALIZATION & ABLATIONS', 'text': 'Classifier-free guidance Finally, Figure 10 compares the performance of agents with and without classifier-free guidance (CFG; Lifshitz et al., 2023), evaluated on a subset of our research environments: Construction Lab, Playhouse, and WorldLab.Without CFG ( = 0), the SIMA agent performs noticeably worse.However, the No CFG agent still exhibits a high degree of language conditionality, significantly outperforming the No Language baseline.These results show the benefit of CFG, highlighting the impact that inference-time interventions can have on agent controllability.No Language (Ablation)'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "bd4b8399-513f-4ec0-9fd8-d0c931564af5\n",
      "{'name': 'HUMAN BASELINE', 'text': \"Figure 11 | Comparison with Human Performance on No Man's Sky.Evaluating on a subset of tasks from No Man's Sky, human game experts outperform all agents.Yet, humans only achieve 60% success on this evaluation.This highlights the difficulty of the tasks considered in this project.\"}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "baba359a-c80d-4d56-a586-b14632cc2579\n",
      "{'name': 'HUMAN COMPARISON', 'text': 'To provide an additional baseline comparison, we evaluated our agents against expert human performance on an additional set of tasks from No Man\\'s Sky, which were chosen to test a focused set of skills in a diverse range of settings.These tasks range in difficulty, from simple instructions (\"walk forward\") to more complex instructions (\"use the analysis visor to identify new animals\").The humans who performed the tasks were players who participated in our data collection and had experience with the game.We evaluated human performance using the same judges and evaluation setup that was used for our agents; the judges were not told that they were evaluating human performance rather than agents.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "5947a261-0cf5-4174-8786-1ade677d7a0a\n",
      "{'name': 'HUMAN COMPARISON', 'text': 'Results are summarized in Figure 11 with error bars denoting parametric 95%-CIs.The human players achieved a success rate of only 60% on these tasks, demonstrating the difficulty of the tasks we considered in this project and the stringency of our evaluation criteria.For example, some human failures appear to be due to engaging in unnecessary behaviors before completing the task, like initially opening and interacting with the starship menu when instructed to \"recharge the mining beam,\" or entering analysis mode after scanning when told to \"mine oxygen.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "d3f9aedc-69af-4ff6-9257-fa6589c4aa66\n",
      "{'name': 'HUMAN COMPARISON', 'text': '\"Despite these challenging evaluations, the SIMA agent achieved non-trivial performance (34% success), far exceeding that of the No Language baseline (11% success), for example.We note that 100% success may not necessarily be achievable, due to disagreement between human judges on more ambiguous tasks.Nevertheless, there is still considerable progress needed to match human performance.This underscores the utility of the entire SIMA setup for providing a challenging, yet informative, metric for assessing grounded language interactions in embodied agents.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "df88e63a-8a15-4644-8e8c-4d7ea6e0547b\n",
      "{'name': 'LOOKING AHEAD', 'text': \"SIMA is a work in progress.In this tech report, we have described our goal and philosophy, and presented some preliminary results showing our agent's ability to ground language instructions in behavior across a variety of rich 3D environments.We see notable performance and early signs of transfer across environments, as well as zero-shot transfer of basic skills to held-out environments.Still, many skills and tasks remain out of reach.In our future work, we aim to a) scale to more environments and datasets by continuing to expand our portfolio of games, environments, and datasets; b) increase the robustness and controllability of agents; c) leverage increasingly high-quality pretrained models (Gemini Team et al., 2023); and d) develop more comprehensive and carefully controlled evaluations.\"}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "4158fc07-13cd-4253-a005-a4003bc29519\n",
      "{'name': 'LOOKING AHEAD', 'text': 'We believe that by doing so, we will make SIMA an ideal platform for doing cutting-edge research on grounding language and pretrained models safely in complex environments, thereby helping to tackle a fundamental challenge of AGI.Our research also has the potential to enrich the learning experiences and deployment environments of future foundation models; one of our goals is to ground the abstract capabilities of large language models in embodied environments.We hope that SIMA will help us learn how to overcome the fundamental challenge of linking language to perception and action at scale, and we are excited to share more details about our research in the future.'}\n",
      "author\n",
      "cb93e784-99c6-4469-9ef4-33349c4c5dd2\n",
      "paper\n",
      "898817be-6ecf-4c41-b574-5f8a45ea8550\n",
      "yext_uuid\n",
      "c18b7f94-762c-4718-81aa-281175512a7f\n"
     ]
    }
   ],
   "source": [
    "c.ingest_data(\"/home/cesar/Projects/Lammps_agent/test/Scaling Instructable Agents Across Many Simulated Worlds.pdf.tei.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "author = c.client.collections.get(\"Author\")\n",
    "\n",
    "\n",
    "response = author.query.bm25(query=\"Vercelli\", limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('9af4fb7c-3fb1-4b55-b243-f0cce7b66558'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'affiliation': 'University of British Columbia', 'name': 'Vercelli, Davide'}, references=None, vector={}, collection='Author')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Connected to base (Python 3.11.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.config import Property, DataType, ReferenceProperty\n",
    "import weaviate.classes as wvc\n",
    "import argparse\n",
    "import uuid\n",
    "import os\n",
    "from files.tei import TEI\n",
    "#  this is a file for ingesting XML Scientific data into Weaviate\n",
    "# By using a tools like Grobib for converting pdfs to XML/TEI format\n",
    "# to search in a smart way scientific papers.\n",
    "\n",
    "def common_neightbourgs(node1, node2):\n",
    "\n",
    "    \"\"\"Find common neighbours between two nodes\"\"\"\n",
    "    neighbours1 = node1.neighbours\n",
    "    neighbours2 = node2.neighbours\n",
    "    common_neighbours = [n for n in neighbours1 if n in neighbours2]\n",
    "    return common_neighbours\n",
    "\n",
    "def jaccard_score():\n",
    "    pass\n",
    "\n",
    "def search_generation(query: str,search_type: str, depth: int = 2):\n",
    "    \"\"\"\n",
    "    Make a generation based on a query, a class,  the objects to traversal and the depth\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def weaviate_generative_search(client, query: str,prompt: str, limit: int = 1, collection: str = \"Article\"):\n",
    "    try:\n",
    "        reviews = client.collections.get(collection)\n",
    "        response = reviews.generate.near_text(\n",
    "            query=query,\n",
    "            single_prompt=prompt,\n",
    "            limit=limit\n",
    "        )\n",
    "\n",
    "        return response\n",
    "    finally:\n",
    "        client.close()\n",
    "\n",
    "\n",
    "\n",
    "class Client:\n",
    "#  A wrapper class for intereating with all the tools generated in here\n",
    "    def __init__(self):\n",
    "        self.client = weaviate.connect_to_local(\n",
    "            headers={\n",
    "            \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_APIKEY\"]  # Replace with your inference API key\n",
    "                })\n",
    "\n",
    "\n",
    "\n",
    "    def ingest_data(self, file_name: str):\n",
    "        with open(file_name, \"r\") as f:\n",
    "            data = f.read()\n",
    "        article = TEI().parse(data,\"\")\n",
    "        self.save_article(article)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def save_article(self, article):\n",
    "        # Build article\n",
    "        article = article.build()\n",
    " \n",
    "        # Split authors string into a list of authors\n",
    "        authors_list = article.get(\"authors\").split('; ')\n",
    "\n",
    "        affiliations_list = article.get(\"affiliations\").split(',')\n",
    "    \n",
    "    # Create a list of author entries for the database\n",
    "        data_authors = [{\"name\": author.strip(), \"affiliation\": article.get(\"affiliations\")} for author in authors_list]\n",
    "        print(\"asdfa\")\n",
    "        print( article['sections'])\n",
    "        # data_text_sections = [\n",
    "        # {\"name\": section[0], \"text\": section[\"text\"]} for section in article['sections']\n",
    "        # ]\n",
    "        data_paper ={\n",
    "            \"title\": article.get(\"title\"),\n",
    "            \"PublicationDate\": article.get(\"publication\"),\n",
    "            \"affiliation\":article.get(\"affiliations\"),\n",
    "        }\n",
    "        author_collection = self.client.collections.get(\"Author\")\n",
    "        paper_collection = self.client.collections.get(\"Paper\")\n",
    "        text_sections_collection = self.client.collections.get(\"TextSectionTemporal\")\n",
    "\n",
    "\n",
    "        #  Before adding a new uuid indentifier we must firt check on the dataset\n",
    "        #  to see if the uuid already exists. If it does we must update the data\n",
    "        paper_response = paper_collection.query.bm25(query=data_paper[\"title\"], query_properties=[\"title\"])\n",
    "        if paper_response.objects:\n",
    "            if paper_response.objects[0]:\n",
    "                paper_uuid = paper_response.objects[0].uuid\n",
    "        else:\n",
    "            paper_uuid = paper_collection.data.insert(data_paper)\n",
    "\n",
    "\n",
    "\n",
    "        for author in data_authors:\n",
    "            authors_response = author_collection.query.bm25(query=author['name'], query_properties=[\"name\"])\n",
    "            if authors_response.objects:\n",
    "                if authors_response.objects[0]:\n",
    "                    author_uuid = authors_response.objects[0].uuid\n",
    "            else:\n",
    "                author_uuid = author_collection.data.insert(author)\n",
    "            author_collection.data.reference_add(author_uuid,\"hasPaper\", paper_uuid)\n",
    "            paper_collection.data.reference_add(paper_uuid,\"hasAuthor\", author_uuid)\n",
    "            \n",
    "\n",
    "        #  put in a batch the text sections\n",
    "            \n",
    "        \n",
    "        for data_row in article['sections']:\n",
    "            print(data_row)\n",
    "            uuid_text_section = uuid.uuid4()\n",
    "            text_sections_collection.data.insert(\n",
    "            uuid=uuid_text_section,\n",
    "            properties=data_row,\n",
    "            )\n",
    "            print(\"author\")\n",
    "            print(author_uuid)\n",
    "            print(\"paper\")\n",
    "            print(paper_uuid)\n",
    "            print(\"yext_uuid\")\n",
    "            print(uuid_text_section)\n",
    "            # text_sections_collection.data.reference_add(uuid_text_section,\"hasAuthor\", author_uuid)\n",
    "            text_sections_collection.data.reference_add(uuid_text_section,\"hasPaper\", paper_uuid)\n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def init_schemas(self):\n",
    "        \"\"\"\n",
    "        A class for initializing the schemas. This schemas are for modeling the data\n",
    "        of scientific papers.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check if the hugginface vectorizer is availble if not use OpenAI\n",
    "        # Overall Local Tools will lave more priority than Paid ones\n",
    "\n",
    "    \n",
    "        self.client.collections.create(\n",
    "            name = \"Paper\",\n",
    "            vectorizer_config = wvc.config.Configure.Vectorizer.text2vec_openai(),\n",
    "            generative_config=wvc.config.Configure.Generative.openai(),\n",
    "            properties=[\n",
    "                Property(name=\"title\", data_type=DataType.TEXT,),\n",
    "                Property(name=\"PublicationDate\", data_type=DataType.DATE),\n",
    "                Property(name=\"affiliation\", data_type=DataType.TEXT),\n",
    "                \n",
    "            ]\n",
    "        )\n",
    "        self.client.collections.create(\n",
    "            name = \"Author\",\n",
    "            vectorizer_config = wvc.config.Configure.Vectorizer.text2vec_openai(),\n",
    "            generative_config=wvc.config.Configure.Generative.openai(),\n",
    "            properties=[\n",
    "                Property(name=\"name\", data_type=DataType.TEXT,\n",
    "                          vectorize_property_name= True),\n",
    "\n",
    "            ]\n",
    "        )\n",
    "        self.client.collections.create(\n",
    "            name = \"TextSectionTemporal\" ,\n",
    "            vectorizer_config = wvc.config.Configure.Vectorizer.text2vec_openai(),\n",
    "            generative_config=wvc.config.Configure.Generative.openai(),\n",
    "            properties=[\n",
    "                Property(name=\"name\", data_type=DataType.TEXT),\n",
    "                Property(name=\"text\", data_type=DataType.TEXT),\n",
    "            ],\n",
    "        )\n",
    "        self.client.collections.create(\n",
    "            name = \"TextSection\" ,\n",
    "            vectorizer_config = wvc.config.Configure.Vectorizer.text2vec_openai(),\n",
    "            generative_config=wvc.config.Configure.Generative.openai(),\n",
    "            properties=[\n",
    "                Property(name=\"section_title\", data_type=DataType.TEXT),\n",
    "                Property(name=\"section_text\", data_type=DataType.TEXT),\n",
    "                Property(name=\"section_id\", data_type=DataType.INT),\n",
    "                Property(name=\"parent_section_title\", data_type=DataType.TEXT),\n",
    "\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.client.collections.create(\n",
    "            name = \"Figure\",\n",
    "            vectorizer_config = wvc.config.Configure.Vectorizer.text2vec_openai(),\n",
    "            generative_config=wvc.config.Configure.Generative.openai(),\n",
    "            properties=[\n",
    "                Property(name=\"figure_caption\", data_type=DataType.TEXT),\n",
    "                Property(name=\"figure_image\", data_type=DataType.INT_ARRAY),\n",
    "                \n",
    "            ]\n",
    "            )\n",
    "    \n",
    "        # Set references\n",
    "        papers = self.client.collections.get(\"Paper\")\n",
    "        papers.config.add_reference(\n",
    "        wvc.config.ReferenceProperty(name=\"hasAuthor\",target_collection=\"Author\"))\n",
    "        papers.config.add_reference(\n",
    "            ReferenceProperty(name=\"hasSection\", target_collection=\"TextSection\")\n",
    "        )\n",
    "        papers.config.add_reference(\n",
    "            ReferenceProperty(name=\"hasReferencedPaper\", target_collection=\"Paper\"))\n",
    "        \n",
    "        authors = self.client.collections.get(\"Author\")\n",
    "        authors.config.add_reference(ReferenceProperty(name=\"hasPaper\", target_collection=\"Paper\"),)\n",
    "        sections = self.client.collections.get(\"TextSectionTemporal\")\n",
    "        sections.config.add_reference(ReferenceProperty(name=\"hasPaper\", target_collection=\"Paper\"),)\n",
    "        sections.config.add_reference(ReferenceProperty(name=\"hasAuthor\", target_collection=\"Author\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate_database import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OPENAI_APIKEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m c \u001b[38;5;241m=\u001b[39m Client()\n",
      "File \u001b[0;32m~/Projects/Lammps_agent/src/weaviate_database.py:52\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m weaviate\u001b[38;5;241m.\u001b[39mconnect_to_local(\n\u001b[1;32m     51\u001b[0m         headers\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m---> 52\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-OpenAI-Api-Key\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_APIKEY\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# Replace with your inference API key\u001b[39;00m\n\u001b[1;32m     53\u001b[0m             })\n",
      "File \u001b[0;32m<frozen os>:679\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OPENAI_APIKEY'"
     ]
    }
   ],
   "source": [
    "c = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_APIKEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c.client.collections.get(\"Author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "response = a.query.hybrid(\n",
    "      query=\"Mathematician\",\n",
    "      alpha=0.5,\n",
    "      return_metadata=wvc.query.MetadataQuery(score=True, explain_score=True),\n",
    "      limit=5,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object(uuid=_WeaviateUUIDInt('e2aab178-5741-4eb1-bbfc-5c0faeb50bdc'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.5, explain_score='\\nHybrid (Result Set vector) Document e2aab178-5741-4eb1-bbfc-5c0faeb50bdc: original score 0.8039473, normalized score: 0.5', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Diamond, Charlie'}, references=None, vector={}, collection='Author')\n",
      "Object(uuid=_WeaviateUUIDInt('6c548e03-83bd-4e59-9539-1e51140d5497'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.4593311548233032, explain_score='\\nHybrid (Result Set vector) Document 6c548e03-83bd-4e59-9539-1e51140d5497: original score 0.80273366, normalized score: 0.45933115', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Eggo, Rosalind'}, references=None, vector={}, collection='Author')\n",
      "Object(uuid=_WeaviateUUIDInt('8a5d10a7-ec30-4240-873c-317e8d386b37'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.3764016032218933, explain_score='\\nHybrid (Result Set vector) Document 8a5d10a7-ec30-4240-873c-317e8d386b37: original score 0.8002588, normalized score: 0.3764016', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Pearson, Carl'}, references=None, vector={}, collection='Author')\n",
      "Object(uuid=_WeaviateUUIDInt('59ddc7de-1564-4df1-be22-efa45bd994b7'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.21505838632583618, explain_score='\\nHybrid (Result Set vector) Document 59ddc7de-1564-4df1-be22-efa45bd994b7: original score 0.7954439, normalized score: 0.21505839', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Liu, Yang'}, references=None, vector={}, collection='Author')\n",
      "Object(uuid=_WeaviateUUIDInt('9e1a7afb-a2a9-42d5-ba39-49226ff52eb6'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.15816353261470795, explain_score='\\nHybrid (Result Set vector) Document 9e1a7afb-a2a9-42d5-ba39-49226ff52eb6: original score 0.793746, normalized score: 0.15816353', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Quilty, Billy'}, references=None, vector={}, collection='Author')\n"
     ]
    }
   ],
   "source": [
    "for i in response.objects:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object(uuid=_WeaviateUUIDInt('e2aab178-5741-4eb1-bbfc-5c0faeb50bdc'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.5, explain_score='\\nHybrid (Result Set vector) Document e2aab178-5741-4eb1-bbfc-5c0faeb50bdc: original score 0.8039473, normalized score: 0.5', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Diamond, Charlie'}, references=None, vector={}, collection='Author')\n",
      "Object(uuid=_WeaviateUUIDInt('6c548e03-83bd-4e59-9539-1e51140d5497'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.4593311548233032, explain_score='\\nHybrid (Result Set vector) Document 6c548e03-83bd-4e59-9539-1e51140d5497: original score 0.80273366, normalized score: 0.45933115', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Eggo, Rosalind'}, references=None, vector={}, collection='Author')\n",
      "Object(uuid=_WeaviateUUIDInt('8a5d10a7-ec30-4240-873c-317e8d386b37'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.3764016032218933, explain_score='\\nHybrid (Result Set vector) Document 8a5d10a7-ec30-4240-873c-317e8d386b37: original score 0.8002588, normalized score: 0.3764016', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Pearson, Carl'}, references=None, vector={}, collection='Author')\n",
      "Object(uuid=_WeaviateUUIDInt('59ddc7de-1564-4df1-be22-efa45bd994b7'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.21505838632583618, explain_score='\\nHybrid (Result Set vector) Document 59ddc7de-1564-4df1-be22-efa45bd994b7: original score 0.7954439, normalized score: 0.21505839', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Liu, Yang'}, references=None, vector={}, collection='Author')\n",
      "Object(uuid=_WeaviateUUIDInt('9e1a7afb-a2a9-42d5-ba39-49226ff52eb6'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.15816353261470795, explain_score='\\nHybrid (Result Set vector) Document 9e1a7afb-a2a9-42d5-ba39-49226ff52eb6: original score 0.793746, normalized score: 0.15816353', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Quilty, Billy'}, references=None, vector={}, collection='Author')\n"
     ]
    }
   ],
   "source": [
    "for o in response.objects:\n",
    "    print(o)\n",
    "    # for ref in o.references[\"hasPaper\"].objects:\n",
    "    #     print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = c.client.collections.get(\"Paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = papers.query.hybrid(query=\"China\", query_properties=[\"title\"], limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = p.objects[0].uuid\n",
    "q = response.objects[0].uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_WeaviateUUIDInt('5aa3653f-973e-4a60-b7fa-429e0cefd0d9')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_WeaviateUUIDInt('e2aab178-5741-4eb1-bbfc-5c0faeb50bdc')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.data.reference_add(from_uuid =q,from_property=\"hasPaper\",to= w)\n",
    "papers.data.reference_add(from_uuid=w,from_property=\"hasAuthor\",to= q)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('5aa3653f-973e-4a60-b7fa-429e0cefd0d9'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'title': 'Changing travel patterns in China during the early stages of the COVID-19 pandemic', 'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'publicationDate': None}, references=None, vector={}, collection='Paper')])\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CollectionConfig(name='Author', description=None, generative_config=_GenerativeConfig(generative=<GenerativeSearches.OPENAI: 'generative-openai'>, model={}), inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False), properties=[_Property(name='name', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai'), _Property(name='affiliation', description=\"This property was generated by Weaviate's auto-schema feature on Thu Apr  4 02:34:16 2024\", data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-openai')], references=[_ReferenceProperty(name='hasPaper', description=None, target_collections=['Paper'])], replication_config=_ReplicationConfig(factor=1), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=_VectorIndexConfigHNSW(quantizer=None, cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, flat_search_cutoff=40000, max_connections=64, skip=False, vector_cache_max_objects=1000000000000), vector_index_type=<VectorIndexType.HNSW: 'hnsw'>, vectorizer_config=_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_OPENAI: 'text2vec-openai'>, model={'baseURL': 'https://api.openai.com', 'model': 'ada'}, vectorize_collection_name=True), vectorizer=<Vectorizers.TEXT2VEC_OPENAI: 'text2vec-openai'>, vector_config=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.config.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('e2aab178-5741-4eb1-bbfc-5c0faeb50bdc'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.5, explain_score='\\nHybrid (Result Set vector) Document e2aab178-5741-4eb1-bbfc-5c0faeb50bdc: original score 0.8039473, normalized score: 0.5', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Diamond, Charlie'}, references=None, vector={}, collection='Author'), Object(uuid=_WeaviateUUIDInt('6c548e03-83bd-4e59-9539-1e51140d5497'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.4593311548233032, explain_score='\\nHybrid (Result Set vector) Document 6c548e03-83bd-4e59-9539-1e51140d5497: original score 0.80273366, normalized score: 0.45933115', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Eggo, Rosalind'}, references=None, vector={}, collection='Author'), Object(uuid=_WeaviateUUIDInt('8a5d10a7-ec30-4240-873c-317e8d386b37'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.3764016032218933, explain_score='\\nHybrid (Result Set vector) Document 8a5d10a7-ec30-4240-873c-317e8d386b37: original score 0.8002588, normalized score: 0.3764016', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Pearson, Carl'}, references=None, vector={}, collection='Author'), Object(uuid=_WeaviateUUIDInt('59ddc7de-1564-4df1-be22-efa45bd994b7'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.21505838632583618, explain_score='\\nHybrid (Result Set vector) Document 59ddc7de-1564-4df1-be22-efa45bd994b7: original score 0.7954439, normalized score: 0.21505839', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Liu, Yang'}, references=None, vector={}, collection='Author'), Object(uuid=_WeaviateUUIDInt('9e1a7afb-a2a9-42d5-ba39-49226ff52eb6'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.15816353261470795, explain_score='\\nHybrid (Result Set vector) Document 9e1a7afb-a2a9-42d5-ba39-49226ff52eb6: original score 0.793746, normalized score: 0.15816353', is_consistent=None, rerank_score=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Quilty, Billy'}, references=None, vector={}, collection='Author')])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ese = a.query.fetch_object_by_id(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.data.reference_add(from_uuid =q,from_property=\"hasPaper\",to= w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectSingleReturn(uuid=_WeaviateUUIDInt('e2aab178-5741-4eb1-bbfc-5c0faeb50bdc'), metadata=MetadataSingleObjectReturn(creation_time=datetime.datetime(2024, 4, 4, 2, 34, 17, 708000, tzinfo=datetime.timezone.utc), last_update_time=datetime.datetime(2024, 4, 4, 4, 22, 24, 486000, tzinfo=datetime.timezone.utc), is_consistent=None), properties={'affiliation': 'Department of Infectious Disease Epidemiology, School of Hygiene and Tropical Medicine; Centre for Mathematical Modelling of Infectious Diseases, School of Hygiene and Tropical Medicine', 'name': 'Diamond, Charlie'}, references=None, vector={}, collection='Author')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = c.client.collections.create(\n",
    "        name=\"JeopardyCategory\",\n",
    "        description=\"A Jeopardy! category\",\n",
    "        properties=[\n",
    "            wvc.config.Property(name=\"title\", data_type=wvc.config.DataType.TEXT)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.Collection at 0x7959baf9a7d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.client.collections.create(\n",
    "        name=\"JeopardyQuestion\",\n",
    "        description=\"A Jeopardy! question\",\n",
    "        properties=[\n",
    "            wvc.config.Property(name=\"question\", data_type=wvc.config.DataType.TEXT),\n",
    "            wvc.config.Property(name=\"answer\", data_type=wvc.config.DataType.TEXT),\n",
    "        ],\n",
    "        references=[\n",
    "            wvc.config.ReferenceProperty(\n",
    "                name=\"hasCategory\",\n",
    "                target_collection=\"JeopardyCategory\"\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Add the reference to JeopardyQuestion, after it was created\n",
    "category = c.client.collections.get(\"JeopardyCategory\")\n",
    "    # category.config.add_reference(\n",
    "category.config.add_reference(\n",
    "        wvc.config.ReferenceProperty(\n",
    "            name=\"hasQuestion\",\n",
    "            target_collection=\"JeopardyQuestion\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('009f090f-a471-4023-bb10-67f8ff29a0b7')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "category = c.client.collections.get(\"JeopardyCategory\")\n",
    "ob1 = uuid.uuid4()\n",
    "category.data.insert(\n",
    "        properties={},  # A dictionary with the properties of the object\n",
    "        uuid=ob1,  # A UUID for the object\n",
    "     # e.g. {\"hasCategory\": \"583876f3-e293-5b5b-9839-03f455f14575\"}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('bd63b992-e6ac-4e71-87dc-707aab378f42')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "questions = c.client.collections.get(\"JeopardyQuestion\")\n",
    "obj2 = uuid.uuid4()\n",
    "questions.data.insert(\n",
    "        properties={},  # A dictionary with the properties of the object\n",
    "        uuid=obj2,  # A UUID for the object\n",
    "        references={\"hasCategory\":ob1 },  # e.g. {\"hasCategory\": \"583876f3-e293-5b5b-9839-03f455f14575\"}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_FetchObjectByIDQuery.fetch_object_by_id() got an unexpected keyword argument 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m r \u001b[38;5;241m=\u001b[39m questions\u001b[38;5;241m.\u001b[39mquery\u001b[38;5;241m.\u001b[39mfetch_object_by_id(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mobj2)\n",
      "\u001b[0;31mTypeError\u001b[0m: _FetchObjectByIDQuery.fetch_object_by_id() got an unexpected keyword argument 'id'"
     ]
    }
   ],
   "source": [
    "r = questions.query.fetch_object_by_id(id=obj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object(uuid=_WeaviateUUIDInt('bd63b992-e6ac-4e71-87dc-707aab378f42'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'answer': None, 'question': None}, references=None, vector={}, collection='JeopardyQuestion')\n",
      "Object(uuid=_WeaviateUUIDInt('fac3daf2-1478-4cae-ab94-8889f26ebfdc'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'answer': None, 'question': None}, references=None, vector={}, collection='JeopardyQuestion')\n"
     ]
    }
   ],
   "source": [
    "for i in questions.iterator():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
